<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>matchmaking_normal-DeepLearning-NoGroup-Precision</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    pre { line-height: 125%; margin: 0; }
td.linenos pre { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
span.linenos { color: #000000; background-color: #f0f0f0; padding-left: 5px; padding-right: 5px; }
td.linenos pre.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">matchData</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;matchedVector_Oct.csv&quot;</span><span class="p">)</span>
<span class="n">matchData</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[1]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>id_user</th>
      <th>gender_公開したくない_user</th>
      <th>gender_女_user</th>
      <th>gender_男_user</th>
      <th>state_address_京都府_user</th>
      <th>state_address_兵庫県_user</th>
      <th>state_address_千葉県_user</th>
      <th>state_address_大阪府_user</th>
      <th>state_address_奈良県_user</th>
      <th>...</th>
      <th>hobbies_description_291_matched</th>
      <th>hobbies_description_292_matched</th>
      <th>hobbies_description_293_matched</th>
      <th>hobbies_description_294_matched</th>
      <th>hobbies_description_295_matched</th>
      <th>hobbies_description_296_matched</th>
      <th>hobbies_description_297_matched</th>
      <th>hobbies_description_298_matched</th>
      <th>hobbies_description_299_matched</th>
      <th>isMatched</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.271225</td>
      <td>0.536644</td>
      <td>0.006921</td>
      <td>0.113247</td>
      <td>0.184511</td>
      <td>0.289309</td>
      <td>-0.191802</td>
      <td>-0.057783</td>
      <td>-0.146640</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.264849</td>
      <td>0.132094</td>
      <td>0.160206</td>
      <td>-0.352224</td>
      <td>0.227690</td>
      <td>0.001928</td>
      <td>-0.094883</td>
      <td>0.245324</td>
      <td>0.500497</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.059004</td>
      <td>0.073294</td>
      <td>-0.034768</td>
      <td>0.152796</td>
      <td>0.025107</td>
      <td>0.041870</td>
      <td>0.078420</td>
      <td>0.078320</td>
      <td>0.017810</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>-0.001368</td>
      <td>0.224195</td>
      <td>-0.074875</td>
      <td>-0.057536</td>
      <td>0.220293</td>
      <td>-0.243604</td>
      <td>-0.199743</td>
      <td>-0.006815</td>
      <td>-0.061889</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.066217</td>
      <td>0.343102</td>
      <td>-0.061304</td>
      <td>0.021724</td>
      <td>0.193784</td>
      <td>-0.147088</td>
      <td>-0.044483</td>
      <td>-0.013207</td>
      <td>-0.024082</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1015</th>
      <td>1015</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.022038</td>
      <td>0.272111</td>
      <td>-0.098638</td>
      <td>0.011447</td>
      <td>0.238410</td>
      <td>-0.168982</td>
      <td>-0.089604</td>
      <td>0.054160</td>
      <td>0.006432</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1016</th>
      <td>1016</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>0.002235</td>
      <td>0.233088</td>
      <td>-0.094603</td>
      <td>0.008887</td>
      <td>0.223330</td>
      <td>-0.162612</td>
      <td>-0.100327</td>
      <td>-0.020706</td>
      <td>-0.025752</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1017</th>
      <td>1017</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>-0.020817</td>
      <td>0.153353</td>
      <td>-0.089354</td>
      <td>0.002173</td>
      <td>0.262459</td>
      <td>-0.128186</td>
      <td>-0.075317</td>
      <td>-0.000606</td>
      <td>-0.108569</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1018</th>
      <td>1018</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>-0.012812</td>
      <td>0.100310</td>
      <td>-0.056103</td>
      <td>0.093714</td>
      <td>0.254967</td>
      <td>-0.097655</td>
      <td>-0.029159</td>
      <td>0.064401</td>
      <td>-0.058740</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1019</th>
      <td>1019</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>...</td>
      <td>-0.010371</td>
      <td>0.187242</td>
      <td>-0.120705</td>
      <td>-0.036971</td>
      <td>0.154782</td>
      <td>-0.144129</td>
      <td>-0.024393</td>
      <td>0.037821</td>
      <td>-0.041253</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>1020 rows × 1304 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">matchData</span><span class="p">[</span><span class="s1">&#39;id_user&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span> <span class="c1">#number of users</span>
<span class="nb">print</span><span class="p">(</span><span class="n">matchData</span><span class="p">[</span><span class="s1">&#39;id_matched&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">())</span><span class="c1">#number of candidates</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>20
51
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#initialize language model</span>
<span class="kn">import</span> <span class="nn">tensorflow_hub</span> <span class="k">as</span> <span class="nn">hub</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow_text</span>

<span class="n">japanese_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;犬&quot;</span><span class="p">,</span> <span class="s2">&quot;子犬はいいです&quot;</span><span class="p">,</span> <span class="s2">&quot;私は犬と一緒にビーチを散歩するのが好きです&quot;</span><span class="p">]</span>
<span class="n">embed</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;https://tfhub.dev/google/universal-sentence-encoder-multilingual/3&quot;</span><span class="p">)</span>
<span class="n">ja_result</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">japanese_sentences</span><span class="p">)</span>
<span class="n">ja_result</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[3]:</div>




<div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain">
<pre>&lt;tf.Tensor: shape=(3, 512), dtype=float32, numpy=
array([[ 0.10949967, -0.02602163,  0.0461009 , ...,  0.0523318 ,
         0.00311095,  0.01985743],
       [ 0.03606613, -0.00969925,  0.04294631, ...,  0.02523111,
        -0.00969074,  0.05069919],
       [-0.02916381, -0.00816519, -0.02910492, ...,  0.00125968,
        -0.00689576,  0.01039782]], dtype=float32)&gt;</pre>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>

<span class="c1">#select features (include everything but text)</span>
<span class="n">user_X</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;gender_公開したくない_user&quot;</span><span class="p">:</span><span class="s2">&quot;coping_strategy_飲酒_user&quot;</span><span class="p">]</span>
<span class="n">target_X</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;gender_公開したくない_matched&quot;</span><span class="p">:</span><span class="s2">&quot;coping_strategy_飲酒_matched&quot;</span><span class="p">]</span>
<span class="n">user_X_Id</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s2">&quot;id_user&quot;</span><span class="p">]]</span>
<span class="n">isMatched</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,[</span><span class="s2">&quot;isMatched&quot;</span><span class="p">]]</span>

<span class="c1">#vectorize the languages</span>
<span class="n">loss_description_user</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;loss_description_user&quot;</span><span class="p">]</span>
<span class="n">loss_vector_col_name</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;loss_user_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">)]</span>
<span class="n">loss_vector</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">loss_description_user</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">columns</span><span class="o">=</span><span class="n">loss_vector_col_name</span><span class="p">)</span>

<span class="n">loss_description_matched</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;loss_description_matched&quot;</span><span class="p">]</span>
<span class="n">loss_vector_match_col_name</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;loss_user_matched_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">)]</span>
<span class="n">loss_vector_matched</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">loss_description_matched</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">columns</span><span class="o">=</span><span class="n">loss_vector_match_col_name</span><span class="p">)</span>

<span class="n">hobbies_description</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;hobbies_description_user&quot;</span><span class="p">]</span>
<span class="n">hobbies_col_name</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;hobbies_description_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">)]</span>
<span class="n">hobbies_vector</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">hobbies_description</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">columns</span><span class="o">=</span><span class="n">hobbies_col_name</span><span class="p">)</span>

<span class="n">hobbies_description_matched</span><span class="o">=</span><span class="n">matchData</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span><span class="s2">&quot;hobbies_description_matched&quot;</span><span class="p">]</span>
<span class="n">hobbies_col_name_matched</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;hobbies_description_matched_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">num</span><span class="p">)</span> <span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">512</span><span class="p">)]</span>
<span class="n">hobbies_vector_matched</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">hobbies_description_matched</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span><span class="n">columns</span><span class="o">=</span><span class="n">hobbies_col_name_matched</span><span class="p">)</span>


<span class="n">matchEncodedData</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">user_X</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">user_X</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span><span class="n">loss_vector</span><span class="p">,</span><span class="n">hobbies_vector</span><span class="p">,</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">target_X</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">target_X</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span><span class="n">loss_vector_matched</span><span class="p">,</span><span class="n">hobbies_vector_matched</span><span class="p">,</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">user_X_Id</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">user_X_Id</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">isMatched</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span><span class="n">isMatched</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="p">]</span>
    <span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="n">matchEncodedData</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[4]:</div>



<div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/html">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>gender_公開したくない_user</th>
      <th>gender_女_user</th>
      <th>gender_男_user</th>
      <th>state_address_京都府_user</th>
      <th>state_address_兵庫県_user</th>
      <th>state_address_千葉県_user</th>
      <th>state_address_大阪府_user</th>
      <th>state_address_奈良県_user</th>
      <th>state_address_愛知県_user</th>
      <th>state_address_東京都_user</th>
      <th>...</th>
      <th>hobbies_description_matched_504</th>
      <th>hobbies_description_matched_505</th>
      <th>hobbies_description_matched_506</th>
      <th>hobbies_description_matched_507</th>
      <th>hobbies_description_matched_508</th>
      <th>hobbies_description_matched_509</th>
      <th>hobbies_description_matched_510</th>
      <th>hobbies_description_matched_511</th>
      <th>id_user</th>
      <th>isMatched</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.049046</td>
      <td>-0.039544</td>
      <td>-0.039549</td>
      <td>-0.014543</td>
      <td>0.065492</td>
      <td>0.003262</td>
      <td>-0.020129</td>
      <td>0.015826</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.053450</td>
      <td>0.004441</td>
      <td>0.038660</td>
      <td>0.038439</td>
      <td>0.026448</td>
      <td>0.058783</td>
      <td>0.013017</td>
      <td>0.049772</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.034459</td>
      <td>-0.019833</td>
      <td>-0.048841</td>
      <td>0.011338</td>
      <td>-0.046273</td>
      <td>-0.008043</td>
      <td>-0.000286</td>
      <td>0.020750</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.000880</td>
      <td>-0.034878</td>
      <td>-0.060844</td>
      <td>0.016372</td>
      <td>0.075033</td>
      <td>-0.002366</td>
      <td>0.047346</td>
      <td>0.038690</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.009543</td>
      <td>-0.092120</td>
      <td>-0.001146</td>
      <td>0.012079</td>
      <td>0.056051</td>
      <td>0.013686</td>
      <td>-0.018617</td>
      <td>-0.016071</td>
      <td>04aac48e-82d7-4dce-b505-68206f8cb634</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1015</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.036651</td>
      <td>-0.096818</td>
      <td>0.015811</td>
      <td>-0.012709</td>
      <td>0.077361</td>
      <td>0.030963</td>
      <td>-0.062089</td>
      <td>-0.020901</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1016</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.064977</td>
      <td>-0.028447</td>
      <td>0.007810</td>
      <td>-0.019448</td>
      <td>0.012961</td>
      <td>-0.011578</td>
      <td>0.020329</td>
      <td>0.012949</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1017</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.052806</td>
      <td>-0.010728</td>
      <td>-0.041381</td>
      <td>-0.018710</td>
      <td>0.087754</td>
      <td>0.070981</td>
      <td>-0.065402</td>
      <td>0.020334</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1018</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.055663</td>
      <td>0.005511</td>
      <td>0.011218</td>
      <td>-0.041733</td>
      <td>-0.027682</td>
      <td>-0.088818</td>
      <td>-0.006499</td>
      <td>0.041154</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1019</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.020469</td>
      <td>-0.030482</td>
      <td>0.029674</td>
      <td>-0.057403</td>
      <td>0.024335</td>
      <td>0.007226</td>
      <td>-0.000058</td>
      <td>0.033232</td>
      <td>9057760d-38f9-4831-89b4-bc9e08282f69</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>1020 rows × 2144 columns</p>
</div>
</div>

</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[5]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">getExistingTrainingToTest</span><span class="p">(</span><span class="n">train_index</span><span class="p">,</span><span class="n">test_index</span><span class="p">,</span><span class="n">ratio</span><span class="p">,</span><span class="n">numMatches</span><span class="p">):</span>
    <span class="n">pickNum</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="n">numMatches</span><span class="o">*</span><span class="n">ratio</span><span class="p">)</span>
    <span class="n">numUsers</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_index</span><span class="p">)</span><span class="o">/</span><span class="n">numMatches</span><span class="p">)</span>
    <span class="n">index</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">new_train_index</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">new_test_index</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">moveList</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numUsers</span><span class="p">):</span>
        <span class="n">randomIndexList</span><span class="o">=</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">numMatches</span><span class="p">),</span> <span class="n">pickNum</span><span class="p">)</span>
        <span class="n">randomIndexList</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">+</span><span class="p">(</span><span class="n">index</span><span class="o">*</span><span class="n">numMatches</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">randomIndexList</span><span class="p">]</span>
        <span class="n">moveList</span> <span class="o">=</span> <span class="n">moveList</span><span class="o">+</span><span class="p">[</span><span class="n">test_index</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">randomIndexList</span><span class="p">]</span>
        <span class="n">index</span><span class="o">=</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span>
    <span class="c1">#move the numbers in the move list to the test and train index</span>
    <span class="n">new_test_index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="ow">not</span><span class="p">(</span><span class="n">x</span> <span class="ow">in</span> <span class="n">moveList</span><span class="p">),</span><span class="n">test_index</span><span class="p">))</span>
    <span class="n">new_train_index</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">train_index</span><span class="p">)</span>
    <span class="n">move_index</span><span class="o">=</span><span class="n">moveList</span>
    <span class="k">return</span> <span class="n">new_train_index</span><span class="p">,</span><span class="n">move_index</span><span class="p">,</span><span class="n">new_test_index</span>
        
    
    
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[6]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span><span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span><span class="n">Dropout</span><span class="p">,</span><span class="n">Flatten</span><span class="p">,</span><span class="n">Input</span><span class="p">,</span><span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">keras.metrics</span> <span class="kn">import</span> <span class="n">AUC</span>

<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>

<span class="k">def</span> <span class="nf">testDLSiamese</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">groupString</span><span class="p">):</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">groupString</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;isMatched&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">groupString</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;isMatched&quot;</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1">#Start training</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">Y_train</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>

    <span class="n">half_size</span><span class="o">=</span><span class="nb">round</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">input_1</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">half_size</span><span class="p">,))</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">input_1</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_1</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">layer_1</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_1</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">layer_1</span><span class="p">)</span>
    <span class="n">layer_1</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_1</span><span class="p">)</span>
    
    <span class="n">input_2</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">half_size</span><span class="p">,))</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">input_2</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_2</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">layer_2</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_2</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">layer_2</span><span class="p">)</span>
    <span class="n">layer_2</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.4</span><span class="p">)(</span><span class="n">layer_2</span><span class="p">)</span>
    
    <span class="n">l1_norm</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">K</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">merged</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="n">function</span><span class="o">=</span><span class="n">l1_norm</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;L1_distance&#39;</span><span class="p">)([</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">layer_2</span><span class="p">])</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;classification_layer&#39;</span><span class="p">)(</span><span class="n">merged</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">input_1</span><span class="p">,</span> <span class="n">input_2</span><span class="p">],</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">AUC</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;auc&#39;</span><span class="p">)])</span>    
    <span class="n">result</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">([</span><span class="n">X_train</span><span class="p">[:,:</span><span class="n">half_size</span><span class="p">],</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">half_size</span><span class="p">:]],</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y_train</span><span class="p">),</span><span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span><span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    
    <span class="n">predict_y</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">X_test</span><span class="p">[:,:</span><span class="n">half_size</span><span class="p">],</span><span class="n">X_test</span><span class="p">[:,</span><span class="n">half_size</span><span class="p">:]])</span>

    <span class="k">return</span> <span class="n">predict_y</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[7]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">from</span> <span class="nn">surprise</span> <span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">surprise</span> <span class="kn">import</span> <span class="n">SVD</span>
<span class="kn">from</span> <span class="nn">surprise.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">surprise</span> <span class="kn">import</span> <span class="n">Reader</span>
<span class="kn">from</span> <span class="nn">surprise</span> <span class="kn">import</span> <span class="n">accuracy</span>

<span class="k">def</span> <span class="nf">NormalizeData</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">data</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">precision_recall_at_k</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">3.5</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return precision and recall at k metrics for each user&quot;&quot;&quot;</span>
        
    <span class="n">precisions</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">recalls</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">uid</span><span class="p">,</span> <span class="n">user_ratings</span> <span class="ow">in</span> <span class="n">predictions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        
        <span class="c1"># normalize from zero to one</span>
        <span class="n">getNormalizeNumber</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">eachRating</span> <span class="ow">in</span> <span class="n">user_ratings</span><span class="p">:</span>
            <span class="n">getNormalizeNumber</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">eachRating</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            
        <span class="n">normalized</span><span class="o">=</span><span class="n">NormalizeData</span><span class="p">(</span><span class="n">getNormalizeNumber</span><span class="p">)</span>
        
        <span class="n">newRating</span><span class="o">=</span><span class="p">[]</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span><span class="n">eachRating</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">user_ratings</span><span class="p">):</span>
            <span class="n">newRating</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">normalized</span><span class="p">[</span><span class="n">index</span><span class="p">],</span><span class="n">eachRating</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">user_ratings</span><span class="o">=</span><span class="n">newRating</span>
        
        <span class="c1"># Sort user ratings by estimated value</span>
        <span class="n">user_ratings</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">user_ratings</span><span class="p">)</span>
        
        <span class="c1"># Number of relevant items</span>
        <span class="n">n_rel</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">true_r</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">true_r</span><span class="p">)</span> <span class="ow">in</span> <span class="n">user_ratings</span><span class="p">)</span>
        
        <span class="c1"># Number of recommended items in top k</span>
        <span class="n">n_rec_k</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">((</span><span class="n">est</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="n">user_ratings</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span>

        <span class="c1"># Number of relevant and recommended items in top k</span>
        <span class="n">n_rel_and_rec_k</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(((</span><span class="n">true_r</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">est</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">))</span>
                              <span class="k">for</span> <span class="p">(</span><span class="n">est</span><span class="p">,</span> <span class="n">true_r</span><span class="p">)</span> <span class="ow">in</span> <span class="n">user_ratings</span><span class="p">[:</span><span class="n">k</span><span class="p">])</span>

        <span class="c1"># Precision@K: Proportion of recommended items that are relevant</span>
        <span class="c1"># When n_rec_k is 0, Precision is undefined. We here set it to 0.</span>

        <span class="n">precisions</span><span class="p">[</span><span class="n">uid</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_rel_and_rec_k</span> <span class="o">/</span> <span class="n">n_rec_k</span> <span class="k">if</span> <span class="n">n_rec_k</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="c1"># Recall@K: Proportion of relevant items that are recommended</span>
        <span class="c1"># When n_rel is 0, Recall is undefined. We here set it to 0.</span>

        <span class="n">recalls</span><span class="p">[</span><span class="n">uid</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_rel_and_rec_k</span> <span class="o">/</span> <span class="n">n_rel</span> <span class="k">if</span> <span class="n">n_rel</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="n">n_rel</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">recalls</span><span class="p">[</span><span class="n">uid</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        
    <span class="k">return</span> <span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[8]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#for parameter optimization</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1">#for evaluation </span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneGroupOut</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#ignore all warnings</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">statistics</span> <span class="kn">import</span> <span class="n">mean</span>

<span class="k">def</span> <span class="nf">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">groupString</span><span class="p">,</span><span class="n">k_value</span><span class="p">,</span><span class="n">ratio</span><span class="p">):</span>
    <span class="n">group</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">groupString</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
    <span class="n">skf</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut</span><span class="p">()</span>
    <span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">group</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">skf</span><span class="p">)</span>
    
    <span class="n">siam_p_k</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">siam_r_k</span><span class="o">=</span><span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="n">group</span><span class="p">):</span>
        <span class="n">train_index</span><span class="p">,</span><span class="n">move_index</span><span class="p">,</span><span class="n">test_index</span><span class="o">=</span><span class="n">getExistingTrainingToTest</span><span class="p">(</span><span class="n">train_index</span><span class="p">,</span><span class="n">test_index</span><span class="p">,</span><span class="n">ratio</span><span class="p">,</span><span class="mi">51</span><span class="p">)</span>
        
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_index</span><span class="p">)]</span>
        <span class="n">X_train_moved</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">move_index</span><span class="p">)]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>

        <span class="n">Y_train</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">Y</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_index</span><span class="p">)]</span>
        <span class="n">Y_train_moved</span><span class="o">=</span><span class="n">Y</span><span class="p">[</span><span class="n">Y</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">move_index</span><span class="p">)]</span>
        <span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y</span><span class="p">[</span><span class="n">Y</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>
            
        <span class="n">X_train</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
           <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
           <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train_moved</span><span class="p">)</span>
        <span class="p">]))</span>
        
        <span class="n">Y_train</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
           <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Y_train</span><span class="p">),</span>
           <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">Y_train_moved</span><span class="p">)</span>
        <span class="p">]))</span>
    
        <span class="n">y_pred</span><span class="o">=</span> <span class="n">testDLSiamese</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">Y_train</span><span class="p">,</span><span class="n">groupString</span><span class="p">)</span>
        
        <span class="c1">#for this to work, we need to format it correctly [uid]=(predicted,true)</span>
        <span class="n">prec_cal</span><span class="o">=</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
        
        <span class="n">counter</span><span class="o">=</span><span class="mi">0</span> <span class="c1">#don&#39;t use index as it doesn&#39;t start at zero</span>
        <span class="k">for</span> <span class="n">index</span><span class="p">,</span><span class="n">eachTest</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
            <span class="n">prec_cal</span><span class="p">[</span><span class="n">eachTest</span><span class="p">[</span><span class="s1">&#39;id_user&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">y_pred</span><span class="p">[</span><span class="n">counter</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">Y_test</span><span class="p">[</span><span class="s1">&#39;isMatched&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">counter</span><span class="p">]))</span>
            <span class="n">counter</span><span class="o">=</span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span>

        <span class="n">precisions</span><span class="p">,</span> <span class="n">recalls</span> <span class="o">=</span> <span class="n">precision_recall_at_k</span><span class="p">(</span><span class="n">prec_cal</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k_value</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">prec</span> <span class="k">for</span> <span class="n">prec</span> <span class="ow">in</span> <span class="n">precisions</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">precisions</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">rec</span> <span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">recalls</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">recalls</span><span class="p">))</span>        
        <span class="n">siam_p_k</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">prec</span> <span class="k">for</span> <span class="n">prec</span> <span class="ow">in</span> <span class="n">precisions</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">precisions</span><span class="p">))</span>
        <span class="n">siam_r_k</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">rec</span> <span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">recalls</span><span class="o">.</span><span class="n">values</span><span class="p">())</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">recalls</span><span class="p">))</span>  
        
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Siam&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">siam_p_k</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">siam_p_k</span>  <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">siam_r_k</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mean</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">siam_r_k</span>  <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[9]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">=</span><span class="n">matchEncodedData</span>
<span class="n">Y</span><span class="o">=</span><span class="n">isMatched</span>

<span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235573163A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/97 [==========================&gt;...] - ETA: 0s - loss: 0.5266 - auc: 0.5233 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500F79C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5273 - auc: 0.5429 - val_loss: 0.2417 - val_auc: 0.6206
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4973 - auc: 0.6251 - val_loss: 0.2137 - val_auc: 0.5413
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6391 - val_loss: 0.2182 - val_auc: 0.6905
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.6752 - val_loss: 0.2336 - val_auc: 0.5942
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6287 - val_loss: 0.2386 - val_auc: 0.4926
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6161 - val_loss: 0.2551 - val_auc: 0.5810
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6472 - val_loss: 0.2581 - val_auc: 0.5873
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6548 - val_loss: 0.2409 - val_auc: 0.5910
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4675 - auc: 0.7153 - val_loss: 0.2589 - val_auc: 0.5847
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4804 - auc: 0.6849 - val_loss: 0.2894 - val_auc: 0.5720
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4737 - auc: 0.7030 - val_loss: 0.2524 - val_auc: 0.4894
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4762 - auc: 0.7153 - val_loss: 0.2293 - val_auc: 0.5561
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4679 - auc: 0.7074 - val_loss: 0.2700 - val_auc: 0.5884
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7001 - val_loss: 0.2345 - val_auc: 0.6005
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4800 - auc: 0.7135 - val_loss: 0.2458 - val_auc: 0.5153
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6874 - val_loss: 0.2609 - val_auc: 0.3905
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4745 - auc: 0.7119 - val_loss: 0.2745 - val_auc: 0.4333
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4731 - auc: 0.7282 - val_loss: 0.2710 - val_auc: 0.4788
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4749 - auc: 0.7136 - val_loss: 0.2702 - val_auc: 0.4540
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.6987 - val_loss: 0.2501 - val_auc: 0.4598
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503335A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8861095, 0), (0.87327015, 1), (0.8722487, 1), (0.8430188, 1), (0.8169199, 1), (0.7916857, 1), (0.7769843, 0), (0.7702162, 0), (0.7484183, 0), (0.74754864, 0), (0.746603, 0), (0.7425251, 0), (0.7384641, 0), (0.7372973, 1), (0.7353068, 0), (0.7346849, 0), (0.7320003, 0), (0.7314338, 0), (0.7306034, 0), (0.72890455, 0), (0.728065, 0), (0.72793007, 0), (0.7279271, 0), (0.7279216, 0), (0.7233993, 0), (0.71874523, 0), (0.71292084, 0), (0.7128254, 1), (0.71058905, 1), (0.70988244, 0), (0.70865357, 1), (0.70391405, 0), (0.7017731, 1), (0.6935067, 0), (0.69055927, 0), (0.6885851, 1), (0.6808884, 0), (0.6784108, 1), (0.6764353, 0), (0.6760655, 1), (0.67358375, 0), (0.67244995, 0), (0.66652644, 0), (0.66270787, 0), (0.6145315, 0), (0.6011785, 1), (0.50912625, 1), (0.3031086, 0), (0.05676936, 1), (0.0, 0)]
0.6
0.1875
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235024AC828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
96/97 [============================&gt;.] - ETA: 0s - loss: 0.6379 - auc: 0.4780WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235083A1828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 7ms/step - loss: 0.6347 - auc: 0.4795 - val_loss: 0.5199 - val_auc: 0.4265
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5540 - auc: 0.5770 - val_loss: 0.3620 - val_auc: 0.7952
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5390 - auc: 0.5992 - val_loss: 0.4130 - val_auc: 0.7698
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6693 - val_loss: 0.3997 - val_auc: 0.5931
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6488 - val_loss: 0.4069 - val_auc: 0.6423
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5180 - auc: 0.6612 - val_loss: 0.3879 - val_auc: 0.5693
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6796 - val_loss: 0.3349 - val_auc: 0.6481
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6569 - val_loss: 0.3585 - val_auc: 0.6323
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.6916 - val_loss: 0.3398 - val_auc: 0.6635
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.7199 - val_loss: 0.3174 - val_auc: 0.6275
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5220 - auc: 0.6520 - val_loss: 0.3656 - val_auc: 0.6529
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.6827 - val_loss: 0.3400 - val_auc: 0.5979
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6851 - val_loss: 0.3463 - val_auc: 0.5884
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5023 - auc: 0.6710 - val_loss: 0.3268 - val_auc: 0.6402
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.7082 - val_loss: 0.3344 - val_auc: 0.6556
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.7025 - val_loss: 0.3445 - val_auc: 0.5714
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4804 - auc: 0.7199 - val_loss: 0.3245 - val_auc: 0.6365
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4732 - auc: 0.7279 - val_loss: 0.3387 - val_auc: 0.5899
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4676 - auc: 0.7363 - val_loss: 0.3187 - val_auc: 0.6545
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7118 - val_loss: 0.3179 - val_auc: 0.5794
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350848AAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9510059, 0), (0.950713, 0), (0.9198441, 1), (0.9106068, 1), (0.90815693, 1), (0.90060794, 0), (0.8958558, 1), (0.88771933, 0), (0.8866123, 0), (0.8740995, 0), (0.86898625, 0), (0.8682876, 0), (0.86620206, 0), (0.8548337, 1), (0.8417831, 0), (0.83686364, 0), (0.83324933, 0), (0.8324774, 1), (0.83003557, 0), (0.82367486, 0), (0.80528486, 0), (0.80119514, 0), (0.7904291, 0), (0.7862892, 0), (0.7830289, 1), (0.78003657, 0), (0.7686518, 0), (0.76147425, 0), (0.7185786, 1), (0.6882082, 0), (0.6836575, 0), (0.64309883, 1), (0.63797975, 0), (0.6296371, 0), (0.61916506, 0), (0.61364084, 0), (0.5802767, 0), (0.55771035, 0), (0.54671943, 0), (0.5442997, 0), (0.51958555, 0), (0.5064785, 0), (0.49012655, 0), (0.46452984, 0), (0.39125258, 0), (0.36546627, 1), (0.30643606, 0), (0.30368266, 0), (0.30136907, 0), (0.0, 0)]
0.4
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235038AA828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/97 [=========================&gt;....] - ETA: 0s - loss: 0.6700 - auc: 0.5582WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235594A7948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.6697 - auc: 0.5490 - val_loss: 0.5259 - val_auc: 0.5085
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5809 - auc: 0.6015 - val_loss: 0.5667 - val_auc: 0.4519
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5681 - auc: 0.5962 - val_loss: 0.5458 - val_auc: 0.5741
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5470 - auc: 0.6219 - val_loss: 0.4992 - val_auc: 0.5598
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5366 - auc: 0.6395 - val_loss: 0.4467 - val_auc: 0.5344
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5397 - auc: 0.5918 - val_loss: 0.4121 - val_auc: 0.7101
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5130 - auc: 0.6623 - val_loss: 0.4007 - val_auc: 0.5513
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5212 - auc: 0.6578 - val_loss: 0.3562 - val_auc: 0.6587
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5151 - auc: 0.6453 - val_loss: 0.3524 - val_auc: 0.6439
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6890 - val_loss: 0.3216 - val_auc: 0.6508
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5084 - auc: 0.6561 - val_loss: 0.3416 - val_auc: 0.5963
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6855 - val_loss: 0.3104 - val_auc: 0.6418
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4919 - auc: 0.6913 - val_loss: 0.3260 - val_auc: 0.6360
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4973 - auc: 0.6945 - val_loss: 0.3041 - val_auc: 0.7212
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6610 - val_loss: 0.3372 - val_auc: 0.6571
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6959 - val_loss: 0.3189 - val_auc: 0.6889
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.6900 - val_loss: 0.3198 - val_auc: 0.6746
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4940 - auc: 0.6898 - val_loss: 0.3029 - val_auc: 0.7143
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6982 - val_loss: 0.3082 - val_auc: 0.7000
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.7012 - val_loss: 0.3449 - val_auc: 0.5984
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235028BAD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.78057456, 0), (0.77802813, 0), (0.7761398, 0), (0.7729675, 0), (0.7716291, 0), (0.77157855, 0), (0.770571, 0), (0.7702153, 0), (0.7647248, 0), (0.7635203, 0), (0.7588367, 0), (0.75855154, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 1), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.7584736, 0), (0.72493154, 0), (0.72410375, 0), (0.6904027, 0), (0.68569225, 0), (0.67971706, 1), (0.6688079, 0), (0.6550657, 1), (0.6533813, 0), (0.6378767, 1), (0.62359524, 0), (0.6025832, 0), (0.41647944, 0), (0.35768387, 0), (0.32049665, 0), (0.301302, 0), (0.277031, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235084C13A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/97 [=========================&gt;....] - ETA: 0s - loss: 0.5256 - auc: 0.5983WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350373A948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5251 - auc: 0.6140 - val_loss: 0.2608 - val_auc: 0.5862
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5059 - auc: 0.6366 - val_loss: 0.2626 - val_auc: 0.6402
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5242 - auc: 0.6347 - val_loss: 0.2586 - val_auc: 0.6402
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5198 - auc: 0.6412 - val_loss: 0.2387 - val_auc: 0.6899
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5176 - auc: 0.6089 - val_loss: 0.2063 - val_auc: 0.6963
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5195 - auc: 0.6274 - val_loss: 0.2549 - val_auc: 0.6153
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5171 - auc: 0.6492 - val_loss: 0.2401 - val_auc: 0.6127
Epoch 8/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4960 - auc: 0.6937 - val_loss: 0.2596 - val_auc: 0.6820
Epoch 9/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5064 - auc: 0.6755 - val_loss: 0.2740 - val_auc: 0.5757
Epoch 10/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4992 - auc: 0.6830 - val_loss: 0.2584 - val_auc: 0.5376
Epoch 11/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5042 - auc: 0.6800 - val_loss: 0.2660 - val_auc: 0.5238
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4996 - auc: 0.6848 - val_loss: 0.2624 - val_auc: 0.5042
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.7162 - val_loss: 0.2694 - val_auc: 0.5058
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4990 - auc: 0.6968 - val_loss: 0.2839 - val_auc: 0.5296
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.7121 - val_loss: 0.2710 - val_auc: 0.4963
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6812 - val_loss: 0.2790 - val_auc: 0.4847
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.7044 - val_loss: 0.2759 - val_auc: 0.5989
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4833 - auc: 0.7092 - val_loss: 0.2730 - val_auc: 0.5571
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.7200 - val_loss: 0.2815 - val_auc: 0.4831
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.7086 - val_loss: 0.2853 - val_auc: 0.6175
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350381EC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7951419, 0), (0.778323, 1), (0.6849226, 0), (0.6783971, 0), (0.6253394, 0), (0.60620856, 0), (0.59233314, 0), (0.59149003, 0), (0.5874888, 0), (0.5385143, 0), (0.51502895, 0), (0.5143693, 1), (0.51242614, 0), (0.48448178, 0), (0.4821842, 0), (0.47820702, 0), (0.4766751, 0), (0.46821338, 0), (0.46820033, 1), (0.46724436, 0), (0.46560356, 0), (0.46435928, 0), (0.46168855, 0), (0.4604528, 0), (0.4592987, 0), (0.4494756, 0), (0.4482556, 0), (0.44503963, 0), (0.44447556, 0), (0.44424197, 0), (0.44324675, 0), (0.44308597, 0), (0.4422169, 0), (0.44176605, 0), (0.44127235, 0), (0.44048592, 0), (0.4398271, 1), (0.43971783, 0), (0.43782353, 0), (0.43690032, 0), (0.43690032, 0), (0.4135434, 0), (0.36309427, 0), (0.283819, 0), (0.275964, 0), (0.26868, 0), (0.26841238, 0), (0.21666631, 0), (0.2117207, 1), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500ACB318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/97 [=========================&gt;....] - ETA: 0s - loss: 0.7868 - auc: 0.5331WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235027290D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 7ms/step - loss: 0.7799 - auc: 0.5290 - val_loss: 0.5920 - val_auc: 0.5905
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6466 - auc: 0.5861 - val_loss: 0.4213 - val_auc: 0.5677
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5778 - auc: 0.6351 - val_loss: 0.4206 - val_auc: 0.7026
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5838 - auc: 0.6023 - val_loss: 0.4975 - val_auc: 0.6376
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5726 - auc: 0.6159 - val_loss: 0.5221 - val_auc: 0.6127
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5530 - auc: 0.6252 - val_loss: 0.4725 - val_auc: 0.8021
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5481 - auc: 0.6200 - val_loss: 0.5403 - val_auc: 0.7302
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5327 - auc: 0.6283 - val_loss: 0.4468 - val_auc: 0.7926
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6799 - val_loss: 0.4113 - val_auc: 0.7106
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5222 - auc: 0.6632 - val_loss: 0.3760 - val_auc: 0.7349
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6992 - val_loss: 0.3702 - val_auc: 0.6762
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5184 - auc: 0.6700 - val_loss: 0.3873 - val_auc: 0.8111
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6975 - val_loss: 0.3649 - val_auc: 0.6026
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5125 - auc: 0.6782 - val_loss: 0.3515 - val_auc: 0.7302
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5100 - auc: 0.6693 - val_loss: 0.3769 - val_auc: 0.6524
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6909 - val_loss: 0.3515 - val_auc: 0.6566
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4960 - auc: 0.7132 - val_loss: 0.3578 - val_auc: 0.6418
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.7117 - val_loss: 0.3723 - val_auc: 0.6111
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4870 - auc: 0.7224 - val_loss: 0.3579 - val_auc: 0.5762
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.7292 - val_loss: 0.3773 - val_auc: 0.5857
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235076E18B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7265627, 0), (0.7221998, 0), (0.7214307, 0), (0.7156265, 0), (0.71512574, 0), (0.7139317, 0), (0.70278054, 0), (0.697072, 0), (0.6964868, 0), (0.6939342, 0), (0.69214803, 0), (0.6874563, 0), (0.6870482, 0), (0.6864645, 0), (0.68614775, 0), (0.6858814, 0), (0.67125446, 0), (0.6700757, 0), (0.6694548, 0), (0.6493688, 1), (0.6443337, 1), (0.6402761, 1), (0.6366439, 1), (0.63395154, 1), (0.627579, 0), (0.6200777, 0), (0.61816496, 0), (0.610778, 0), (0.60359955, 0), (0.5802742, 0), (0.56169695, 0), (0.54037017, 0), (0.5382138, 0), (0.52911615, 0), (0.51909024, 1), (0.510458, 0), (0.499923, 0), (0.49439564, 0), (0.45345694, 0), (0.44955024, 0), (0.42914793, 0), (0.41828373, 0), (0.3756961, 0), (0.3745474, 0), (0.353901, 0), (0.3373707, 0), (0.32583347, 0), (0.18377252, 0), (0.15750965, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDBC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
94/97 [============================&gt;.] - ETA: 0s - loss: 0.5431 - auc: 0.5120WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350382C798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 7ms/step - loss: 0.5430 - auc: 0.5112 - val_loss: 0.3094 - val_auc: 0.6392
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5303 - auc: 0.5588 - val_loss: 0.3112 - val_auc: 0.4979
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5184 - auc: 0.6209 - val_loss: 0.2953 - val_auc: 0.6460
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6636 - val_loss: 0.2977 - val_auc: 0.5222
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5217 - auc: 0.6122 - val_loss: 0.2735 - val_auc: 0.4947
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4996 - auc: 0.6608 - val_loss: 0.2701 - val_auc: 0.5270
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6839 - val_loss: 0.2843 - val_auc: 0.5566
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6590 - val_loss: 0.2792 - val_auc: 0.5169
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4924 - auc: 0.6818 - val_loss: 0.2727 - val_auc: 0.5312
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4879 - auc: 0.6835 - val_loss: 0.2862 - val_auc: 0.5735
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6967 - val_loss: 0.3005 - val_auc: 0.6529
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.6845 - val_loss: 0.2723 - val_auc: 0.6069
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5156 - auc: 0.6236 - val_loss: 0.2911 - val_auc: 0.5582
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.7165 - val_loss: 0.2837 - val_auc: 0.5889
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4901 - auc: 0.6940 - val_loss: 0.2837 - val_auc: 0.7053
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7086 - val_loss: 0.2780 - val_auc: 0.4810
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5025 - auc: 0.6682 - val_loss: 0.2853 - val_auc: 0.4857
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4784 - auc: 0.6994 - val_loss: 0.2905 - val_auc: 0.4772
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6898 - val_loss: 0.2899 - val_auc: 0.4042
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4937 - auc: 0.6921 - val_loss: 0.3078 - val_auc: 0.4608
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502337558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8821493, 0), (0.8144659, 1), (0.75238657, 1), (0.7299311, 0), (0.6813556, 0), (0.6496661, 1), (0.6472077, 1), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 1), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 1), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 1), (0.6446897, 1), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 1), (0.6446897, 0), (0.6446897, 0), (0.6446897, 0), (0.6446897, 1), (0.6446897, 0), (0.6446897, 0), (0.64284235, 0), (0.6408102, 0), (0.6199318, 1), (0.5930601, 0), (0.4879247, 0), (0.46662712, 0), (0.4416072, 0), (0.44116685, 0), (0.43739718, 0), (0.35146534, 0), (0.3105501, 0), (0.16266751, 0), (0.0, 0)]
0.4
0.18181818181818182
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023E0678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
84/97 [========================&gt;.....] - ETA: 0s - loss: 0.6209 - auc: 0.4625WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503C90E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 7ms/step - loss: 0.6169 - auc: 0.4714 - val_loss: 0.5092 - val_auc: 0.5212
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5305 - auc: 0.5998 - val_loss: 0.3998 - val_auc: 0.6693
Epoch 3/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5167 - auc: 0.6193 - val_loss: 0.3852 - val_auc: 0.5947
Epoch 4/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5054 - auc: 0.6651 - val_loss: 0.4318 - val_auc: 0.4169
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6736 - val_loss: 0.3944 - val_auc: 0.4153
Epoch 6/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5158 - auc: 0.6276 - val_loss: 0.3675 - val_auc: 0.5429
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6820 - val_loss: 0.3368 - val_auc: 0.6180
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6522 - val_loss: 0.3539 - val_auc: 0.6952
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.7143 - val_loss: 0.3285 - val_auc: 0.7550
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4817 - auc: 0.7156 - val_loss: 0.2747 - val_auc: 0.8153
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.7097 - val_loss: 0.2954 - val_auc: 0.7238
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4694 - auc: 0.7339 - val_loss: 0.3086 - val_auc: 0.6667
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.6970 - val_loss: 0.3216 - val_auc: 0.6519
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4741 - auc: 0.7369 - val_loss: 0.3032 - val_auc: 0.6587
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4699 - auc: 0.7188 - val_loss: 0.2974 - val_auc: 0.6280
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4699 - auc: 0.7311 - val_loss: 0.3200 - val_auc: 0.6333
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7156 - val_loss: 0.3280 - val_auc: 0.6429
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.7175 - val_loss: 0.3121 - val_auc: 0.6746
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4739 - auc: 0.7179 - val_loss: 0.3345 - val_auc: 0.6376
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4620 - auc: 0.7403 - val_loss: 0.2866 - val_auc: 0.6296
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508324C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.99832284, 0), (0.9726757, 0), (0.97233254, 0), (0.9648078, 0), (0.95312566, 0), (0.9387215, 1), (0.93424904, 1), (0.9226476, 0), (0.91358787, 1), (0.9021381, 0), (0.8925936, 0), (0.88259983, 0), (0.881275, 0), (0.87896216, 0), (0.87501615, 0), (0.86633235, 0), (0.86403316, 1), (0.8634073, 1), (0.8625025, 0), (0.8544143, 0), (0.8533859, 0), (0.84413236, 0), (0.8327402, 0), (0.82678574, 0), (0.79708564, 1), (0.79017574, 1), (0.77715695, 1), (0.7679945, 1), (0.7345898, 0), (0.72749096, 1), (0.7130909, 0), (0.71032995, 0), (0.70693135, 0), (0.698009, 0), (0.6149747, 0), (0.586044, 0), (0.56535757, 0), (0.5511259, 0), (0.5304298, 0), (0.49314004, 0), (0.47762424, 0), (0.4448995, 0), (0.3383668, 0), (0.29621407, 0), (0.2923729, 1), (0.27701315, 1), (0.25533232, 0), (0.25460097, 1), (0.18917802, 0), (0.0, 0)]
0.2
0.07142857142857142
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350240B288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
84/97 [========================&gt;.....] - ETA: 0s - loss: 0.5673 - auc: 0.4909 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023508324948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 7ms/step - loss: 0.5711 - auc: 0.5131 - val_loss: 0.3454 - val_auc: 0.5101
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5584 - auc: 0.5483 - val_loss: 0.3546 - val_auc: 0.5187
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5138 - auc: 0.6306 - val_loss: 0.3385 - val_auc: 0.4894
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5151 - auc: 0.6613 - val_loss: 0.3088 - val_auc: 0.4505
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5101 - auc: 0.6601 - val_loss: 0.3431 - val_auc: 0.5690
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5039 - auc: 0.6570 - val_loss: 0.3176 - val_auc: 0.5668
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6738 - val_loss: 0.3068 - val_auc: 0.4935
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5100 - auc: 0.6569 - val_loss: 0.3049 - val_auc: 0.5641
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4941 - auc: 0.6820 - val_loss: 0.3189 - val_auc: 0.5348
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5098 - auc: 0.6636 - val_loss: 0.3180 - val_auc: 0.4402
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6688 - val_loss: 0.3196 - val_auc: 0.5101
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5075 - auc: 0.6630 - val_loss: 0.3203 - val_auc: 0.6152
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6756 - val_loss: 0.3044 - val_auc: 0.6095
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5052 - auc: 0.6802 - val_loss: 0.3219 - val_auc: 0.5986
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4879 - auc: 0.7106 - val_loss: 0.2904 - val_auc: 0.6769
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.7218 - val_loss: 0.2989 - val_auc: 0.6546
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6717 - val_loss: 0.2992 - val_auc: 0.6573
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6925 - val_loss: 0.3234 - val_auc: 0.5886
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5055 - auc: 0.6746 - val_loss: 0.2988 - val_auc: 0.4954
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6975 - val_loss: 0.3086 - val_auc: 0.5764
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235023E0A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99976826, 0), (0.94935185, 0), (0.9103683, 0), (0.8825765, 0), (0.8795021, 0), (0.857391, 1), (0.8380885, 0), (0.83450526, 0), (0.830021, 0), (0.82813144, 0), (0.8249734, 0), (0.81168014, 0), (0.8068674, 0), (0.80472594, 0), (0.7984629, 0), (0.79468167, 1), (0.79193, 0), (0.79015553, 0), (0.7743244, 0), (0.7741024, 0), (0.7597893, 0), (0.7589789, 0), (0.75342995, 0), (0.7513257, 0), (0.7493333, 0), (0.7472662, 0), (0.7324394, 0), (0.73057944, 0), (0.71651167, 0), (0.7158888, 0), (0.66669744, 0), (0.66002756, 0), (0.6515406, 0), (0.6453296, 0), (0.63504314, 0), (0.5946944, 0), (0.59179646, 0), (0.5655074, 0), (0.5460072, 0), (0.51193863, 0), (0.4984911, 0), (0.43187284, 0), (0.42617837, 0), (0.41674638, 0), (0.41253862, 0), (0.4035163, 0), (0.31980303, 0), (0.28790724, 0), (0.22109416, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502337C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/97 [==========================&gt;...] - ETA: 0s - loss: 0.5281 - auc: 0.5821WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502729F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5350 - auc: 0.5762 - val_loss: 0.2711 - val_auc: 0.4619
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5447 - auc: 0.5611 - val_loss: 0.2971 - val_auc: 0.4323
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5140 - auc: 0.6087 - val_loss: 0.2824 - val_auc: 0.4868
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.6379 - val_loss: 0.2916 - val_auc: 0.5815
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5115 - auc: 0.6348 - val_loss: 0.2944 - val_auc: 0.6238
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5158 - auc: 0.6359 - val_loss: 0.2997 - val_auc: 0.5799
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6816 - val_loss: 0.2837 - val_auc: 0.6698
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6995 - val_loss: 0.2712 - val_auc: 0.6127
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6614 - val_loss: 0.2801 - val_auc: 0.5698
Epoch 10/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5051 - auc: 0.6641 - val_loss: 0.2777 - val_auc: 0.6011
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6649 - val_loss: 0.2918 - val_auc: 0.4566
Epoch 12/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5043 - auc: 0.6867 - val_loss: 0.2994 - val_auc: 0.5667
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4886 - auc: 0.6925 - val_loss: 0.2773 - val_auc: 0.6143
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6760 - val_loss: 0.2793 - val_auc: 0.6741
Epoch 15/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4850 - auc: 0.7063 - val_loss: 0.2757 - val_auc: 0.7032
Epoch 16/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5134 - auc: 0.6833 - val_loss: 0.2943 - val_auc: 0.7471
Epoch 17/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4755 - auc: 0.7287 - val_loss: 0.2800 - val_auc: 0.6497
Epoch 18/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4895 - auc: 0.6934 - val_loss: 0.2616 - val_auc: 0.7190
Epoch 19/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4965 - auc: 0.6910 - val_loss: 0.2802 - val_auc: 0.7175
Epoch 20/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5046 - auc: 0.6840 - val_loss: 0.2919 - val_auc: 0.7090
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350A17FD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9214268, 1), (0.87402546, 0), (0.8739082, 1), (0.86448854, 0), (0.85781026, 1), (0.8504377, 0), (0.8406924, 0), (0.8329349, 0), (0.8329349, 1), (0.8298413, 0), (0.82855844, 0), (0.82140857, 0), (0.82135564, 0), (0.8199863, 0), (0.81852543, 0), (0.81267756, 0), (0.8104195, 0), (0.80605376, 0), (0.8057464, 0), (0.8049806, 0), (0.80356765, 0), (0.80172527, 1), (0.7964059, 1), (0.79617685, 0), (0.7958581, 0), (0.7946574, 1), (0.7937276, 0), (0.7895164, 0), (0.7886632, 0), (0.78795695, 0), (0.78757566, 0), (0.7815623, 0), (0.7691338, 0), (0.76876014, 0), (0.74452955, 0), (0.7434612, 0), (0.7395816, 0), (0.7391574, 0), (0.709797, 0), (0.6774556, 0), (0.6605839, 0), (0.6211373, 0), (0.59599096, 0), (0.58492905, 0), (0.54796046, 0), (0.53574276, 0), (0.46111995, 1), (0.42633402, 0), (0.39206132, 0), (0.0, 0)]
0.4
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235076FD8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.6395 - auc: 0.5001WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503C84948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 10ms/step - loss: 0.6385 - auc: 0.4961 - val_loss: 0.5587 - val_auc: 0.5741
Epoch 2/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5419 - auc: 0.6020 - val_loss: 0.4558 - val_auc: 0.6614
Epoch 3/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5389 - auc: 0.6037 - val_loss: 0.3766 - val_auc: 0.5847
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5207 - auc: 0.6385 - val_loss: 0.4017 - val_auc: 0.6106
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6759 - val_loss: 0.3900 - val_auc: 0.5153
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6505 - val_loss: 0.3368 - val_auc: 0.5698
Epoch 7/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4945 - auc: 0.6872 - val_loss: 0.3174 - val_auc: 0.5942
Epoch 8/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4936 - auc: 0.6827 - val_loss: 0.3635 - val_auc: 0.5164
Epoch 9/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4820 - auc: 0.6983 - val_loss: 0.3387 - val_auc: 0.5397
Epoch 10/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4858 - auc: 0.6747 - val_loss: 0.3146 - val_auc: 0.5989
Epoch 11/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4931 - auc: 0.6874 - val_loss: 0.3215 - val_auc: 0.6307
Epoch 12/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4821 - auc: 0.7049 - val_loss: 0.3476 - val_auc: 0.6735
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4707 - auc: 0.7139 - val_loss: 0.3266 - val_auc: 0.6233
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4747 - auc: 0.7174 - val_loss: 0.3244 - val_auc: 0.5915
Epoch 15/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4825 - auc: 0.7081 - val_loss: 0.3142 - val_auc: 0.5444
Epoch 16/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4792 - auc: 0.7151 - val_loss: 0.3057 - val_auc: 0.5820
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4711 - auc: 0.7213 - val_loss: 0.2687 - val_auc: 0.6460
Epoch 18/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4700 - auc: 0.7191 - val_loss: 0.3230 - val_auc: 0.6069
Epoch 19/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4705 - auc: 0.7260 - val_loss: 0.2942 - val_auc: 0.6529
Epoch 20/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4744 - auc: 0.7177 - val_loss: 0.3089 - val_auc: 0.6429
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235048A43A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9938395, 0), (0.9819766, 0), (0.9353849, 1), (0.92880064, 0), (0.870588, 0), (0.8142487, 1), (0.80665684, 0), (0.7781647, 1), (0.7485536, 0), (0.7465341, 0), (0.743411, 0), (0.74157774, 0), (0.73832804, 1), (0.7362987, 0), (0.73302454, 0), (0.7188481, 0), (0.7139454, 1), (0.7065478, 0), (0.6978101, 0), (0.6936265, 1), (0.6885373, 0), (0.68344545, 0), (0.6751875, 0), (0.67464024, 0), (0.67375374, 1), (0.67054546, 1), (0.656748, 1), (0.65409404, 0), (0.6421915, 0), (0.63546777, 1), (0.62231135, 0), (0.61933047, 1), (0.59276646, 0), (0.58917964, 0), (0.5487427, 1), (0.52895796, 0), (0.48152536, 0), (0.47436276, 0), (0.4714172, 0), (0.4661472, 0), (0.40452906, 1), (0.38678777, 0), (0.36752513, 0), (0.36661196, 0), (0.35453245, 0), (0.29976016, 0), (0.2885563, 0), (0.26931834, 0), (0.2641239, 1), (0.0, 0)]
0.2
0.07142857142857142
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
93/97 [===========================&gt;..] - ETA: 0s - loss: 0.5986 - auc: 0.5174WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502337678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 8ms/step - loss: 0.5929 - auc: 0.5234 - val_loss: 0.3471 - val_auc: 0.5037
Epoch 2/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5581 - auc: 0.5559 - val_loss: 0.3316 - val_auc: 0.4503
Epoch 3/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5262 - auc: 0.6200 - val_loss: 0.3512 - val_auc: 0.5095
Epoch 4/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5340 - auc: 0.5903 - val_loss: 0.3313 - val_auc: 0.4820
Epoch 5/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5157 - auc: 0.6430 - val_loss: 0.3245 - val_auc: 0.4667
Epoch 6/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5172 - auc: 0.6389 - val_loss: 0.3267 - val_auc: 0.4582
Epoch 7/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5173 - auc: 0.6141 - val_loss: 0.2931 - val_auc: 0.6032
Epoch 8/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5141 - auc: 0.6433 - val_loss: 0.3357 - val_auc: 0.6995
Epoch 9/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5078 - auc: 0.6406 - val_loss: 0.3124 - val_auc: 0.6312
Epoch 10/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5002 - auc: 0.6676 - val_loss: 0.3209 - val_auc: 0.6730
Epoch 11/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5149 - auc: 0.6427 - val_loss: 0.3178 - val_auc: 0.7603
Epoch 12/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5153 - auc: 0.6364 - val_loss: 0.3315 - val_auc: 0.6000
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5099 - auc: 0.6484 - val_loss: 0.3000 - val_auc: 0.6339
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6888 - val_loss: 0.3248 - val_auc: 0.6159
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5139 - auc: 0.6538 - val_loss: 0.3279 - val_auc: 0.5450
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6509 - val_loss: 0.3014 - val_auc: 0.6640
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4978 - auc: 0.6861 - val_loss: 0.3171 - val_auc: 0.5725
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6730 - val_loss: 0.3245 - val_auc: 0.6201
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6648 - val_loss: 0.3112 - val_auc: 0.5815
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5127 - auc: 0.6880 - val_loss: 0.3096 - val_auc: 0.6423
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235038CF798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.995985, 0), (0.99301726, 0), (0.98905957, 0), (0.98524517, 0), (0.9818137, 0), (0.97881055, 0), (0.97881055, 1), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.97881055, 1), (0.97881055, 0), (0.97881055, 0), (0.97881055, 0), (0.9757824, 0), (0.9697906, 0), (0.95903695, 1), (0.9535076, 0), (0.9531953, 0), (0.9494291, 0), (0.94637024, 0), (0.9135067, 0), (0.9072504, 0), (0.9005577, 0), (0.8990076, 0), (0.8987009, 0), (0.8984026, 0), (0.8804686, 0), (0.8775507, 0), (0.8705592, 0), (0.8634644, 0), (0.8462749, 0), (0.8448504, 0), (0.6954585, 0), (0.6449948, 0), (0.5644232, 0), (0.5218211, 0), (0.4986064, 0), (0.40492243, 0), (0.33712223, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023509909DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/97 [=========================&gt;....] - ETA: 0s - loss: 0.6141 - auc: 0.5041WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235043CBCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 7ms/step - loss: 0.6057 - auc: 0.5130 - val_loss: 0.4198 - val_auc: 0.4630
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5268 - auc: 0.6155 - val_loss: 0.3914 - val_auc: 0.4889
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5362 - auc: 0.6126 - val_loss: 0.4165 - val_auc: 0.5068
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5244 - auc: 0.6282 - val_loss: 0.3599 - val_auc: 0.4378
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5195 - auc: 0.6509 - val_loss: 0.3594 - val_auc: 0.4818
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6783 - val_loss: 0.3578 - val_auc: 0.4780
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.6772 - val_loss: 0.3702 - val_auc: 0.4666
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6706 - val_loss: 0.3139 - val_auc: 0.5168
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6855 - val_loss: 0.3214 - val_auc: 0.4894
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.7037 - val_loss: 0.3316 - val_auc: 0.5122
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.7044 - val_loss: 0.3289 - val_auc: 0.4932
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6910 - val_loss: 0.3210 - val_auc: 0.4766
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.7079 - val_loss: 0.3567 - val_auc: 0.5144
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.7106 - val_loss: 0.3063 - val_auc: 0.4823
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7151 - val_loss: 0.3479 - val_auc: 0.4410
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.7077 - val_loss: 0.3268 - val_auc: 0.4788
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4873 - auc: 0.6864 - val_loss: 0.3438 - val_auc: 0.4774
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.7008 - val_loss: 0.3238 - val_auc: 0.4734
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7293 - val_loss: 0.3168 - val_auc: 0.4796
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4824 - auc: 0.7259 - val_loss: 0.3141 - val_auc: 0.4954
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350440B4C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8366895, 0), (0.80196995, 0), (0.73683065, 0), (0.6833523, 0), (0.6487118, 0), (0.64047223, 0), (0.61037105, 0), (0.5987137, 0), (0.594317, 0), (0.5803427, 0), (0.5674108, 1), (0.56633145, 0), (0.56269634, 0), (0.5568017, 0), (0.5554611, 0), (0.5519967, 0), (0.5476301, 0), (0.5475339, 0), (0.5469518, 0), (0.54689425, 0), (0.542195, 1), (0.53466517, 0), (0.51992583, 0), (0.51352686, 0), (0.5089528, 0), (0.49669328, 0), (0.4831731, 0), (0.4830761, 0), (0.48233673, 0), (0.4515389, 0), (0.45090476, 0), (0.45001116, 0), (0.44255486, 0), (0.4132366, 0), (0.4108345, 0), (0.40614465, 0), (0.3825901, 0), (0.35799208, 0), (0.35347888, 0), (0.35137144, 0), (0.35030764, 0), (0.34869418, 0), (0.289896, 0), (0.28858554, 0), (0.27227235, 0), (0.2559612, 0), (0.2452292, 0), (0.21899126, 0), (0.13817309, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558A4E438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/97 [==========================&gt;...] - ETA: 0s - loss: 0.6235 - auc: 0.4964WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB7AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.6232 - auc: 0.4984 - val_loss: 0.5230 - val_auc: 0.5291
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5439 - auc: 0.5816 - val_loss: 0.4268 - val_auc: 0.5783
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5255 - auc: 0.6120 - val_loss: 0.3778 - val_auc: 0.5206
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6298 - val_loss: 0.3856 - val_auc: 0.4418
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6648 - val_loss: 0.3603 - val_auc: 0.6296
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6539 - val_loss: 0.3272 - val_auc: 0.3407
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6441 - val_loss: 0.3413 - val_auc: 0.3434
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.6667 - val_loss: 0.3148 - val_auc: 0.3751
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.6851 - val_loss: 0.2854 - val_auc: 0.4529
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.7080 - val_loss: 0.2531 - val_auc: 0.5386
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.6843 - val_loss: 0.2991 - val_auc: 0.4630
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.6906 - val_loss: 0.2918 - val_auc: 0.5265
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.6926 - val_loss: 0.2830 - val_auc: 0.4931
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.6810 - val_loss: 0.3065 - val_auc: 0.4635
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4693 - auc: 0.7053 - val_loss: 0.2884 - val_auc: 0.5608
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4571 - auc: 0.7261 - val_loss: 0.2821 - val_auc: 0.5074
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4703 - auc: 0.7273 - val_loss: 0.2761 - val_auc: 0.4804
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4717 - auc: 0.7179 - val_loss: 0.2966 - val_auc: 0.4492
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4765 - auc: 0.7072 - val_loss: 0.2908 - val_auc: 0.5233
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.6923 - val_loss: 0.2802 - val_auc: 0.6132
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB9D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98515767, 1), (0.9562339, 1), (0.9007283, 1), (0.87645483, 0), (0.82453513, 0), (0.8156975, 0), (0.7874612, 0), (0.77152985, 1), (0.7670577, 0), (0.762556, 0), (0.75683963, 0), (0.7557013, 1), (0.7306447, 1), (0.72581077, 0), (0.7257056, 1), (0.7174144, 1), (0.7163992, 0), (0.7152787, 1), (0.7142416, 0), (0.71132034, 0), (0.70896655, 0), (0.6952598, 0), (0.68479544, 1), (0.68356687, 1), (0.6807112, 1), (0.6663235, 1), (0.66563994, 0), (0.653863, 1), (0.6464602, 0), (0.6437848, 0), (0.6432662, 0), (0.63505226, 1), (0.6337536, 0), (0.608107, 0), (0.5999325, 0), (0.5987344, 0), (0.5939642, 0), (0.5781512, 0), (0.54487246, 1), (0.53708154, 0), (0.53267264, 0), (0.5024539, 0), (0.4377594, 1), (0.42333832, 0), (0.26849827, 0), (0.26575133, 0), (0.23216718, 0), (0.15445198, 0), (0.15034561, 1), (0.0, 0)]
0.6
0.16666666666666666
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235099095E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/97 [==========================&gt;...] - ETA: 0s - loss: 0.6142 - auc: 0.5210 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023508324828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.6069 - auc: 0.5284 - val_loss: 0.3963 - val_auc: 0.5442
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5669 - auc: 0.5621 - val_loss: 0.4426 - val_auc: 0.5633
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5457 - auc: 0.5814 - val_loss: 0.3509 - val_auc: 0.4620
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5413 - auc: 0.5904 - val_loss: 0.3572 - val_auc: 0.4468
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5284 - auc: 0.6095 - val_loss: 0.3472 - val_auc: 0.5204
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5193 - auc: 0.6233 - val_loss: 0.3412 - val_auc: 0.5482
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.6528 - val_loss: 0.3381 - val_auc: 0.5482
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6726 - val_loss: 0.3131 - val_auc: 0.4998
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5295 - auc: 0.6293 - val_loss: 0.3264 - val_auc: 0.4630
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6560 - val_loss: 0.2960 - val_auc: 0.5378
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6705 - val_loss: 0.2889 - val_auc: 0.5517
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6445 - val_loss: 0.3061 - val_auc: 0.5529
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.6831 - val_loss: 0.2933 - val_auc: 0.5291
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6615 - val_loss: 0.3172 - val_auc: 0.5219
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6740 - val_loss: 0.2985 - val_auc: 0.5325
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6778 - val_loss: 0.2971 - val_auc: 0.5467
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4992 - auc: 0.6931 - val_loss: 0.2956 - val_auc: 0.4856
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4989 - auc: 0.6945 - val_loss: 0.2949 - val_auc: 0.5241
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4873 - auc: 0.6881 - val_loss: 0.3024 - val_auc: 0.5181
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.7187 - val_loss: 0.2833 - val_auc: 0.4784
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350846EDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.875602, 0), (0.8435108, 0), (0.8241878, 0), (0.8029011, 0), (0.7988428, 0), (0.7883792, 0), (0.78790414, 0), (0.77693725, 0), (0.77334815, 0), (0.77300376, 0), (0.7698639, 1), (0.7651208, 0), (0.7570329, 0), (0.7523573, 0), (0.7358359, 0), (0.73360837, 0), (0.73360837, 0), (0.73360837, 0), (0.7328255, 0), (0.72831225, 0), (0.7261406, 0), (0.71667796, 0), (0.7157876, 0), (0.7145724, 0), (0.7033958, 0), (0.7012298, 0), (0.69542116, 0), (0.68940985, 0), (0.68727916, 0), (0.6853045, 0), (0.6841946, 0), (0.680585, 0), (0.67992944, 0), (0.6740614, 0), (0.65831286, 0), (0.6472631, 0), (0.6235235, 0), (0.62169, 0), (0.6185509, 0), (0.56251353, 0), (0.50369096, 0), (0.4380104, 0), (0.4188994, 0), (0.35222027, 0), (0.3519379, 0), (0.32688504, 0), (0.29293346, 0), (0.29063806, 0), (0.24891745, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350769D168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/97 [=========================&gt;....] - ETA: 0s - loss: 0.6404 - auc: 0.5186WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 7ms/step - loss: 0.6218 - auc: 0.5324 - val_loss: 0.5130 - val_auc: 0.6476
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5343 - auc: 0.6311 - val_loss: 0.4980 - val_auc: 0.4794
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5327 - auc: 0.6237 - val_loss: 0.4423 - val_auc: 0.5317
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5254 - auc: 0.6129 - val_loss: 0.3295 - val_auc: 0.5836
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6941 - val_loss: 0.3531 - val_auc: 0.6862
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6589 - val_loss: 0.3747 - val_auc: 0.5307
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5051 - auc: 0.6514 - val_loss: 0.3626 - val_auc: 0.6053
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4827 - auc: 0.6809 - val_loss: 0.3903 - val_auc: 0.5011
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6775 - val_loss: 0.3619 - val_auc: 0.5233
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.6852 - val_loss: 0.3541 - val_auc: 0.5037
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5062 - auc: 0.6394 - val_loss: 0.3350 - val_auc: 0.6889
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4854 - auc: 0.6969 - val_loss: 0.3390 - val_auc: 0.6243
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.7171 - val_loss: 0.3326 - val_auc: 0.6370
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4774 - auc: 0.7138 - val_loss: 0.3232 - val_auc: 0.5889
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4780 - auc: 0.7094 - val_loss: 0.3404 - val_auc: 0.6386
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.6857 - val_loss: 0.3332 - val_auc: 0.5275
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7147 - val_loss: 0.3266 - val_auc: 0.5593
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4833 - auc: 0.7109 - val_loss: 0.3280 - val_auc: 0.5328
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4989 - auc: 0.6938 - val_loss: 0.3193 - val_auc: 0.5370
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.7139 - val_loss: 0.3258 - val_auc: 0.5603
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350A052D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.979403, 1), (0.9323749, 0), (0.8917798, 0), (0.8876168, 0), (0.8766394, 1), (0.8754538, 0), (0.8745337, 0), (0.87333053, 0), (0.87272954, 0), (0.86985624, 1), (0.8673651, 0), (0.86569726, 0), (0.8643118, 0), (0.8598171, 0), (0.8594756, 1), (0.85914034, 1), (0.8578347, 0), (0.85665536, 0), (0.85476196, 1), (0.8507814, 0), (0.8488703, 0), (0.84840393, 0), (0.8473864, 0), (0.8469755, 1), (0.845252, 0), (0.84356093, 1), (0.8432313, 1), (0.8354266, 0), (0.83520263, 0), (0.8326539, 0), (0.8233188, 0), (0.81556153, 0), (0.8138341, 1), (0.8010162, 0), (0.7724152, 0), (0.7274946, 0), (0.689056, 0), (0.6854553, 1), (0.6630183, 0), (0.65310687, 0), (0.60693127, 0), (0.5850665, 0), (0.55678016, 0), (0.48452732, 0), (0.42136922, 0), (0.39670178, 1), (0.26982176, 1), (0.25410903, 0), (0.19887586, 0), (0.0, 0)]
0.2
0.07692307692307693
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503067558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
92/97 [===========================&gt;..] - ETA: 0s - loss: 0.5790 - auc: 0.5062WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.5783 - auc: 0.5122 - val_loss: 0.3775 - val_auc: 0.8063
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5284 - auc: 0.5233 - val_loss: 0.3749 - val_auc: 0.6540
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.5769 - val_loss: 0.4267 - val_auc: 0.5545
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.6388 - val_loss: 0.3764 - val_auc: 0.6524
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.6297 - val_loss: 0.3390 - val_auc: 0.6635
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4625 - auc: 0.6620 - val_loss: 0.3625 - val_auc: 0.7788
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.6121 - val_loss: 0.3052 - val_auc: 0.8212
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4798 - auc: 0.6277 - val_loss: 0.2850 - val_auc: 0.8032
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4673 - auc: 0.6627 - val_loss: 0.2823 - val_auc: 0.7725
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4623 - auc: 0.6692 - val_loss: 0.2749 - val_auc: 0.7529
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4571 - auc: 0.6752 - val_loss: 0.2779 - val_auc: 0.6614
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4561 - auc: 0.6796 - val_loss: 0.2661 - val_auc: 0.7090
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4579 - auc: 0.6873 - val_loss: 0.2918 - val_auc: 0.6667
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4467 - auc: 0.7070 - val_loss: 0.2595 - val_auc: 0.7016
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4631 - auc: 0.6831 - val_loss: 0.2686 - val_auc: 0.6894
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4561 - auc: 0.6943 - val_loss: 0.2664 - val_auc: 0.7164
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4515 - auc: 0.6978 - val_loss: 0.2673 - val_auc: 0.7450
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4511 - auc: 0.6975 - val_loss: 0.2795 - val_auc: 0.6455
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4581 - auc: 0.6800 - val_loss: 0.2717 - val_auc: 0.6476
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4572 - auc: 0.6846 - val_loss: 0.2779 - val_auc: 0.6460
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350769D8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.985681, 1), (0.91090155, 1), (0.8734441, 0), (0.84510297, 0), (0.83314943, 1), (0.8199965, 0), (0.8068656, 1), (0.80299324, 0), (0.79580086, 0), (0.79317224, 1), (0.7906899, 0), (0.7860098, 0), (0.7858663, 1), (0.78454936, 1), (0.7823863, 1), (0.77681637, 1), (0.77677685, 1), (0.7741234, 1), (0.77322114, 1), (0.77256435, 1), (0.77192456, 0), (0.7718671, 1), (0.76981556, 1), (0.7682208, 0), (0.76758087, 1), (0.76602924, 1), (0.7645293, 1), (0.74224585, 1), (0.7409317, 0), (0.7400057, 1), (0.73883414, 1), (0.7328222, 0), (0.7288665, 1), (0.64593893, 0), (0.6107078, 0), (0.60157174, 1), (0.55901927, 1), (0.51233864, 1), (0.43373752, 0), (0.42805701, 0), (0.42590964, 1), (0.42241675, 1), (0.41491172, 1), (0.39910507, 1), (0.3725584, 1), (0.2748785, 1), (0.2062093, 1), (0.014820323, 0), (0.010376647, 1), (0.0, 1)]
0.4
0.058823529411764705
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDB948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
93/97 [===========================&gt;..] - ETA: 0s - loss: 0.5548 - auc: 0.5245 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023508324048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5581 - auc: 0.5200 - val_loss: 0.3513 - val_auc: 0.5561
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5217 - auc: 0.6323 - val_loss: 0.2620 - val_auc: 0.5185
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5255 - auc: 0.6100 - val_loss: 0.3226 - val_auc: 0.5148
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6499 - val_loss: 0.3218 - val_auc: 0.5487
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5130 - auc: 0.6322 - val_loss: 0.3039 - val_auc: 0.5942
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6684 - val_loss: 0.2807 - val_auc: 0.6407
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4829 - auc: 0.6920 - val_loss: 0.2934 - val_auc: 0.6788
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.7077 - val_loss: 0.3114 - val_auc: 0.6180
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6844 - val_loss: 0.2835 - val_auc: 0.6873
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.6964 - val_loss: 0.2739 - val_auc: 0.5725
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.6848 - val_loss: 0.2697 - val_auc: 0.6587
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.7127 - val_loss: 0.2792 - val_auc: 0.6153
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4682 - auc: 0.7256 - val_loss: 0.2982 - val_auc: 0.5614
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.7036 - val_loss: 0.2924 - val_auc: 0.5190
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6898 - val_loss: 0.2518 - val_auc: 0.5677
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4873 - auc: 0.7013 - val_loss: 0.2794 - val_auc: 0.5746
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6907 - val_loss: 0.2776 - val_auc: 0.5497
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.6999 - val_loss: 0.2691 - val_auc: 0.6233
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6850 - val_loss: 0.2943 - val_auc: 0.5677
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4649 - auc: 0.7341 - val_loss: 0.2820 - val_auc: 0.5899
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB70A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 1), (0.7528794, 0), (0.7528794, 0), (0.7528794, 1), (0.7528794, 0), (0.7528794, 0), (0.7528794, 1), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 0), (0.7528794, 1), (0.7528794, 0), (0.7528794, 1), (0.7528794, 1), (0.74886537, 1), (0.7302427, 0), (0.7206497, 0), (0.70644635, 0), (0.69945943, 0), (0.6906578, 0), (0.68055296, 1), (0.63948864, 0), (0.6232927, 0), (0.61271363, 0), (0.58344626, 1), (0.5673914, 0), (0.531384, 0), (0.45833948, 0), (0.44297516, 0), (0.41174993, 0), (0.3339108, 0), (0.30950767, 1), (0.27530125, 0), (0.2562957, 1), (0.16757521, 0), (0.014714783, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235036DB798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.5688 - auc: 0.5635WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350846E1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.5651 - auc: 0.5624 - val_loss: 0.2944 - val_auc: 0.4836
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5430 - auc: 0.6368 - val_loss: 0.3690 - val_auc: 0.5640
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5239 - auc: 0.6387 - val_loss: 0.3320 - val_auc: 0.5201
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5135 - auc: 0.6628 - val_loss: 0.3465 - val_auc: 0.4889
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5124 - auc: 0.6542 - val_loss: 0.3404 - val_auc: 0.5825
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4926 - auc: 0.6899 - val_loss: 0.3033 - val_auc: 0.5751
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5154 - auc: 0.6657 - val_loss: 0.3000 - val_auc: 0.7418
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6789 - val_loss: 0.3230 - val_auc: 0.5307
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.7049 - val_loss: 0.3071 - val_auc: 0.5889
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6963 - val_loss: 0.2928 - val_auc: 0.6185
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4879 - auc: 0.7129 - val_loss: 0.3063 - val_auc: 0.5238
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.7103 - val_loss: 0.3017 - val_auc: 0.5608
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5042 - auc: 0.6922 - val_loss: 0.3144 - val_auc: 0.4709
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6907 - val_loss: 0.3060 - val_auc: 0.5476
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6902 - val_loss: 0.3139 - val_auc: 0.5423
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.7110 - val_loss: 0.3009 - val_auc: 0.5709
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4834 - auc: 0.7368 - val_loss: 0.2997 - val_auc: 0.5820
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.7022 - val_loss: 0.2950 - val_auc: 0.5878
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4800 - auc: 0.7246 - val_loss: 0.2936 - val_auc: 0.6852
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6964 - val_loss: 0.3027 - val_auc: 0.6011
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB70D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9658822, 0), (0.87066585, 0), (0.8249847, 1), (0.76507133, 0), (0.7621955, 0), (0.7106568, 0), (0.7105533, 0), (0.70784295, 0), (0.7067677, 0), (0.70580566, 0), (0.70418745, 0), (0.7035241, 0), (0.7024724, 0), (0.6971768, 0), (0.6967848, 0), (0.6927602, 0), (0.69244844, 0), (0.6921172, 0), (0.6906131, 0), (0.6887032, 0), (0.6874508, 0), (0.6846493, 0), (0.67612237, 0), (0.6758975, 0), (0.66707855, 0), (0.66233236, 0), (0.66111827, 0), (0.6496945, 0), (0.64477456, 0), (0.63584393, 0), (0.6328239, 0), (0.62945837, 0), (0.62359476, 0), (0.6219005, 0), (0.56258255, 0), (0.5615469, 0), (0.5347936, 0), (0.51606053, 1), (0.5041235, 0), (0.49929973, 0), (0.47421736, 0), (0.42366394, 1), (0.3840825, 0), (0.30416563, 0), (0.27388018, 0), (0.27279446, 0), (0.23920222, 1), (0.23545855, 1), (0.18380177, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235076E1288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/97 [==========================&gt;...] - ETA: 0s - loss: 0.6651 - auc: 0.5663WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023E0B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.6613 - auc: 0.5684 - val_loss: 0.5341 - val_auc: 0.5672
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6054 - auc: 0.5956 - val_loss: 0.5303 - val_auc: 0.4560
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5484 - auc: 0.6385 - val_loss: 0.4197 - val_auc: 0.4042
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5685 - auc: 0.6105 - val_loss: 0.4632 - val_auc: 0.5000
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5410 - auc: 0.6203 - val_loss: 0.4280 - val_auc: 0.5071
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5287 - auc: 0.6382 - val_loss: 0.4014 - val_auc: 0.4667
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5164 - auc: 0.6649 - val_loss: 0.3732 - val_auc: 0.6089
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5320 - auc: 0.6220 - val_loss: 0.3761 - val_auc: 0.4671
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5074 - auc: 0.6697 - val_loss: 0.3874 - val_auc: 0.5447
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5336 - auc: 0.6124 - val_loss: 0.3522 - val_auc: 0.5722
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6708 - val_loss: 0.3144 - val_auc: 0.5528
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6885 - val_loss: 0.3153 - val_auc: 0.5444
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4926 - auc: 0.6883 - val_loss: 0.3166 - val_auc: 0.6028
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.7090 - val_loss: 0.3080 - val_auc: 0.6277
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6916 - val_loss: 0.3073 - val_auc: 0.6206
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6911 - val_loss: 0.3213 - val_auc: 0.5860
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7284 - val_loss: 0.3163 - val_auc: 0.5783
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7183 - val_loss: 0.3059 - val_auc: 0.5759
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4838 - auc: 0.7253 - val_loss: 0.3123 - val_auc: 0.5927
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4862 - auc: 0.7160 - val_loss: 0.2976 - val_auc: 0.4919
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023500A72948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9736464, 0), (0.87541085, 1), (0.8528039, 0), (0.7840694, 0), (0.76817966, 0), (0.76122427, 0), (0.7546949, 1), (0.73433685, 0), (0.73061323, 0), (0.72333443, 0), (0.7032625, 0), (0.7006195, 0), (0.6971576, 0), (0.6897638, 0), (0.6860501, 0), (0.68319225, 0), (0.6830426, 0), (0.680414, 0), (0.6735391, 0), (0.671792, 0), (0.66848654, 0), (0.66848654, 0), (0.66848654, 0), (0.6662089, 0), (0.6653034, 0), (0.65981036, 0), (0.65290445, 0), (0.6518825, 0), (0.6388564, 0), (0.63322777, 0), (0.6233875, 0), (0.6201441, 1), (0.61771727, 0), (0.6072841, 0), (0.6046665, 0), (0.6029397, 0), (0.60260385, 0), (0.60048836, 0), (0.5989882, 0), (0.5929582, 0), (0.55897146, 0), (0.55728203, 1), (0.54595935, 0), (0.5288399, 0), (0.5037673, 0), (0.45958963, 0), (0.45654422, 0), (0.42219824, 0), (0.30522314, 0), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235099090D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/97 [==========================&gt;...] - ETA: 0s - loss: 0.9036 - auc: 0.4827WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350339FB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.8819 - auc: 0.4919 - val_loss: 0.6706 - val_auc: 0.8190
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.7033 - auc: 0.5785 - val_loss: 0.6946 - val_auc: 0.7598
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6218 - auc: 0.6251 - val_loss: 0.6631 - val_auc: 0.7328
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6259 - auc: 0.6010 - val_loss: 0.7300 - val_auc: 0.6651
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5895 - auc: 0.6334 - val_loss: 0.6550 - val_auc: 0.6048
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5667 - auc: 0.6272 - val_loss: 0.5802 - val_auc: 0.6741
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5521 - auc: 0.6432 - val_loss: 0.4863 - val_auc: 0.6799
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5363 - auc: 0.6564 - val_loss: 0.4506 - val_auc: 0.6032
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5464 - auc: 0.6435 - val_loss: 0.5533 - val_auc: 0.7005
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5293 - auc: 0.6548 - val_loss: 0.4780 - val_auc: 0.7090
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5118 - auc: 0.6908 - val_loss: 0.4280 - val_auc: 0.6772
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5293 - auc: 0.6550 - val_loss: 0.4377 - val_auc: 0.7730
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6949 - val_loss: 0.4019 - val_auc: 0.7434
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5218 - auc: 0.6601 - val_loss: 0.4039 - val_auc: 0.7577
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6917 - val_loss: 0.3850 - val_auc: 0.7825
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6826 - val_loss: 0.3574 - val_auc: 0.7720
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6891 - val_loss: 0.3799 - val_auc: 0.7243
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4989 - auc: 0.6994 - val_loss: 0.3595 - val_auc: 0.6709
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.6844 - val_loss: 0.3642 - val_auc: 0.7016
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4894 - auc: 0.6979 - val_loss: 0.3408 - val_auc: 0.7222
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF3EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9575555, 0), (0.9419597, 0), (0.9252364, 0), (0.9209053, 0), (0.92028636, 0), (0.90603, 0), (0.90575296, 0), (0.9052823, 0), (0.9004882, 0), (0.9001124, 0), (0.8875627, 0), (0.882683, 0), (0.87595063, 0), (0.872761, 1), (0.8712253, 0), (0.86931735, 0), (0.8683141, 0), (0.86216265, 0), (0.850356, 0), (0.8397067, 0), (0.8357194, 1), (0.8290131, 0), (0.80627674, 0), (0.8042162, 0), (0.7994651, 0), (0.7975249, 0), (0.786503, 0), (0.77789336, 1), (0.77555734, 0), (0.75479203, 0), (0.6971143, 0), (0.6712837, 0), (0.62592596, 0), (0.6028749, 0), (0.5945657, 0), (0.5917747, 0), (0.58016855, 0), (0.54483724, 0), (0.53580177, 0), (0.5014097, 0), (0.489011, 0), (0.4557796, 0), (0.4205293, 1), (0.42036408, 0), (0.30850667, 0), (0.24090272, 0), (0.2350852, 0), (0.16085522, 0), (0.14736377, 0), (0.0, 0)]
0.0
0.0
Siam
[0.6, 0.4, 0.0, 0.2, 0.0, 0.4, 0.2, 0.0, 0.4, 0.2, 0.0, 0.0, 0.6, 0.0, 0.2, 0.4, 0.0, 0.2, 0.2, 0.0]
0.2
[0.1875, 0.2, 0.0, 0.2, 0.0, 0.18181818181818182, 0.07142857142857142, 0.0, 0.25, 0.07142857142857142, 0.0, 0.0, 0.16666666666666666, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0, 0.2, 0.25, 0.0]
0.09572942988384164
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[10]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350239ACA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/98 [=========================&gt;....] - ETA: 0s - loss: 0.6124 - auc: 0.5547WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235038CF5E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.6027 - auc: 0.5539 - val_loss: 0.4378 - val_auc: 0.4696
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5464 - auc: 0.5940 - val_loss: 0.2995 - val_auc: 0.5388
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5203 - auc: 0.6233 - val_loss: 0.3243 - val_auc: 0.5710
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6615 - val_loss: 0.2991 - val_auc: 0.6001
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6603 - val_loss: 0.3214 - val_auc: 0.5379
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5118 - auc: 0.6364 - val_loss: 0.3008 - val_auc: 0.5542
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6698 - val_loss: 0.3064 - val_auc: 0.5833
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6528 - val_loss: 0.3040 - val_auc: 0.6287
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4852 - auc: 0.6837 - val_loss: 0.2833 - val_auc: 0.5428
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.6712 - val_loss: 0.2975 - val_auc: 0.6623
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4633 - auc: 0.7112 - val_loss: 0.2979 - val_auc: 0.5582
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4800 - auc: 0.6960 - val_loss: 0.2860 - val_auc: 0.5476
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4776 - auc: 0.7166 - val_loss: 0.2843 - val_auc: 0.6138
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6983 - val_loss: 0.2793 - val_auc: 0.6063
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.6887 - val_loss: 0.2823 - val_auc: 0.5476
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4758 - auc: 0.6958 - val_loss: 0.2717 - val_auc: 0.5767
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4687 - auc: 0.7048 - val_loss: 0.2564 - val_auc: 0.4519
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4696 - auc: 0.6999 - val_loss: 0.2790 - val_auc: 0.4815
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4759 - auc: 0.7018 - val_loss: 0.2640 - val_auc: 0.4705
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4780 - auc: 0.6949 - val_loss: 0.2643 - val_auc: 0.4537
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350339FB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.8330545, 1), (0.82098734, 0), (0.8072262, 0), (0.80556214, 1), (0.7786047, 0), (0.75413704, 1), (0.7461587, 0), (0.7444782, 0), (0.7366396, 0), (0.7232126, 1), (0.72030777, 1), (0.7090197, 0), (0.7013232, 0), (0.696845, 1), (0.6803686, 0), (0.67547375, 0), (0.6718108, 0), (0.67042875, 1), (0.6677023, 0), (0.65799963, 0), (0.6547476, 0), (0.6545995, 1), (0.6531104, 0), (0.6488156, 0), (0.6454281, 0), (0.6443852, 0), (0.64322084, 0), (0.6366832, 1), (0.63551146, 0), (0.63503313, 0), (0.6349782, 0), (0.6344973, 0), (0.6327531, 0), (0.6226417, 1), (0.6202782, 1), (0.6190456, 0), (0.6168409, 0), (0.6102179, 1), (0.60060966, 1), (0.5950603, 0), (0.5548061, 0), (0.42776495, 0), (0.35005078, 0), (0.22307006, 1), (0.0, 0)]
0.6
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/98 [==========================&gt;...] - ETA: 0s - loss: 0.5390 - auc: 0.5417WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023E0D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5364 - auc: 0.5468 - val_loss: 0.3161 - val_auc: 0.4259
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5229 - auc: 0.5883 - val_loss: 0.3197 - val_auc: 0.6195
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5157 - auc: 0.6301 - val_loss: 0.2853 - val_auc: 0.8038
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5186 - auc: 0.6055 - val_loss: 0.2816 - val_auc: 0.8823
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6490 - val_loss: 0.2613 - val_auc: 0.8629
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6492 - val_loss: 0.2372 - val_auc: 0.8086
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6598 - val_loss: 0.2681 - val_auc: 0.5269
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6740 - val_loss: 0.2892 - val_auc: 0.5573
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6908 - val_loss: 0.2860 - val_auc: 0.5538
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6804 - val_loss: 0.2840 - val_auc: 0.6790
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.6944 - val_loss: 0.2829 - val_auc: 0.6182
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6787 - val_loss: 0.2791 - val_auc: 0.5441
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6953 - val_loss: 0.2771 - val_auc: 0.4947
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6801 - val_loss: 0.2879 - val_auc: 0.6164
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.7001 - val_loss: 0.2902 - val_auc: 0.4361
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4713 - auc: 0.7312 - val_loss: 0.2976 - val_auc: 0.4863
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.7064 - val_loss: 0.3068 - val_auc: 0.5212
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4894 - auc: 0.6923 - val_loss: 0.2941 - val_auc: 0.5617
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6728 - val_loss: 0.2745 - val_auc: 0.6407
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6983 - val_loss: 0.2869 - val_auc: 0.5560
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB70558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9882614, 1), (0.9368233, 0), (0.9031697, 0), (0.88846385, 0), (0.83603275, 1), (0.83111274, 0), (0.8201134, 1), (0.807814, 1), (0.8050603, 0), (0.7898346, 0), (0.7888125, 0), (0.7813443, 0), (0.7807799, 0), (0.7794092, 0), (0.7785939, 0), (0.77798927, 0), (0.7757253, 0), (0.7757253, 1), (0.7757253, 0), (0.7757253, 0), (0.77463245, 0), (0.77463245, 1), (0.77463245, 0), (0.77463245, 0), (0.77463245, 1), (0.77463245, 0), (0.77463245, 0), (0.77463245, 0), (0.77463245, 0), (0.77463245, 0), (0.77463245, 0), (0.77463245, 0), (0.75622547, 1), (0.7435093, 0), (0.7015073, 0), (0.6926942, 0), (0.690174, 0), (0.6889968, 1), (0.6888041, 0), (0.6501734, 0), (0.63429606, 0), (0.5663699, 0), (0.31160727, 0), (0.21542807, 0), (0.0, 0)]
0.2
0.1111111111111111
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235048A48B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/98 [=========================&gt;....] - ETA: 0s - loss: 0.6701 - auc: 0.5041WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235582983A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.6573 - auc: 0.5125 - val_loss: 0.4015 - val_auc: 0.6421
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5560 - auc: 0.6150 - val_loss: 0.4645 - val_auc: 0.7184
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5284 - auc: 0.6385 - val_loss: 0.4328 - val_auc: 0.7484
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5539 - auc: 0.6081 - val_loss: 0.4404 - val_auc: 0.5537
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5229 - auc: 0.6563 - val_loss: 0.4707 - val_auc: 0.5995
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5267 - auc: 0.6407 - val_loss: 0.4130 - val_auc: 0.5563
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5186 - auc: 0.6574 - val_loss: 0.4676 - val_auc: 0.5905
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6787 - val_loss: 0.3801 - val_auc: 0.7179
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4960 - auc: 0.6954 - val_loss: 0.3787 - val_auc: 0.6095
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.6895 - val_loss: 0.4021 - val_auc: 0.5958
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5198 - auc: 0.6553 - val_loss: 0.3755 - val_auc: 0.6495
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.7138 - val_loss: 0.3578 - val_auc: 0.7226
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.7025 - val_loss: 0.3397 - val_auc: 0.6853
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6919 - val_loss: 0.3484 - val_auc: 0.6995
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6815 - val_loss: 0.3239 - val_auc: 0.7421
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6943 - val_loss: 0.3143 - val_auc: 0.7479
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.7148 - val_loss: 0.3121 - val_auc: 0.7537
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6941 - val_loss: 0.3178 - val_auc: 0.7495
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6986 - val_loss: 0.3546 - val_auc: 0.7116
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4964 - auc: 0.7080 - val_loss: 0.3240 - val_auc: 0.6995
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508590318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.83386046, 0), (0.8236296, 0), (0.7920617, 0), (0.7912539, 0), (0.7912539, 0), (0.7912539, 0), (0.7912539, 0), (0.7907977, 0), (0.7901982, 0), (0.7887991, 0), (0.786231, 0), (0.7862297, 0), (0.78595537, 0), (0.78142667, 0), (0.7789984, 0), (0.7719413, 0), (0.7718133, 0), (0.7677246, 0), (0.76498103, 0), (0.75957257, 0), (0.75813234, 1), (0.74917346, 0), (0.7436602, 0), (0.74344844, 0), (0.73685247, 1), (0.7317232, 0), (0.7265311, 0), (0.68949175, 0), (0.6588562, 1), (0.6180217, 0), (0.5991039, 1), (0.5865951, 0), (0.55728394, 0), (0.55549425, 0), (0.54646534, 0), (0.5110476, 0), (0.48859113, 0), (0.4762961, 0), (0.46816453, 0), (0.45886627, 0), (0.36967725, 0), (0.36421004, 0), (0.24354394, 0), (0.21214893, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503880F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/98 [==========================&gt;...] - ETA: 0s - loss: 0.5495 - auc: 0.5319WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023557BDB288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5491 - auc: 0.5321 - val_loss: 0.3203 - val_auc: 0.6479
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5288 - auc: 0.5938 - val_loss: 0.3330 - val_auc: 0.6011
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5227 - auc: 0.6308 - val_loss: 0.3391 - val_auc: 0.4605
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5266 - auc: 0.6240 - val_loss: 0.3399 - val_auc: 0.5821
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6682 - val_loss: 0.3011 - val_auc: 0.5500
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6748 - val_loss: 0.3142 - val_auc: 0.6989
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5088 - auc: 0.6704 - val_loss: 0.2888 - val_auc: 0.6405
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5093 - auc: 0.6808 - val_loss: 0.3171 - val_auc: 0.6258
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.7273 - val_loss: 0.2687 - val_auc: 0.6395
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6869 - val_loss: 0.3237 - val_auc: 0.5905
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.7006 - val_loss: 0.2961 - val_auc: 0.5837
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6985 - val_loss: 0.3294 - val_auc: 0.5642
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6939 - val_loss: 0.2951 - val_auc: 0.6621
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6858 - val_loss: 0.3020 - val_auc: 0.6089
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.7264 - val_loss: 0.3215 - val_auc: 0.5605
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6993 - val_loss: 0.2788 - val_auc: 0.6600
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4962 - auc: 0.6982 - val_loss: 0.3023 - val_auc: 0.6274
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4808 - auc: 0.7203 - val_loss: 0.3003 - val_auc: 0.6095
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.7013 - val_loss: 0.3129 - val_auc: 0.6868
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4877 - auc: 0.7053 - val_loss: 0.3030 - val_auc: 0.7405
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF1F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.90205204, 0), (0.84536994, 0), (0.82035124, 0), (0.81536883, 0), (0.81317735, 0), (0.80962193, 0), (0.8093286, 0), (0.80663395, 0), (0.8041459, 0), (0.79095894, 0), (0.7809857, 0), (0.7748766, 1), (0.7578566, 1), (0.7533231, 0), (0.7522846, 0), (0.74970573, 0), (0.7459069, 0), (0.74144006, 0), (0.7412185, 1), (0.7408676, 0), (0.73273814, 0), (0.721716, 0), (0.71768653, 0), (0.70966417, 0), (0.6999186, 0), (0.6996846, 0), (0.67858183, 0), (0.66158646, 1), (0.64848465, 0), (0.5876463, 0), (0.5851169, 0), (0.5723083, 0), (0.5632439, 0), (0.55818987, 0), (0.55475104, 0), (0.5095627, 0), (0.47055975, 0), (0.46720606, 0), (0.4505919, 0), (0.41563118, 0), (0.40316892, 0), (0.38316816, 0), (0.27515832, 0), (0.26757285, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235038CFEE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/98 [==========================&gt;...] - ETA: 0s - loss: 0.7207 - auc: 0.5226WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF0288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.7013 - auc: 0.5329 - val_loss: 0.4875 - val_auc: 0.6200
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5982 - auc: 0.5905 - val_loss: 0.4758 - val_auc: 0.7163
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5620 - auc: 0.6201 - val_loss: 0.6848 - val_auc: 0.6632
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5606 - auc: 0.6211 - val_loss: 0.7251 - val_auc: 0.5479
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5627 - auc: 0.6056 - val_loss: 0.6320 - val_auc: 0.5879
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5542 - auc: 0.6059 - val_loss: 0.4689 - val_auc: 0.6626
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6704 - val_loss: 0.4139 - val_auc: 0.7516
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5063 - auc: 0.6842 - val_loss: 0.4411 - val_auc: 0.6995
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6701 - val_loss: 0.4091 - val_auc: 0.6889
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.6943 - val_loss: 0.3581 - val_auc: 0.7253
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.6949 - val_loss: 0.3298 - val_auc: 0.7405
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6808 - val_loss: 0.3481 - val_auc: 0.6426
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6842 - val_loss: 0.3286 - val_auc: 0.6547
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6832 - val_loss: 0.3431 - val_auc: 0.6316
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6896 - val_loss: 0.3444 - val_auc: 0.6442
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5064 - auc: 0.6723 - val_loss: 0.3411 - val_auc: 0.6842
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4889 - auc: 0.6946 - val_loss: 0.3195 - val_auc: 0.6837
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.7276 - val_loss: 0.3155 - val_auc: 0.7184
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.7355 - val_loss: 0.3256 - val_auc: 0.6889
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.7214 - val_loss: 0.3377 - val_auc: 0.6642
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235023533A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8747576, 0), (0.8282546, 0), (0.8257143, 0), (0.79416895, 0), (0.791168, 0), (0.789655, 0), (0.7864847, 1), (0.7782227, 0), (0.7767669, 0), (0.77470887, 0), (0.76967007, 0), (0.763353, 0), (0.7533822, 0), (0.75126827, 0), (0.7504138, 1), (0.7456829, 0), (0.73601866, 0), (0.7356491, 1), (0.7289073, 0), (0.7126602, 1), (0.69694406, 0), (0.69314164, 1), (0.67395407, 0), (0.6657253, 0), (0.66084445, 0), (0.6549951, 0), (0.60855323, 1), (0.5816014, 0), (0.5685856, 0), (0.5678428, 0), (0.55583704, 0), (0.5283694, 0), (0.51553196, 0), (0.51091516, 0), (0.48777142, 0), (0.46734405, 0), (0.46607193, 0), (0.460885, 0), (0.4436888, 0), (0.43003434, 0), (0.3989819, 0), (0.28365466, 0), (0.19726275, 0), (0.1587262, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504014D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/98 [=========================&gt;....] - ETA: 0s - loss: 0.5315 - auc: 0.5983WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504014678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.5249 - auc: 0.6044 - val_loss: 0.2253 - val_auc: 0.5534
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5339 - auc: 0.5888 - val_loss: 0.3025 - val_auc: 0.6636
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6250 - val_loss: 0.3098 - val_auc: 0.7288
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5046 - auc: 0.6384 - val_loss: 0.2938 - val_auc: 0.4541
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6369 - val_loss: 0.3013 - val_auc: 0.6080
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.6539 - val_loss: 0.2722 - val_auc: 0.6376
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5134 - auc: 0.6313 - val_loss: 0.2766 - val_auc: 0.6764
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6491 - val_loss: 0.2907 - val_auc: 0.7209
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6558 - val_loss: 0.2794 - val_auc: 0.8554
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6545 - val_loss: 0.2811 - val_auc: 0.6653
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.6534 - val_loss: 0.2888 - val_auc: 0.6971
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6827 - val_loss: 0.3235 - val_auc: 0.7280
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6979 - val_loss: 0.2892 - val_auc: 0.6446
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.7140 - val_loss: 0.3097 - val_auc: 0.6146
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.6863 - val_loss: 0.2908 - val_auc: 0.6023
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4862 - auc: 0.7066 - val_loss: 0.2840 - val_auc: 0.6107
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4948 - auc: 0.6904 - val_loss: 0.2693 - val_auc: 0.5750
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.7104 - val_loss: 0.2847 - val_auc: 0.5600
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6781 - val_loss: 0.2810 - val_auc: 0.6389
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.6903 - val_loss: 0.2901 - val_auc: 0.4780
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235034853A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.84298265, 0), (0.8391301, 0), (0.68875253, 0), (0.68219936, 0), (0.67570037, 1), (0.6721396, 0), (0.6716921, 1), (0.6598646, 1), (0.65382797, 1), (0.6536594, 0), (0.6523425, 0), (0.65191394, 0), (0.65191394, 1), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 1), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 1), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 0), (0.65191394, 1), (0.65191394, 0), (0.65191394, 0), (0.649928, 0), (0.62489617, 0), (0.6191364, 1), (0.5964868, 0), (0.5762468, 0), (0.5694955, 0), (0.5400869, 1), (0.52880204, 0), (0.37827444, 0), (0.3739381, 0), (0.35785532, 0), (0.35219297, 0), (0.34217903, 0), (0.2951731, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235099095E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/98 [==========================&gt;...] - ETA: 0s - loss: 0.5313 - auc: 0.5225 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502729D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5322 - auc: 0.5312 - val_loss: 0.2868 - val_auc: 0.5116
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5201 - auc: 0.5654 - val_loss: 0.2854 - val_auc: 0.4821
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.6055 - val_loss: 0.2676 - val_auc: 0.7165
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.5986 - val_loss: 0.2799 - val_auc: 0.5469
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.6649 - val_loss: 0.2652 - val_auc: 0.5484
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6596 - val_loss: 0.2659 - val_auc: 0.5654
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5027 - auc: 0.6425 - val_loss: 0.2575 - val_auc: 0.5812
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.6890 - val_loss: 0.2715 - val_auc: 0.6455
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4937 - auc: 0.6604 - val_loss: 0.3029 - val_auc: 0.5902
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.6900 - val_loss: 0.2666 - val_auc: 0.5932
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.7135 - val_loss: 0.2732 - val_auc: 0.5741
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.7015 - val_loss: 0.2938 - val_auc: 0.5060
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4603 - auc: 0.7362 - val_loss: 0.2725 - val_auc: 0.6162
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7018 - val_loss: 0.3081 - val_auc: 0.5367
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.6799 - val_loss: 0.2940 - val_auc: 0.5137
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.6898 - val_loss: 0.2858 - val_auc: 0.5568
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4729 - auc: 0.7176 - val_loss: 0.3060 - val_auc: 0.5433
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4707 - auc: 0.7151 - val_loss: 0.2665 - val_auc: 0.5935
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4626 - auc: 0.7352 - val_loss: 0.2809 - val_auc: 0.5887
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.7054 - val_loss: 0.2966 - val_auc: 0.5750
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB701F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.92490333, 0), (0.8514081, 1), (0.78890455, 0), (0.7696282, 0), (0.75860083, 1), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 0), (0.75860083, 1), (0.75860083, 1), (0.75860083, 1), (0.75860083, 0), (0.7579564, 1), (0.7502069, 1), (0.7434147, 0), (0.7403168, 0), (0.7397026, 0), (0.7293494, 0), (0.7270106, 0), (0.71294355, 0), (0.662881, 0), (0.6446662, 0), (0.62890524, 1), (0.5996362, 0), (0.59542024, 0), (0.54021543, 0), (0.53585774, 0), (0.50666624, 0), (0.47807476, 0), (0.33072424, 0), (0.24645317, 0), (0.18789092, 0), (0.18557131, 0), (0.17128429, 1), (0.15165657, 1), (0.0, 0)]
0.2
0.1
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350497E708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5590 - auc: 0.4885WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF0708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5566 - auc: 0.5026 - val_loss: 0.3467 - val_auc: 0.5035
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5266 - auc: 0.5957 - val_loss: 0.3421 - val_auc: 0.4519
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6572 - val_loss: 0.3275 - val_auc: 0.4000
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5140 - auc: 0.6474 - val_loss: 0.3291 - val_auc: 0.4211
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6500 - val_loss: 0.3294 - val_auc: 0.4330
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6746 - val_loss: 0.2944 - val_auc: 0.4678
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6438 - val_loss: 0.3211 - val_auc: 0.4673
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5055 - auc: 0.6636 - val_loss: 0.3278 - val_auc: 0.5259
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.6913 - val_loss: 0.3101 - val_auc: 0.5014
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6872 - val_loss: 0.3009 - val_auc: 0.4500
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4941 - auc: 0.6886 - val_loss: 0.3097 - val_auc: 0.4532
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5023 - auc: 0.6860 - val_loss: 0.3084 - val_auc: 0.4427
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6780 - val_loss: 0.2960 - val_auc: 0.3965
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.6959 - val_loss: 0.2859 - val_auc: 0.3938
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6845 - val_loss: 0.3175 - val_auc: 0.4473
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6717 - val_loss: 0.3094 - val_auc: 0.4392
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.7090 - val_loss: 0.3131 - val_auc: 0.4168
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.7059 - val_loss: 0.3086 - val_auc: 0.4322
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4864 - auc: 0.7194 - val_loss: 0.2990 - val_auc: 0.4178
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6979 - val_loss: 0.2917 - val_auc: 0.4792
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508590048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9327788, 0), (0.9218518, 1), (0.9145562, 0), (0.8763817, 0), (0.8422924, 1), (0.8409823, 0), (0.83545285, 0), (0.8316024, 0), (0.8304247, 0), (0.8291999, 0), (0.8263974, 0), (0.8167612, 0), (0.814388, 0), (0.8143587, 0), (0.81175214, 0), (0.8056657, 0), (0.8047147, 0), (0.8003863, 0), (0.7967814, 0), (0.7951372, 0), (0.7839264, 0), (0.7824344, 0), (0.78163815, 0), (0.7771588, 0), (0.77270955, 0), (0.7581605, 0), (0.75454676, 0), (0.7521941, 0), (0.74496865, 0), (0.74143857, 0), (0.71326125, 0), (0.7071076, 0), (0.69949836, 0), (0.6696343, 0), (0.59254783, 0), (0.5784244, 0), (0.5444821, 0), (0.5138364, 0), (0.49437743, 0), (0.4062854, 0), (0.33348817, 0), (0.24212098, 0), (0.18814741, 0), (0.1860812, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350339C288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/98 [=========================&gt;....] - ETA: 0s - loss: 0.6194 - auc: 0.5236WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.6180 - auc: 0.5253 - val_loss: 0.3833 - val_auc: 0.5847
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5377 - auc: 0.6156 - val_loss: 0.4061 - val_auc: 0.6636
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5232 - auc: 0.6433 - val_loss: 0.3654 - val_auc: 0.4788
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6680 - val_loss: 0.3953 - val_auc: 0.5445
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6761 - val_loss: 0.3769 - val_auc: 0.5141
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6742 - val_loss: 0.3362 - val_auc: 0.6195
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6952 - val_loss: 0.3698 - val_auc: 0.6124
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6748 - val_loss: 0.3352 - val_auc: 0.6279
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6948 - val_loss: 0.3465 - val_auc: 0.7253
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.7042 - val_loss: 0.3491 - val_auc: 0.6720
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.6994 - val_loss: 0.2990 - val_auc: 0.7244
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7008 - val_loss: 0.3117 - val_auc: 0.6790
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.7048 - val_loss: 0.3386 - val_auc: 0.6772
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4865 - auc: 0.7109 - val_loss: 0.3048 - val_auc: 0.7156
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.7071 - val_loss: 0.3161 - val_auc: 0.6715
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6937 - val_loss: 0.3210 - val_auc: 0.6781
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4863 - auc: 0.7092 - val_loss: 0.3310 - val_auc: 0.5772
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6679 - val_loss: 0.3098 - val_auc: 0.6526
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4862 - auc: 0.7186 - val_loss: 0.3238 - val_auc: 0.5450
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.6790 - val_loss: 0.3367 - val_auc: 0.5952
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.79973483, 1), (0.7567975, 1), (0.693705, 0), (0.692972, 0), (0.6925836, 0), (0.68633574, 0), (0.6736518, 0), (0.6708721, 0), (0.67059606, 0), (0.6703456, 0), (0.6687732, 1), (0.6687151, 0), (0.6686772, 0), (0.6676061, 1), (0.6669505, 0), (0.6667212, 0), (0.6664926, 1), (0.6653678, 0), (0.66499865, 0), (0.6646193, 0), (0.6639176, 1), (0.6599427, 0), (0.6588813, 0), (0.65624535, 0), (0.64896846, 0), (0.6345269, 0), (0.63284796, 0), (0.63212997, 0), (0.6221864, 0), (0.6076203, 0), (0.60523164, 0), (0.5891116, 0), (0.58049065, 0), (0.57911247, 0), (0.57496136, 0), (0.5612684, 0), (0.54215705, 0), (0.5235636, 0), (0.5132019, 0), (0.4524644, 0), (0.45210314, 0), (0.4458881, 0), (0.36339357, 1), (0.27078587, 0), (0.0, 0)]
0.4
0.2857142857142857
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350497E0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/98 [==========================&gt;...] - ETA: 0s - loss: 0.5191 - auc: 0.5903WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235076E1438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5162 - auc: 0.5977 - val_loss: 0.2269 - val_auc: 0.4784
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5071 - auc: 0.6511 - val_loss: 0.2624 - val_auc: 0.6177
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5190 - auc: 0.5993 - val_loss: 0.2433 - val_auc: 0.6746
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.6608 - val_loss: 0.2423 - val_auc: 0.5225
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5072 - auc: 0.6374 - val_loss: 0.2278 - val_auc: 0.7421
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6492 - val_loss: 0.2546 - val_auc: 0.6054
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.6869 - val_loss: 0.2523 - val_auc: 0.5948
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6705 - val_loss: 0.2509 - val_auc: 0.6530
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.6545 - val_loss: 0.2562 - val_auc: 0.6107
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4767 - auc: 0.7056 - val_loss: 0.2701 - val_auc: 0.6777
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.6596 - val_loss: 0.2936 - val_auc: 0.5485
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.6864 - val_loss: 0.2664 - val_auc: 0.5564
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5015 - auc: 0.6732 - val_loss: 0.2622 - val_auc: 0.6129
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4783 - auc: 0.7092 - val_loss: 0.2606 - val_auc: 0.5802
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4858 - auc: 0.6983 - val_loss: 0.2583 - val_auc: 0.6155
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.6725 - val_loss: 0.2663 - val_auc: 0.6036
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.7151 - val_loss: 0.2617 - val_auc: 0.5282
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7184 - val_loss: 0.2767 - val_auc: 0.5644
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.7100 - val_loss: 0.2694 - val_auc: 0.5855
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4698 - auc: 0.7149 - val_loss: 0.2573 - val_auc: 0.5560
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023500A728B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9816839, 0), (0.9317815, 1), (0.9241918, 0), (0.9039545, 1), (0.8942591, 1), (0.86972135, 0), (0.86668086, 0), (0.8627395, 0), (0.8588928, 0), (0.8535681, 0), (0.8513648, 0), (0.8477574, 1), (0.84065646, 1), (0.8376765, 0), (0.8364414, 1), (0.8359759, 0), (0.8243064, 1), (0.8208687, 0), (0.8174241, 0), (0.8134012, 1), (0.8134012, 1), (0.81216663, 0), (0.81161964, 0), (0.81061786, 1), (0.8023965, 0), (0.79861224, 0), (0.79168093, 0), (0.7543174, 1), (0.74095327, 0), (0.71997327, 0), (0.71880895, 0), (0.699314, 0), (0.69387287, 0), (0.692236, 0), (0.6808261, 0), (0.6419204, 0), (0.6173342, 1), (0.50158745, 0), (0.48476994, 1), (0.4322264, 0), (0.32482445, 0), (0.2813133, 0), (0.27400598, 0), (0.2610155, 0), (0.0, 0)]
0.4
0.15384615384615385
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502729EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/98 [==========================&gt;...] - ETA: 0s - loss: 0.6608 - auc: 0.5336WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB79D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 8ms/step - loss: 0.6496 - auc: 0.5397 - val_loss: 0.4684 - val_auc: 0.5807
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.6055 - auc: 0.5590 - val_loss: 0.4510 - val_auc: 0.6208
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5581 - auc: 0.5981 - val_loss: 0.4205 - val_auc: 0.6927
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5566 - auc: 0.5894 - val_loss: 0.4846 - val_auc: 0.4330
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5344 - auc: 0.6165 - val_loss: 0.4283 - val_auc: 0.5608
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5375 - auc: 0.6146 - val_loss: 0.4154 - val_auc: 0.5119
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5181 - auc: 0.6492 - val_loss: 0.3661 - val_auc: 0.4841
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5161 - auc: 0.6702 - val_loss: 0.3736 - val_auc: 0.4815
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6813 - val_loss: 0.3606 - val_auc: 0.5414
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5018 - auc: 0.6853 - val_loss: 0.3864 - val_auc: 0.5066
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5233 - auc: 0.6316 - val_loss: 0.3535 - val_auc: 0.4387
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6970 - val_loss: 0.3497 - val_auc: 0.5670
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5007 - auc: 0.7026 - val_loss: 0.3355 - val_auc: 0.5481
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6937 - val_loss: 0.3458 - val_auc: 0.5639
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6876 - val_loss: 0.3411 - val_auc: 0.5767
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.7084 - val_loss: 0.3143 - val_auc: 0.6526
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.6733 - val_loss: 0.3510 - val_auc: 0.6971
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.7027 - val_loss: 0.3137 - val_auc: 0.7601
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5227 - auc: 0.6616 - val_loss: 0.3379 - val_auc: 0.8104
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4877 - auc: 0.7058 - val_loss: 0.3346 - val_auc: 0.7099
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235048A4678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.88498604, 0), (0.84632796, 0), (0.8377692, 1), (0.8310768, 0), (0.81128514, 0), (0.80949605, 0), (0.80572325, 0), (0.80493355, 0), (0.8006202, 0), (0.7971965, 0), (0.7936383, 0), (0.79335016, 0), (0.78980565, 0), (0.78923655, 0), (0.77476025, 0), (0.773301, 0), (0.77285826, 0), (0.76715606, 0), (0.76600343, 0), (0.7605436, 0), (0.7577585, 0), (0.75666505, 0), (0.75658154, 0), (0.7533422, 0), (0.7528814, 0), (0.75275946, 0), (0.7495237, 0), (0.7447492, 0), (0.7430116, 0), (0.74263066, 1), (0.73817885, 0), (0.73817885, 0), (0.7352026, 0), (0.726454, 0), (0.7021143, 0), (0.6996312, 0), (0.68515646, 0), (0.6633456, 0), (0.6587766, 0), (0.52210665, 0), (0.4349525, 0), (0.351538, 1), (0.26390734, 0), (0.23962097, 0), (0.0, 0)]
0.2
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDB3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.7211 - auc: 0.5243WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502B9C558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.7063 - auc: 0.5383 - val_loss: 0.5492 - val_auc: 0.3995
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.6087 - auc: 0.5770 - val_loss: 0.4957 - val_auc: 0.3281
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5791 - auc: 0.5939 - val_loss: 0.6141 - val_auc: 0.3638
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5742 - auc: 0.6039 - val_loss: 0.5020 - val_auc: 0.4443
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5436 - auc: 0.6333 - val_loss: 0.4157 - val_auc: 0.6111
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5264 - auc: 0.6396 - val_loss: 0.4793 - val_auc: 0.4838
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5088 - auc: 0.6687 - val_loss: 0.4484 - val_auc: 0.5151
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5179 - auc: 0.6633 - val_loss: 0.4527 - val_auc: 0.4957
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6817 - val_loss: 0.4039 - val_auc: 0.5659
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6759 - val_loss: 0.3795 - val_auc: 0.5703
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5084 - auc: 0.6676 - val_loss: 0.3650 - val_auc: 0.4884
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5133 - auc: 0.6667 - val_loss: 0.3741 - val_auc: 0.4884
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6814 - val_loss: 0.3366 - val_auc: 0.5138
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6871 - val_loss: 0.3278 - val_auc: 0.5765
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6864 - val_loss: 0.3361 - val_auc: 0.5008
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7200 - val_loss: 0.3530 - val_auc: 0.4646
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5048 - auc: 0.6825 - val_loss: 0.3504 - val_auc: 0.5024
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4982 - auc: 0.7126 - val_loss: 0.3440 - val_auc: 0.5657
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4742 - auc: 0.7325 - val_loss: 0.3416 - val_auc: 0.5278
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4850 - auc: 0.7136 - val_loss: 0.3347 - val_auc: 0.5922
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9802541, 0), (0.7955233, 0), (0.78837365, 1), (0.77940375, 0), (0.77470917, 0), (0.75616026, 0), (0.75355434, 0), (0.750851, 0), (0.7466622, 0), (0.7454805, 0), (0.74191827, 0), (0.74039805, 0), (0.73746276, 0), (0.73195356, 0), (0.7306844, 0), (0.72940725, 0), (0.725089, 0), (0.72278094, 0), (0.7220278, 0), (0.7158144, 0), (0.71522087, 1), (0.71203065, 0), (0.71095663, 0), (0.70999813, 0), (0.7084699, 0), (0.7082162, 0), (0.70427287, 0), (0.69914687, 0), (0.6930362, 0), (0.69271725, 0), (0.68615997, 0), (0.64206004, 0), (0.6312176, 0), (0.62733465, 0), (0.62113506, 0), (0.6180871, 0), (0.6110089, 0), (0.59874827, 0), (0.59024614, 0), (0.56090087, 0), (0.52525616, 0), (0.5208317, 0), (0.30700293, 0), (0.24964498, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/98 [==========================&gt;...] - ETA: 0s - loss: 0.5192 - auc: 0.5455WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504A6FB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5164 - auc: 0.5566 - val_loss: 0.3096 - val_auc: 0.4164
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.6170 - val_loss: 0.3021 - val_auc: 0.4850
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6419 - val_loss: 0.2959 - val_auc: 0.2470
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6026 - val_loss: 0.2848 - val_auc: 0.5966
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6268 - val_loss: 0.2682 - val_auc: 0.7691
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4814 - auc: 0.6789 - val_loss: 0.3105 - val_auc: 0.5959
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.6872 - val_loss: 0.2933 - val_auc: 0.6497
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.6582 - val_loss: 0.2734 - val_auc: 0.6674
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.6687 - val_loss: 0.2887 - val_auc: 0.6668
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4784 - auc: 0.6949 - val_loss: 0.2738 - val_auc: 0.6511
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4926 - auc: 0.6690 - val_loss: 0.2709 - val_auc: 0.6347
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4762 - auc: 0.6848 - val_loss: 0.2854 - val_auc: 0.6223
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4749 - auc: 0.6945 - val_loss: 0.2584 - val_auc: 0.7650
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.6806 - val_loss: 0.2724 - val_auc: 0.7523
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4746 - auc: 0.6954 - val_loss: 0.2654 - val_auc: 0.7122
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4677 - auc: 0.7227 - val_loss: 0.2861 - val_auc: 0.7032
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4682 - auc: 0.6979 - val_loss: 0.2734 - val_auc: 0.7383
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.7261 - val_loss: 0.2673 - val_auc: 0.6511
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4661 - auc: 0.7209 - val_loss: 0.2828 - val_auc: 0.6862
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4641 - auc: 0.7212 - val_loss: 0.2867 - val_auc: 0.6598
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.6954653, 1), (0.6826135, 1), (0.64521664, 0), (0.6090414, 0), (0.5837892, 0), (0.5727026, 0), (0.5631518, 1), (0.5606169, 0), (0.541987, 1), (0.522944, 0), (0.50456405, 0), (0.49525496, 0), (0.47872424, 0), (0.47867393, 1), (0.47248212, 1), (0.4713715, 0), (0.47111315, 1), (0.468508, 1), (0.46681207, 0), (0.46494827, 0), (0.4639373, 1), (0.4597889, 1), (0.45977318, 1), (0.45694807, 0), (0.45117608, 0), (0.45112425, 0), (0.45027015, 1), (0.44885662, 0), (0.44750267, 0), (0.44229203, 0), (0.44099978, 0), (0.43118447, 0), (0.42834657, 1), (0.4226482, 0), (0.42173445, 0), (0.4151863, 0), (0.4133369, 0), (0.37790716, 0), (0.3352717, 1), (0.32390392, 0), (0.31833076, 0), (0.24273175, 0), (0.24034658, 0), (0.13463001, 1), (0.0, 0)]
0.4
0.13333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235037F0A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/98 [==========================&gt;...] - ETA: 0s - loss: 0.5927 - auc: 0.5277WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.5881 - auc: 0.5241 - val_loss: 0.4349 - val_auc: 0.4738
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5510 - auc: 0.5770 - val_loss: 0.3947 - val_auc: 0.6151
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5220 - auc: 0.6440 - val_loss: 0.3468 - val_auc: 0.4027
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5231 - auc: 0.6353 - val_loss: 0.3216 - val_auc: 0.4538
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5286 - auc: 0.6076 - val_loss: 0.3406 - val_auc: 0.5208
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6480 - val_loss: 0.3192 - val_auc: 0.4649
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6507 - val_loss: 0.3034 - val_auc: 0.4311
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5039 - auc: 0.6842 - val_loss: 0.2994 - val_auc: 0.4943
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.7011 - val_loss: 0.3155 - val_auc: 0.5089
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6781 - val_loss: 0.3002 - val_auc: 0.4449
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7117 - val_loss: 0.2964 - val_auc: 0.5208
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4998 - auc: 0.6881 - val_loss: 0.2917 - val_auc: 0.4279
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.7060 - val_loss: 0.2851 - val_auc: 0.4528
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4645 - auc: 0.7514 - val_loss: 0.2862 - val_auc: 0.5079
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6757 - val_loss: 0.2951 - val_auc: 0.5017
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6746 - val_loss: 0.2977 - val_auc: 0.5079
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4924 - auc: 0.7107 - val_loss: 0.3005 - val_auc: 0.4839
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.7211 - val_loss: 0.2815 - val_auc: 0.5343
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.6876 - val_loss: 0.2767 - val_auc: 0.5487
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4660 - auc: 0.7512 - val_loss: 0.2791 - val_auc: 0.5109
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502729EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9376477, 0), (0.93117, 0), (0.9262588, 0), (0.9038039, 0), (0.86695373, 0), (0.8619285, 0), (0.85396326, 0), (0.8463933, 0), (0.8419167, 0), (0.83912563, 1), (0.83108, 0), (0.82755685, 0), (0.8271459, 0), (0.82470256, 0), (0.819597, 0), (0.81926227, 0), (0.8132409, 0), (0.81274813, 0), (0.8117282, 0), (0.801819, 0), (0.8016831, 0), (0.77141434, 0), (0.7566928, 0), (0.7546797, 0), (0.753766, 0), (0.74358225, 0), (0.74053824, 0), (0.71119887, 0), (0.7102592, 0), (0.6921312, 0), (0.6817907, 0), (0.6581938, 0), (0.5675585, 0), (0.5141426, 0), (0.5043185, 0), (0.48123604, 0), (0.47178638, 0), (0.45255017, 0), (0.42759973, 0), (0.3680265, 0), (0.360199, 0), (0.33375788, 0), (0.15608694, 0), (0.15104078, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F99708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
94/98 [===========================&gt;..] - ETA: 0s - loss: 0.6706 - auc: 0.5345WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DBCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.6627 - auc: 0.5422 - val_loss: 0.6538 - val_auc: 0.4594
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5703 - auc: 0.6098 - val_loss: 0.5819 - val_auc: 0.5287
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5440 - auc: 0.6380 - val_loss: 0.4384 - val_auc: 0.5176
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5525 - auc: 0.6226 - val_loss: 0.4847 - val_auc: 0.5476
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5323 - auc: 0.6226 - val_loss: 0.4170 - val_auc: 0.6834
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6710 - val_loss: 0.4321 - val_auc: 0.5516
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6675 - val_loss: 0.3925 - val_auc: 0.5273
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.6876 - val_loss: 0.3873 - val_auc: 0.4960
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4858 - auc: 0.6833 - val_loss: 0.3081 - val_auc: 0.6481
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6817 - val_loss: 0.3406 - val_auc: 0.6437
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4805 - auc: 0.7246 - val_loss: 0.3302 - val_auc: 0.5234
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.6870 - val_loss: 0.3394 - val_auc: 0.5547
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7032 - val_loss: 0.3238 - val_auc: 0.5639
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.7042 - val_loss: 0.3258 - val_auc: 0.5842
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4795 - auc: 0.7066 - val_loss: 0.3492 - val_auc: 0.4978
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.6628 - val_loss: 0.3338 - val_auc: 0.5207
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4732 - auc: 0.7100 - val_loss: 0.3338 - val_auc: 0.6129
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4830 - auc: 0.7039 - val_loss: 0.3194 - val_auc: 0.6014
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7160 - val_loss: 0.3213 - val_auc: 0.5604
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.7044 - val_loss: 0.3173 - val_auc: 0.5225
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FAEC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.879133, 0), (0.8369755, 0), (0.83526164, 0), (0.83422196, 0), (0.83327025, 0), (0.82583636, 0), (0.82419, 0), (0.822452, 1), (0.8101619, 0), (0.80334926, 0), (0.7982254, 0), (0.79456306, 1), (0.789851, 1), (0.78941125, 0), (0.7891658, 1), (0.7876081, 0), (0.7861352, 1), (0.78561926, 0), (0.78352535, 0), (0.78305364, 0), (0.78296715, 0), (0.78267825, 0), (0.7824849, 0), (0.78025204, 1), (0.7796175, 0), (0.77961385, 1), (0.7792407, 0), (0.77774143, 0), (0.7766856, 0), (0.77666676, 1), (0.7766135, 1), (0.77649206, 0), (0.7764732, 0), (0.77529174, 1), (0.7750366, 0), (0.7750366, 0), (0.7340536, 0), (0.668003, 0), (0.58580744, 0), (0.47920844, 0), (0.42847058, 0), (0.3098085, 0), (0.28540933, 1), (0.20587383, 0), (0.0, 0)]
0.2
0.08333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023E0D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/98 [==========================&gt;...] - ETA: 0s - loss: 0.4896 - auc: 0.5524 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235048A41F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.4947 - auc: 0.5595 - val_loss: 0.2966 - val_auc: 0.3853
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4962 - auc: 0.5491 - val_loss: 0.2895 - val_auc: 0.5230
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4877 - auc: 0.5704 - val_loss: 0.2920 - val_auc: 0.6968
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4781 - auc: 0.6001 - val_loss: 0.2593 - val_auc: 0.5884
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4648 - auc: 0.6125 - val_loss: 0.2685 - val_auc: 0.6081
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.6248 - val_loss: 0.2929 - val_auc: 0.5397
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.5638 - val_loss: 0.2823 - val_auc: 0.6392
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4805 - auc: 0.5926 - val_loss: 0.2811 - val_auc: 0.6314
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.6111 - val_loss: 0.2792 - val_auc: 0.5714
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.6412 - val_loss: 0.2756 - val_auc: 0.5920
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4625 - auc: 0.6692 - val_loss: 0.2718 - val_auc: 0.5962
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4703 - auc: 0.6389 - val_loss: 0.2750 - val_auc: 0.5565
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.6349 - val_loss: 0.2726 - val_auc: 0.5690
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4691 - auc: 0.6475 - val_loss: 0.2846 - val_auc: 0.5463
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4542 - auc: 0.6721 - val_loss: 0.2846 - val_auc: 0.5481
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4618 - auc: 0.6470 - val_loss: 0.2915 - val_auc: 0.5756
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4549 - auc: 0.6684 - val_loss: 0.3077 - val_auc: 0.5570
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4708 - auc: 0.6451 - val_loss: 0.2801 - val_auc: 0.5699
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4651 - auc: 0.6626 - val_loss: 0.2938 - val_auc: 0.5493
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4564 - auc: 0.6861 - val_loss: 0.2762 - val_auc: 0.5738
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508324E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8003647, 1), (0.77281415, 0), (0.76023746, 1), (0.7099877, 0), (0.7036437, 1), (0.70113736, 1), (0.7002354, 0), (0.69470567, 0), (0.6912001, 1), (0.6702808, 0), (0.6490699, 1), (0.6412968, 1), (0.6357206, 1), (0.62985367, 0), (0.62905574, 1), (0.61536795, 1), (0.6111234, 1), (0.60398287, 1), (0.59853345, 0), (0.596624, 0), (0.59535795, 1), (0.58974046, 0), (0.5862306, 0), (0.58560205, 1), (0.57673204, 1), (0.57373154, 1), (0.57174605, 1), (0.5222573, 1), (0.5206521, 1), (0.47586805, 0), (0.46300405, 1), (0.44666424, 1), (0.42676958, 1), (0.42189595, 1), (0.4170365, 1), (0.3997332, 1), (0.39315265, 0), (0.3766649, 0), (0.37640944, 1), (0.37607738, 1), (0.35011545, 1), (0.3158222, 0), (0.036975354, 1), (0.0106865745, 0), (0.0, 1)]
0.4
0.06666666666666667
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503485EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/98 [==========================&gt;...] - ETA: 0s - loss: 0.6373 - auc: 0.5012 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504A6F708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.6249 - auc: 0.5125 - val_loss: 0.3832 - val_auc: 0.5916
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5464 - auc: 0.5993 - val_loss: 0.3644 - val_auc: 0.6126
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5369 - auc: 0.6101 - val_loss: 0.4459 - val_auc: 0.5732
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5123 - auc: 0.6436 - val_loss: 0.4241 - val_auc: 0.6405
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6320 - val_loss: 0.3207 - val_auc: 0.6379
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6590 - val_loss: 0.3213 - val_auc: 0.6979
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6762 - val_loss: 0.3172 - val_auc: 0.6168
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6724 - val_loss: 0.2803 - val_auc: 0.6211
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4850 - auc: 0.6886 - val_loss: 0.3269 - val_auc: 0.6258
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6645 - val_loss: 0.2949 - val_auc: 0.6395
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4817 - auc: 0.7070 - val_loss: 0.2800 - val_auc: 0.7189
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4674 - auc: 0.7317 - val_loss: 0.3041 - val_auc: 0.6489
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4676 - auc: 0.7321 - val_loss: 0.2623 - val_auc: 0.7568
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.7060 - val_loss: 0.2526 - val_auc: 0.7895
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4718 - auc: 0.7150 - val_loss: 0.2905 - val_auc: 0.8095
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7039 - val_loss: 0.2866 - val_auc: 0.7674
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.7103 - val_loss: 0.3036 - val_auc: 0.6447
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4669 - auc: 0.7445 - val_loss: 0.2714 - val_auc: 0.7321
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4803 - auc: 0.7183 - val_loss: 0.2807 - val_auc: 0.7174
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.7116 - val_loss: 0.2779 - val_auc: 0.7374
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350339C168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9043538, 0), (0.8147542, 0), (0.81337714, 0), (0.80401826, 0), (0.7728485, 0), (0.6732341, 1), (0.64289314, 1), (0.6390202, 0), (0.63680965, 0), (0.61419654, 1), (0.5903417, 1), (0.5885895, 0), (0.587386, 0), (0.58252573, 0), (0.5779049, 0), (0.5728158, 0), (0.57157767, 1), (0.56918985, 0), (0.55559474, 0), (0.5553928, 0), (0.54163235, 0), (0.53610873, 0), (0.53490174, 0), (0.5307718, 0), (0.5253412, 0), (0.5084515, 1), (0.5045521, 0), (0.5031343, 1), (0.50308377, 1), (0.49941128, 0), (0.49153173, 0), (0.45841798, 0), (0.449788, 0), (0.44579887, 0), (0.42260647, 0), (0.42101824, 0), (0.42032528, 1), (0.41473377, 1), (0.35800576, 0), (0.30372185, 0), (0.294104, 1), (0.25065014, 0), (0.19824733, 0), (0.007281042, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDB4C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/98 [==========================&gt;...] - ETA: 0s - loss: 0.5426 - auc: 0.5367WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF05E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5507 - auc: 0.5423 - val_loss: 0.2286 - val_auc: 0.8016
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5222 - auc: 0.6210 - val_loss: 0.2365 - val_auc: 0.6932
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6783 - val_loss: 0.2359 - val_auc: 0.6026
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6815 - val_loss: 0.2614 - val_auc: 0.6226
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5107 - auc: 0.6518 - val_loss: 0.2774 - val_auc: 0.6911
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6597 - val_loss: 0.2842 - val_auc: 0.7200
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5006 - auc: 0.6790 - val_loss: 0.2733 - val_auc: 0.6011
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6752 - val_loss: 0.2743 - val_auc: 0.7447
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6902 - val_loss: 0.2672 - val_auc: 0.5947
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.7040 - val_loss: 0.2592 - val_auc: 0.5495
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.7054 - val_loss: 0.2960 - val_auc: 0.6516
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5052 - auc: 0.6871 - val_loss: 0.2915 - val_auc: 0.6758
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5137 - auc: 0.6800 - val_loss: 0.2796 - val_auc: 0.6311
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6878 - val_loss: 0.2545 - val_auc: 0.6184
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6946 - val_loss: 0.2569 - val_auc: 0.5974
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5140 - auc: 0.6872 - val_loss: 0.2731 - val_auc: 0.6500
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4901 - auc: 0.7125 - val_loss: 0.2661 - val_auc: 0.5921
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6929 - val_loss: 0.2731 - val_auc: 0.6695
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.7058 - val_loss: 0.2737 - val_auc: 0.6163
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6866 - val_loss: 0.2679 - val_auc: 0.5779
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508590B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.928554, 0), (0.776737, 0), (0.75720835, 0), (0.7215948, 0), (0.70990086, 0), (0.69098586, 0), (0.68360937, 0), (0.64850014, 0), (0.6257945, 0), (0.6247639, 0), (0.6221602, 0), (0.59500223, 0), (0.58599186, 0), (0.5778763, 0), (0.5691926, 0), (0.56535995, 0), (0.56326467, 0), (0.56036335, 0), (0.55117387, 1), (0.54593104, 0), (0.54279155, 0), (0.5403456, 0), (0.53243077, 0), (0.529625, 0), (0.5169245, 1), (0.5062298, 0), (0.50478476, 0), (0.49746975, 0), (0.48602208, 0), (0.48572895, 0), (0.48513347, 0), (0.48127085, 0), (0.47880694, 0), (0.47440326, 0), (0.4719256, 1), (0.46558067, 0), (0.45125046, 0), (0.45032996, 0), (0.44868714, 0), (0.44717845, 0), (0.44591036, 0), (0.42179585, 1), (0.33642906, 0), (0.047646124, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502258A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
92/98 [===========================&gt;..] - ETA: 0s - loss: 0.5242 - auc: 0.5631WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 8ms/step - loss: 0.5312 - auc: 0.5723 - val_loss: 0.3214 - val_auc: 0.4425
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5307 - auc: 0.5839 - val_loss: 0.2732 - val_auc: 0.5100
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5120 - auc: 0.6128 - val_loss: 0.2674 - val_auc: 0.4659
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5222 - auc: 0.6103 - val_loss: 0.2856 - val_auc: 0.4672
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5105 - auc: 0.6223 - val_loss: 0.2705 - val_auc: 0.5495
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6725 - val_loss: 0.2679 - val_auc: 0.4288
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5331 - auc: 0.6118 - val_loss: 0.2693 - val_auc: 0.4158
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5196 - auc: 0.6253 - val_loss: 0.2790 - val_auc: 0.4332
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5058 - auc: 0.6545 - val_loss: 0.2793 - val_auc: 0.4064
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6504 - val_loss: 0.2979 - val_auc: 0.4265
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6417 - val_loss: 0.2803 - val_auc: 0.4749
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6577 - val_loss: 0.2839 - val_auc: 0.4188
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6629 - val_loss: 0.2786 - val_auc: 0.4275
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5072 - auc: 0.6695 - val_loss: 0.2673 - val_auc: 0.4459
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6634 - val_loss: 0.3051 - val_auc: 0.4395
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5112 - auc: 0.6721 - val_loss: 0.2829 - val_auc: 0.4592
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4998 - auc: 0.6874 - val_loss: 0.2759 - val_auc: 0.4502
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5099 - auc: 0.6710 - val_loss: 0.2940 - val_auc: 0.4395
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6891 - val_loss: 0.2809 - val_auc: 0.4703
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.6880 - val_loss: 0.2740 - val_auc: 0.5060
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023557BDB1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.6937054, 1), (0.58449405, 0), (0.568164, 0), (0.5506732, 0), (0.5472181, 1), (0.54139173, 0), (0.54003644, 0), (0.53954613, 0), (0.5386754, 0), (0.5370925, 0), (0.5356226, 0), (0.5353071, 0), (0.5352842, 0), (0.5343643, 0), (0.5336842, 1), (0.53102404, 0), (0.53102404, 0), (0.53102404, 0), (0.5270039, 0), (0.5264601, 0), (0.52643114, 0), (0.5263152, 0), (0.526216, 0), (0.526042, 0), (0.52571356, 0), (0.5249489, 0), (0.52458084, 0), (0.52428854, 0), (0.5138345, 0), (0.5036916, 0), (0.48235968, 0), (0.4811034, 0), (0.4671664, 0), (0.46437758, 0), (0.4627029, 0), (0.46240255, 1), (0.45880848, 0), (0.45353374, 0), (0.45301256, 0), (0.45178583, 0), (0.446186, 0), (0.31495982, 0), (0.28530964, 0), (0.28095815, 0), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F998B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/98 [==========================&gt;...] - ETA: 0s - loss: 0.5943 - auc: 0.5514WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350497EAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5876 - auc: 0.5547 - val_loss: 0.3191 - val_auc: 0.7284
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5581 - auc: 0.5373 - val_loss: 0.3533 - val_auc: 0.6534
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5159 - auc: 0.6353 - val_loss: 0.3262 - val_auc: 0.6367
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5108 - auc: 0.6509 - val_loss: 0.3454 - val_auc: 0.6658
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5147 - auc: 0.6566 - val_loss: 0.3192 - val_auc: 0.6380
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5168 - auc: 0.6543 - val_loss: 0.2682 - val_auc: 0.6909
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5193 - auc: 0.6398 - val_loss: 0.2996 - val_auc: 0.6830
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6532 - val_loss: 0.2914 - val_auc: 0.6543
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4858 - auc: 0.7012 - val_loss: 0.3198 - val_auc: 0.5644
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4960 - auc: 0.6867 - val_loss: 0.3295 - val_auc: 0.5622
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5153 - auc: 0.6540 - val_loss: 0.3074 - val_auc: 0.5820
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6836 - val_loss: 0.3070 - val_auc: 0.5970
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.7067 - val_loss: 0.2947 - val_auc: 0.6645
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7122 - val_loss: 0.3290 - val_auc: 0.6424
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.7069 - val_loss: 0.2921 - val_auc: 0.6821
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5041 - auc: 0.6950 - val_loss: 0.2946 - val_auc: 0.7094
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.7104 - val_loss: 0.3007 - val_auc: 0.7046
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.7261 - val_loss: 0.3094 - val_auc: 0.6146
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4836 - auc: 0.7037 - val_loss: 0.2962 - val_auc: 0.6847
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6973 - val_loss: 0.2722 - val_auc: 0.6786
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504497828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.6589175, 0), (0.62697214, 0), (0.62629634, 0), (0.56796604, 0), (0.55820966, 0), (0.5208757, 0), (0.4965266, 0), (0.4800343, 0), (0.46335664, 0), (0.45320222, 0), (0.4045585, 0), (0.3990176, 0), (0.39589882, 0), (0.38975516, 0), (0.38100928, 1), (0.36162367, 0), (0.3588358, 0), (0.35657865, 0), (0.35289007, 0), (0.34563872, 0), (0.34456554, 0), (0.3427387, 0), (0.3302941, 0), (0.30953065, 0), (0.3094398, 0), (0.30116758, 0), (0.3011634, 0), (0.29723114, 1), (0.2911178, 0), (0.27505425, 0), (0.26633307, 1), (0.26443687, 0), (0.26400945, 0), (0.23645814, 0), (0.20294085, 0), (0.16990793, 0), (0.16868067, 0), (0.16107461, 0), (0.15384644, 0), (0.14128137, 0), (0.11343845, 0), (0.07230128, 0), (0.0160987, 0), (0.012410791, 0), (0.0, 0)]
0.0
0.0
Siam
[0.6, 0.2, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.2, 0.2, 0.4, 0.0, 0.2, 0.4, 0.0, 0.2, 0.2, 0.0]
0.19
[0.2, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.1, 0.5, 0.2857142857142857, 0.15384615384615385, 0.3333333333333333, 0.5, 0.13333333333333333, 0.0, 0.08333333333333333, 0.06666666666666667, 0.0, 0.2, 0.25, 0.0]
0.14586691086691086
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[11]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A6F828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.5809 - auc: 0.4956WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235034854C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5871 - auc: 0.4921 - val_loss: 0.4111 - val_auc: 0.5652
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5379 - auc: 0.5600 - val_loss: 0.4313 - val_auc: 0.5491
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5041 - auc: 0.6361 - val_loss: 0.4383 - val_auc: 0.5215
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5074 - auc: 0.6257 - val_loss: 0.4115 - val_auc: 0.5130
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6636 - val_loss: 0.3993 - val_auc: 0.5936
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4982 - auc: 0.6570 - val_loss: 0.3640 - val_auc: 0.5467
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4720 - auc: 0.6890 - val_loss: 0.3516 - val_auc: 0.4748
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5054 - auc: 0.6401 - val_loss: 0.3411 - val_auc: 0.6371
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6643 - val_loss: 0.3598 - val_auc: 0.4326
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.6948 - val_loss: 0.3490 - val_auc: 0.5076
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.7120 - val_loss: 0.3455 - val_auc: 0.5293
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4666 - auc: 0.7050 - val_loss: 0.3328 - val_auc: 0.6620
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4783 - auc: 0.7041 - val_loss: 0.3474 - val_auc: 0.6347
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.6924 - val_loss: 0.3357 - val_auc: 0.5630
Epoch 15/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4681 - auc: 0.7130 - val_loss: 0.3383 - val_auc: 0.4939
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4732 - auc: 0.7050 - val_loss: 0.3545 - val_auc: 0.5367
Epoch 17/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4495 - auc: 0.7406 - val_loss: 0.3239 - val_auc: 0.6043
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4680 - auc: 0.7236 - val_loss: 0.3209 - val_auc: 0.6146
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4600 - auc: 0.7212 - val_loss: 0.3306 - val_auc: 0.5347
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4750 - auc: 0.7128 - val_loss: 0.3320 - val_auc: 0.5342
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235081001F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9654835, 1), (0.9535038, 1), (0.89624393, 0), (0.8841581, 0), (0.87478375, 0), (0.8731147, 1), (0.86645544, 0), (0.86641353, 0), (0.86496526, 0), (0.8625931, 0), (0.8579076, 1), (0.8513849, 0), (0.8511209, 0), (0.8503794, 0), (0.84675896, 0), (0.8435539, 1), (0.84287244, 1), (0.8428081, 0), (0.8365721, 0), (0.8358873, 0), (0.83410364, 0), (0.8338445, 1), (0.8336316, 1), (0.8329523, 0), (0.8041394, 1), (0.78974044, 0), (0.7890606, 0), (0.7862039, 0), (0.78604245, 0), (0.7756048, 0), (0.7520951, 0), (0.67362523, 0), (0.36013788, 0), (0.35426736, 0), (0.28505787, 1), (0.2099916, 0), (0.0, 0)]
0.4
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504062AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.7632 - auc: 0.5188WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235038803A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.7590 - auc: 0.5232 - val_loss: 0.5490 - val_auc: 0.5131
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.6607 - auc: 0.5412 - val_loss: 0.6494 - val_auc: 0.6056
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5846 - auc: 0.6194 - val_loss: 0.5959 - val_auc: 0.4743
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5587 - auc: 0.6278 - val_loss: 0.4842 - val_auc: 0.4158
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5623 - auc: 0.6099 - val_loss: 0.4990 - val_auc: 0.5807
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5574 - auc: 0.5802 - val_loss: 0.4582 - val_auc: 0.4734
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5236 - auc: 0.6268 - val_loss: 0.4080 - val_auc: 0.7155
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5157 - auc: 0.6382 - val_loss: 0.4360 - val_auc: 0.6287
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6589 - val_loss: 0.4382 - val_auc: 0.6038
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6833 - val_loss: 0.3914 - val_auc: 0.5048
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5054 - auc: 0.6652 - val_loss: 0.3638 - val_auc: 0.5436
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5026 - auc: 0.6504 - val_loss: 0.3580 - val_auc: 0.5449
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.6864 - val_loss: 0.3351 - val_auc: 0.5672
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6907 - val_loss: 0.3359 - val_auc: 0.6588
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6740 - val_loss: 0.3328 - val_auc: 0.5545
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.6948 - val_loss: 0.3512 - val_auc: 0.6056
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4758 - auc: 0.7159 - val_loss: 0.3247 - val_auc: 0.7138
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.6851 - val_loss: 0.3234 - val_auc: 0.8037
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6719 - val_loss: 0.3202 - val_auc: 0.7413
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4846 - auc: 0.6942 - val_loss: 0.3142 - val_auc: 0.6972
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508100B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.83018893, 1), (0.5417634, 1), (0.52863824, 0), (0.52370787, 0), (0.5137747, 0), (0.50066984, 0), (0.49985364, 0), (0.47656184, 0), (0.47543848, 0), (0.4749254, 1), (0.46724916, 0), (0.4632532, 0), (0.4626562, 0), (0.4599256, 0), (0.45863077, 0), (0.45775285, 0), (0.4557708, 1), (0.45265675, 0), (0.4490568, 0), (0.4475656, 0), (0.44126752, 0), (0.4410612, 1), (0.43841478, 1), (0.43790385, 1), (0.43754494, 0), (0.4234843, 0), (0.4214478, 1), (0.38546097, 0), (0.38451222, 0), (0.38401446, 0), (0.37297368, 0), (0.33298463, 0), (0.30220175, 0), (0.23435156, 0), (0.1712348, 0), (0.077129275, 0), (0.0, 0)]
0.6
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A6F0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/99 [==========================&gt;...] - ETA: 0s - loss: 0.5933 - auc: 0.5641WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FF1678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5841 - auc: 0.5714 - val_loss: 0.5141 - val_auc: 0.5282
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5618 - auc: 0.6076 - val_loss: 0.3980 - val_auc: 0.5635
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5505 - auc: 0.6094 - val_loss: 0.4078 - val_auc: 0.6286
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5301 - auc: 0.6267 - val_loss: 0.3487 - val_auc: 0.5117
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5245 - auc: 0.6354 - val_loss: 0.3515 - val_auc: 0.5876
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5080 - auc: 0.6558 - val_loss: 0.3249 - val_auc: 0.6102
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5195 - auc: 0.6409 - val_loss: 0.3176 - val_auc: 0.5868
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6845 - val_loss: 0.3146 - val_auc: 0.6124
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6791 - val_loss: 0.3085 - val_auc: 0.5962
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6725 - val_loss: 0.3048 - val_auc: 0.6635
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6789 - val_loss: 0.3008 - val_auc: 0.6372
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6877 - val_loss: 0.3222 - val_auc: 0.5985
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.6873 - val_loss: 0.2885 - val_auc: 0.6203
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5027 - auc: 0.6805 - val_loss: 0.2978 - val_auc: 0.6353
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6781 - val_loss: 0.3208 - val_auc: 0.5932
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.6919 - val_loss: 0.3144 - val_auc: 0.5898
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6930 - val_loss: 0.3028 - val_auc: 0.6124
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6949 - val_loss: 0.3013 - val_auc: 0.6150
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6828 - val_loss: 0.3017 - val_auc: 0.6109
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7213 - val_loss: 0.2874 - val_auc: 0.6470
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FAECA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98816556, 0), (0.9124656, 0), (0.65040046, 0), (0.6346324, 0), (0.57818943, 0), (0.57718813, 0), (0.5728674, 0), (0.570802, 0), (0.56515914, 0), (0.55768794, 0), (0.5572, 0), (0.5548154, 0), (0.5537325, 0), (0.5498122, 0), (0.54758763, 0), (0.54654706, 0), (0.5439129, 0), (0.5272202, 0), (0.52701163, 0), (0.5104248, 0), (0.50585455, 0), (0.49547818, 0), (0.4850264, 0), (0.47547296, 1), (0.43282005, 0), (0.42270744, 0), (0.4162751, 0), (0.4138871, 0), (0.40823147, 0), (0.37744886, 0), (0.35907185, 0), (0.34677938, 1), (0.33686158, 0), (0.3232665, 0), (0.31942487, 0), (0.16814525, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502B9C288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.6472 - auc: 0.5379 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023557BDB168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.6574 - auc: 0.5312 - val_loss: 0.4848 - val_auc: 0.6357
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5520 - auc: 0.6137 - val_loss: 0.4414 - val_auc: 0.7295
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5671 - auc: 0.5898 - val_loss: 0.4338 - val_auc: 0.7068
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5355 - auc: 0.6347 - val_loss: 0.3740 - val_auc: 0.6248
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5269 - auc: 0.6523 - val_loss: 0.4192 - val_auc: 0.7325
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5166 - auc: 0.6695 - val_loss: 0.4133 - val_auc: 0.6880
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6786 - val_loss: 0.3570 - val_auc: 0.7312
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6953 - val_loss: 0.3495 - val_auc: 0.7496
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6826 - val_loss: 0.3480 - val_auc: 0.6798
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6681 - val_loss: 0.3363 - val_auc: 0.7229
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.7026 - val_loss: 0.3324 - val_auc: 0.7059
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6861 - val_loss: 0.3257 - val_auc: 0.6846
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5107 - auc: 0.6509 - val_loss: 0.3236 - val_auc: 0.6444
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6920 - val_loss: 0.3187 - val_auc: 0.7007
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.7056 - val_loss: 0.3288 - val_auc: 0.6514
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.7038 - val_loss: 0.3144 - val_auc: 0.7653
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.7223 - val_loss: 0.3154 - val_auc: 0.7286
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6972 - val_loss: 0.3248 - val_auc: 0.8128
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.7100 - val_loss: 0.3184 - val_auc: 0.6793
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.7121 - val_loss: 0.3248 - val_auc: 0.7020
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502729948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.80563045, 0), (0.69044596, 0), (0.67562103, 0), (0.6733785, 0), (0.67020714, 0), (0.6601764, 0), (0.6568196, 1), (0.6564763, 0), (0.6558635, 0), (0.65574104, 0), (0.64922696, 0), (0.64807653, 0), (0.64718026, 0), (0.6464093, 0), (0.64364606, 0), (0.64082205, 0), (0.63838583, 0), (0.6322188, 0), (0.63059336, 0), (0.6274659, 1), (0.6270017, 0), (0.6223179, 0), (0.57626826, 0), (0.5651889, 0), (0.5642094, 0), (0.5559932, 0), (0.5110702, 0), (0.49787754, 0), (0.47297603, 0), (0.42129275, 0), (0.4033285, 0), (0.38060018, 0), (0.341233, 1), (0.3369731, 0), (0.2652523, 0), (0.19827928, 0), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235085904C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/99 [=========================&gt;....] - ETA: 0s - loss: 0.5805 - auc: 0.5031WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286C8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.5714 - auc: 0.5152 - val_loss: 0.3065 - val_auc: 0.6300
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5126 - auc: 0.6641 - val_loss: 0.3632 - val_auc: 0.5257
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5390 - auc: 0.5972 - val_loss: 0.2763 - val_auc: 0.6366
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5382 - auc: 0.5946 - val_loss: 0.3130 - val_auc: 0.6937
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5015 - auc: 0.6609 - val_loss: 0.2722 - val_auc: 0.6396
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6636 - val_loss: 0.2762 - val_auc: 0.7221
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6710 - val_loss: 0.2651 - val_auc: 0.7086
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6704 - val_loss: 0.2724 - val_auc: 0.7592
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6689 - val_loss: 0.2740 - val_auc: 0.7129
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5059 - auc: 0.6781 - val_loss: 0.3044 - val_auc: 0.6793
Epoch 11/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5126 - auc: 0.6631 - val_loss: 0.2904 - val_auc: 0.6518
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6732 - val_loss: 0.2682 - val_auc: 0.7068
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5038 - auc: 0.6631 - val_loss: 0.2662 - val_auc: 0.7443
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.6995 - val_loss: 0.2715 - val_auc: 0.6863
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4856 - auc: 0.7059 - val_loss: 0.2851 - val_auc: 0.6099
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6821 - val_loss: 0.2872 - val_auc: 0.6283
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.7076 - val_loss: 0.2520 - val_auc: 0.7077
Epoch 18/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4828 - auc: 0.7086 - val_loss: 0.2875 - val_auc: 0.7055
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4744 - auc: 0.7326 - val_loss: 0.2816 - val_auc: 0.6706
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6981 - val_loss: 0.2823 - val_auc: 0.5825
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503485DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99427795, 0), (0.9842811, 0), (0.98263335, 0), (0.9721701, 1), (0.96445996, 0), (0.96399766, 1), (0.9612522, 0), (0.95408595, 0), (0.9520848, 0), (0.9449975, 1), (0.9439295, 0), (0.9409124, 0), (0.94073, 0), (0.93895864, 0), (0.93785465, 0), (0.93593705, 0), (0.9331244, 0), (0.9316612, 0), (0.927702, 0), (0.9135424, 0), (0.9092684, 0), (0.90259266, 1), (0.87902945, 0), (0.8446228, 0), (0.7850335, 0), (0.7635509, 0), (0.75645226, 1), (0.7172147, 0), (0.71003073, 0), (0.6961098, 0), (0.6776641, 0), (0.6525991, 0), (0.62770134, 0), (0.32922512, 0), (0.32189545, 0), (0.3152606, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350A17F168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.7653 - auc: 0.5220 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FF1168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.7429 - auc: 0.5427 - val_loss: 0.5258 - val_auc: 0.5804
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.6380 - auc: 0.5806 - val_loss: 0.6155 - val_auc: 0.6313
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5510 - auc: 0.6405 - val_loss: 0.4674 - val_auc: 0.6524
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5838 - auc: 0.6248 - val_loss: 0.6990 - val_auc: 0.5959
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5376 - auc: 0.6603 - val_loss: 0.7416 - val_auc: 0.7490
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5436 - auc: 0.6554 - val_loss: 0.6244 - val_auc: 0.8234
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5430 - auc: 0.6424 - val_loss: 0.5046 - val_auc: 0.7616
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5442 - auc: 0.6276 - val_loss: 0.5593 - val_auc: 0.6753
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5150 - auc: 0.6696 - val_loss: 0.5710 - val_auc: 0.6677
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5138 - auc: 0.6769 - val_loss: 0.4245 - val_auc: 0.6872
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6830 - val_loss: 0.5213 - val_auc: 0.6763
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4829 - auc: 0.7016 - val_loss: 0.4649 - val_auc: 0.6753
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6931 - val_loss: 0.3926 - val_auc: 0.7073
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4728 - auc: 0.7268 - val_loss: 0.4257 - val_auc: 0.7001
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.6929 - val_loss: 0.4799 - val_auc: 0.6739
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4780 - auc: 0.7208 - val_loss: 0.4116 - val_auc: 0.6508
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.6987 - val_loss: 0.4348 - val_auc: 0.6763
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4635 - auc: 0.7333 - val_loss: 0.4069 - val_auc: 0.7021
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.7052 - val_loss: 0.4058 - val_auc: 0.7368
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.7301 - val_loss: 0.3386 - val_auc: 0.7219
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235048A41F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9226132, 0), (0.87371963, 0), (0.8668432, 1), (0.835654, 0), (0.8244468, 1), (0.8004965, 0), (0.79654413, 0), (0.76903284, 0), (0.75770324, 0), (0.7260378, 0), (0.71184355, 0), (0.6970914, 0), (0.6866149, 1), (0.65971154, 1), (0.5884004, 0), (0.5778421, 0), (0.5765615, 0), (0.5623147, 0), (0.560398, 0), (0.50608, 0), (0.48227784, 0), (0.4564289, 0), (0.43919224, 1), (0.409872, 1), (0.3818855, 0), (0.37709525, 0), (0.30874997, 0), (0.2825301, 1), (0.2787259, 0), (0.2531052, 0), (0.24010117, 1), (0.22066481, 0), (0.16221009, 0), (0.07708297, 0), (0.056355573, 0), (0.0016118167, 0), (0.0, 0)]
0.2
0.125
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023E05E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.5158 - auc: 0.5575WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.5415 - auc: 0.5337 - val_loss: 0.3038 - val_auc: 0.3997
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5215 - auc: 0.5862 - val_loss: 0.3087 - val_auc: 0.6067
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5041 - auc: 0.6319 - val_loss: 0.3044 - val_auc: 0.5837
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6445 - val_loss: 0.2904 - val_auc: 0.6981
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4854 - auc: 0.6430 - val_loss: 0.2948 - val_auc: 0.5620
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4826 - auc: 0.6803 - val_loss: 0.2891 - val_auc: 0.6406
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5012 - auc: 0.6377 - val_loss: 0.3124 - val_auc: 0.5711
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6568 - val_loss: 0.2915 - val_auc: 0.5353
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6554 - val_loss: 0.3019 - val_auc: 0.6305
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4860 - auc: 0.6875 - val_loss: 0.2895 - val_auc: 0.5976
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.7149 - val_loss: 0.2921 - val_auc: 0.4757
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.6773 - val_loss: 0.2892 - val_auc: 0.4963
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4659 - auc: 0.7253 - val_loss: 0.2865 - val_auc: 0.5211
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4718 - auc: 0.7256 - val_loss: 0.2787 - val_auc: 0.5914
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6865 - val_loss: 0.2998 - val_auc: 0.5265
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4785 - auc: 0.7073 - val_loss: 0.2931 - val_auc: 0.5524
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.6920 - val_loss: 0.2740 - val_auc: 0.6356
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.6911 - val_loss: 0.2949 - val_auc: 0.5527
Epoch 19/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4572 - auc: 0.7209 - val_loss: 0.2785 - val_auc: 0.5717
Epoch 20/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4658 - auc: 0.7153 - val_loss: 0.3052 - val_auc: 0.5545
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350A17F318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98697066, 0), (0.98414606, 0), (0.982969, 0), (0.97359985, 0), (0.972546, 1), (0.9716089, 0), (0.96891326, 1), (0.9583943, 1), (0.95657796, 0), (0.9510753, 0), (0.94757277, 0), (0.9301864, 0), (0.9247523, 0), (0.92046607, 1), (0.91755754, 0), (0.9088384, 0), (0.9018935, 0), (0.88521576, 0), (0.8834435, 1), (0.86489594, 0), (0.8559347, 0), (0.85307974, 1), (0.83658826, 0), (0.8329069, 1), (0.8237871, 0), (0.8108555, 1), (0.7993554, 0), (0.6239023, 0), (0.6200406, 0), (0.6033993, 0), (0.5880663, 0), (0.5016731, 0), (0.4734034, 0), (0.35230932, 1), (0.32031855, 0), (0.21423368, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350339C048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/99 [============================&gt;.] - ETA: 0s - loss: 0.5424 - auc: 0.5804WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350497E048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 7ms/step - loss: 0.5421 - auc: 0.5801 - val_loss: 0.3173 - val_auc: 0.3690
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5204 - auc: 0.5993 - val_loss: 0.3101 - val_auc: 0.3482
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5208 - auc: 0.6313 - val_loss: 0.3309 - val_auc: 0.4181
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5277 - auc: 0.6060 - val_loss: 0.3201 - val_auc: 0.4311
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5147 - auc: 0.6368 - val_loss: 0.3178 - val_auc: 0.4257
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5276 - auc: 0.6112 - val_loss: 0.2929 - val_auc: 0.4252
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5111 - auc: 0.6212 - val_loss: 0.3097 - val_auc: 0.4247
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6707 - val_loss: 0.3077 - val_auc: 0.4250
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6701 - val_loss: 0.3076 - val_auc: 0.3881
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4976 - auc: 0.6815 - val_loss: 0.3027 - val_auc: 0.4289
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5007 - auc: 0.6683 - val_loss: 0.3166 - val_auc: 0.4081
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6882 - val_loss: 0.3161 - val_auc: 0.4201
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5080 - auc: 0.6429 - val_loss: 0.3049 - val_auc: 0.5154
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6747 - val_loss: 0.3134 - val_auc: 0.4428
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6813 - val_loss: 0.3118 - val_auc: 0.4181
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4824 - auc: 0.6937 - val_loss: 0.2964 - val_auc: 0.4472
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4889 - auc: 0.7177 - val_loss: 0.3025 - val_auc: 0.4521
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6979 - val_loss: 0.2963 - val_auc: 0.5142
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6723 - val_loss: 0.3088 - val_auc: 0.4616
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.6943 - val_loss: 0.3019 - val_auc: 0.4130
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235594A78B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7925329, 0), (0.77761525, 0), (0.7682863, 1), (0.7193329, 0), (0.71553457, 0), (0.7136721, 0), (0.70567507, 0), (0.7035674, 0), (0.70273703, 0), (0.699835, 0), (0.6957323, 0), (0.6876856, 0), (0.6870856, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6865553, 0), (0.6842058, 0), (0.656778, 0), (0.6101478, 0), (0.54189825, 0), (0.28801098, 0), (0.2836607, 0), (0.24840608, 0), (0.0, 0)]
0.2
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235038CFCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - ETA: 0s - loss: 0.5605 - auc: 0.5245WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350769D1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5605 - auc: 0.5245 - val_loss: 0.3295 - val_auc: 0.6396
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5172 - auc: 0.5990 - val_loss: 0.2744 - val_auc: 0.4747
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5039 - auc: 0.6346 - val_loss: 0.2787 - val_auc: 0.7483
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6596 - val_loss: 0.2873 - val_auc: 0.5742
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.6220 - val_loss: 0.2739 - val_auc: 0.6715
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6214 - val_loss: 0.3136 - val_auc: 0.6440
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5012 - auc: 0.6613 - val_loss: 0.2860 - val_auc: 0.6226
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4783 - auc: 0.6935 - val_loss: 0.2834 - val_auc: 0.5982
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.6806 - val_loss: 0.2817 - val_auc: 0.5833
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4759 - auc: 0.6933 - val_loss: 0.2730 - val_auc: 0.6588
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4790 - auc: 0.7058 - val_loss: 0.2744 - val_auc: 0.7177
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5103 - auc: 0.6700 - val_loss: 0.3005 - val_auc: 0.6453
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6590 - val_loss: 0.2890 - val_auc: 0.6697
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.6960 - val_loss: 0.2664 - val_auc: 0.6780
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4856 - auc: 0.7081 - val_loss: 0.2791 - val_auc: 0.6990
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.7092 - val_loss: 0.2601 - val_auc: 0.7264
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.7133 - val_loss: 0.2493 - val_auc: 0.7282
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4887 - auc: 0.6874 - val_loss: 0.2818 - val_auc: 0.6933
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.7201 - val_loss: 0.2724 - val_auc: 0.7090
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4765 - auc: 0.7136 - val_loss: 0.2726 - val_auc: 0.7269
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235021A7438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (0.9991712, 1), (0.98799706, 0), (0.9820088, 0), (0.96969444, 0), (0.9634204, 1), (0.9590572, 1), (0.954927, 0), (0.9488569, 0), (0.93047047, 0), (0.92336595, 0), (0.87929416, 0), (0.87570024, 1), (0.8375685, 0), (0.6615494, 0), (0.5999675, 0), (0.59840846, 0), (0.5965141, 0), (0.5760074, 0), (0.55531114, 0), (0.54702073, 0), (0.4029168, 0), (0.09362592, 0), (0.0, 1)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503C7A3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/99 [==========================&gt;...] - ETA: 0s - loss: 0.5348 - auc: 0.5116WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DB168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 3s 6ms/step - loss: 0.5379 - auc: 0.5119 - val_loss: 0.3077 - val_auc: 0.5550
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5229 - auc: 0.5765 - val_loss: 0.3447 - val_auc: 0.6557
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6297 - val_loss: 0.3009 - val_auc: 0.5591
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6202 - val_loss: 0.2946 - val_auc: 0.6705
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6265 - val_loss: 0.3161 - val_auc: 0.5689
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6565 - val_loss: 0.2868 - val_auc: 0.5192
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.6507 - val_loss: 0.3185 - val_auc: 0.5659
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.6925 - val_loss: 0.2938 - val_auc: 0.5845
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6687 - val_loss: 0.2928 - val_auc: 0.4953
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6622 - val_loss: 0.3191 - val_auc: 0.5044
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.6950 - val_loss: 0.3037 - val_auc: 0.5680
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6756 - val_loss: 0.2970 - val_auc: 0.5901
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.7207 - val_loss: 0.3037 - val_auc: 0.6386
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.7031 - val_loss: 0.2993 - val_auc: 0.6028
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.6919 - val_loss: 0.2982 - val_auc: 0.6141
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4893 - auc: 0.6753 - val_loss: 0.3097 - val_auc: 0.5957
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6922 - val_loss: 0.3056 - val_auc: 0.6557
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.7089 - val_loss: 0.3093 - val_auc: 0.6421
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4680 - auc: 0.7233 - val_loss: 0.2937 - val_auc: 0.6492
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7115 - val_loss: 0.3059 - val_auc: 0.6690
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235095939D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8105942, 0), (0.8011317, 0), (0.6914768, 0), (0.6201548, 1), (0.6024079, 0), (0.57755953, 0), (0.57064724, 0), (0.5565251, 0), (0.550869, 1), (0.52136236, 0), (0.5190266, 0), (0.5174317, 1), (0.48086968, 0), (0.47693545, 0), (0.4689865, 1), (0.4689313, 0), (0.46800503, 0), (0.4677118, 0), (0.46510336, 0), (0.4592671, 0), (0.45701495, 0), (0.4543571, 0), (0.4520115, 1), (0.45200628, 1), (0.45134503, 0), (0.4469803, 0), (0.4441359, 0), (0.41410035, 0), (0.4093578, 0), (0.39823538, 1), (0.3565675, 0), (0.34238264, 1), (0.27682614, 0), (0.24790934, 1), (0.102396466, 1), (0.069572814, 0), (0.0, 0)]
0.2
0.1
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502258D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - ETA: 0s - loss: 0.5514 - auc: 0.5242WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235594A7E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5514 - auc: 0.5242 - val_loss: 0.2980 - val_auc: 0.5026
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5304 - auc: 0.6064 - val_loss: 0.3105 - val_auc: 0.6609
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5187 - auc: 0.6486 - val_loss: 0.2772 - val_auc: 0.5255
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5165 - auc: 0.6328 - val_loss: 0.3305 - val_auc: 0.6177
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5113 - auc: 0.6388 - val_loss: 0.2677 - val_auc: 0.6307
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5231 - auc: 0.6246 - val_loss: 0.2924 - val_auc: 0.5906
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6489 - val_loss: 0.2905 - val_auc: 0.6130
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6491 - val_loss: 0.2972 - val_auc: 0.6687
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5058 - auc: 0.6596 - val_loss: 0.3036 - val_auc: 0.5885
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6714 - val_loss: 0.2942 - val_auc: 0.6667
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5136 - auc: 0.6637 - val_loss: 0.3161 - val_auc: 0.7573
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6459 - val_loss: 0.2923 - val_auc: 0.6427
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5143 - auc: 0.6601 - val_loss: 0.2914 - val_auc: 0.6792
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6936 - val_loss: 0.2987 - val_auc: 0.7661
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5066 - auc: 0.6587 - val_loss: 0.3049 - val_auc: 0.6302
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6833 - val_loss: 0.2824 - val_auc: 0.6755
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4892 - auc: 0.7109 - val_loss: 0.2922 - val_auc: 0.6875
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6889 - val_loss: 0.2823 - val_auc: 0.6969
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5026 - auc: 0.6800 - val_loss: 0.2811 - val_auc: 0.7036
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.7005 - val_loss: 0.2783 - val_auc: 0.6714
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FAEDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.792132, 1), (0.7116548, 0), (0.6160351, 0), (0.56713307, 0), (0.47788924, 0), (0.4595459, 0), (0.45850834, 1), (0.45626566, 0), (0.45531544, 0), (0.45429912, 0), (0.45380998, 0), (0.45278618, 0), (0.45201424, 0), (0.45145392, 0), (0.451279, 0), (0.45043987, 0), (0.44983524, 0), (0.44978985, 0), (0.44927412, 0), (0.44923046, 0), (0.44906127, 1), (0.4490148, 0), (0.4489395, 0), (0.44878447, 0), (0.44780234, 0), (0.4477015, 0), (0.4477015, 0), (0.4477015, 0), (0.44350204, 0), (0.44145724, 0), (0.41358444, 0), (0.1605454, 0), (0.14453302, 0), (0.12194187, 0), (0.10547042, 0), (0.074400574, 1), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDBEE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/99 [=========================&gt;....] - ETA: 0s - loss: 0.5309 - auc: 0.5642WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C013A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5436 - auc: 0.5605 - val_loss: 0.2570 - val_auc: 0.5188
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5286 - auc: 0.5656 - val_loss: 0.2879 - val_auc: 0.4511
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5237 - auc: 0.5716 - val_loss: 0.2859 - val_auc: 0.5017
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6177 - val_loss: 0.2889 - val_auc: 0.3829
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5153 - auc: 0.6608 - val_loss: 0.2972 - val_auc: 0.3974
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5146 - auc: 0.6287 - val_loss: 0.3016 - val_auc: 0.3663
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6452 - val_loss: 0.2899 - val_auc: 0.4934
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6362 - val_loss: 0.2873 - val_auc: 0.4729
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6779 - val_loss: 0.2784 - val_auc: 0.4660
Epoch 10/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5073 - auc: 0.6406 - val_loss: 0.2798 - val_auc: 0.4343
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6519 - val_loss: 0.2889 - val_auc: 0.4025
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6753 - val_loss: 0.2866 - val_auc: 0.4370
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6463 - val_loss: 0.2914 - val_auc: 0.3895
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.6792 - val_loss: 0.2884 - val_auc: 0.4282
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6685 - val_loss: 0.2962 - val_auc: 0.4106
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6634 - val_loss: 0.2860 - val_auc: 0.4069
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6696 - val_loss: 0.2853 - val_auc: 0.4196
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6745 - val_loss: 0.2864 - val_auc: 0.4013
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6785 - val_loss: 0.2903 - val_auc: 0.3893
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6846 - val_loss: 0.2856 - val_auc: 0.4049
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508100EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 1), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.9828688, 0), (0.7586195, 0), (0.5117072, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F99708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - ETA: 0s - loss: 0.5184 - auc: 0.5012WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502B9C318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.5184 - auc: 0.5012 - val_loss: 0.2669 - val_auc: 0.5050
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.5969 - val_loss: 0.2574 - val_auc: 0.5585
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5031 - auc: 0.5479 - val_loss: 0.2679 - val_auc: 0.5860
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6610 - val_loss: 0.2549 - val_auc: 0.5800
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.5974 - val_loss: 0.2509 - val_auc: 0.5688
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6678 - val_loss: 0.2609 - val_auc: 0.6657
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.6666 - val_loss: 0.2346 - val_auc: 0.4074
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.6575 - val_loss: 0.2590 - val_auc: 0.4772
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4817 - auc: 0.6589 - val_loss: 0.2705 - val_auc: 0.5255
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4762 - auc: 0.6793 - val_loss: 0.2640 - val_auc: 0.4798
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.6959 - val_loss: 0.2666 - val_auc: 0.4547
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4694 - auc: 0.6960 - val_loss: 0.2725 - val_auc: 0.4699
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4710 - auc: 0.6987 - val_loss: 0.2650 - val_auc: 0.5470
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.6791 - val_loss: 0.2675 - val_auc: 0.6121
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6658 - val_loss: 0.2594 - val_auc: 0.6442
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.6847 - val_loss: 0.2678 - val_auc: 0.5083
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4742 - auc: 0.6815 - val_loss: 0.2708 - val_auc: 0.5460
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4679 - auc: 0.7027 - val_loss: 0.2632 - val_auc: 0.5331
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4741 - auc: 0.6827 - val_loss: 0.2590 - val_auc: 0.5489
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4742 - auc: 0.7057 - val_loss: 0.2751 - val_auc: 0.5691
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.89594287, 1), (0.69735694, 1), (0.6903105, 0), (0.50845116, 0), (0.47056958, 1), (0.3449187, 0), (0.3402232, 0), (0.2943683, 0), (0.26802823, 0), (0.23360975, 0), (0.23209107, 0), (0.17477708, 1), (0.1559566, 1), (0.14297229, 0), (0.14133991, 1), (0.13589172, 1), (0.11741289, 0), (0.102443725, 1), (0.07572648, 0), (0.06006543, 0), (0.05456356, 0), (0.05019219, 0), (0.0451975, 0), (0.040212207, 0), (0.029443586, 1), (0.023938451, 0), (0.02289551, 0), (0.016823594, 0), (0.014870988, 1), (0.014101539, 1), (0.006333161, 0), (0.0015019572, 1), (0.0, 1), (0.0, 0), (0.0, 1), (0.0, 0), (0.0, 0)]
0.6
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350769D1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/99 [=========================&gt;....] - ETA: 0s - loss: 0.5261 - auc: 0.5104WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FF10D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5330 - auc: 0.5415 - val_loss: 0.3009 - val_auc: 0.4745
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5299 - auc: 0.5770 - val_loss: 0.2996 - val_auc: 0.5212
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5218 - auc: 0.6047 - val_loss: 0.2907 - val_auc: 0.5356
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5156 - auc: 0.6343 - val_loss: 0.2951 - val_auc: 0.5685
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6517 - val_loss: 0.3083 - val_auc: 0.5176
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5167 - auc: 0.6366 - val_loss: 0.2963 - val_auc: 0.5590
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5183 - auc: 0.6266 - val_loss: 0.2848 - val_auc: 0.5376
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6646 - val_loss: 0.3122 - val_auc: 0.5376
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5037 - auc: 0.6539 - val_loss: 0.2972 - val_auc: 0.5770
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6940 - val_loss: 0.3078 - val_auc: 0.5525
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4869 - auc: 0.7040 - val_loss: 0.2980 - val_auc: 0.4820
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5026 - auc: 0.6736 - val_loss: 0.2868 - val_auc: 0.5577
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.6963 - val_loss: 0.3015 - val_auc: 0.5268
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.7105 - val_loss: 0.3053 - val_auc: 0.5239
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.7088 - val_loss: 0.3203 - val_auc: 0.5264
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5069 - auc: 0.6780 - val_loss: 0.3159 - val_auc: 0.5561
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.7129 - val_loss: 0.3145 - val_auc: 0.5401
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6964 - val_loss: 0.2900 - val_auc: 0.5905
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.7172 - val_loss: 0.2855 - val_auc: 0.5214
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6997 - val_loss: 0.2986 - val_auc: 0.5561
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508324288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.89442104, 0), (0.8062221, 0), (0.7896948, 0), (0.78082573, 0), (0.73727316, 0), (0.72285074, 0), (0.6954403, 0), (0.6826155, 0), (0.6794553, 0), (0.6659166, 0), (0.66550493, 0), (0.6517562, 0), (0.6514791, 0), (0.6513151, 0), (0.65103656, 0), (0.64870346, 0), (0.643826, 0), (0.62300044, 0), (0.62036556, 0), (0.61763287, 0), (0.603822, 0), (0.5924675, 0), (0.59036666, 0), (0.57617754, 0), (0.5465633, 0), (0.546361, 0), (0.5343332, 0), (0.5327253, 0), (0.4930699, 0), (0.47165263, 0), (0.42407843, 0), (0.40960905, 0), (0.36193544, 0), (0.32206106, 0), (0.2753031, 0), (0.12472966, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503485318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/99 [=========================&gt;....] - ETA: 0s - loss: 0.5784 - auc: 0.5819WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.5698 - auc: 0.5816 - val_loss: 0.2395 - val_auc: 0.3822
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5561 - auc: 0.5774 - val_loss: 0.2363 - val_auc: 0.5394
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5291 - auc: 0.6022 - val_loss: 0.2392 - val_auc: 0.6827
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5147 - auc: 0.6534 - val_loss: 0.2481 - val_auc: 0.4941
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5091 - auc: 0.6458 - val_loss: 0.2673 - val_auc: 0.5245
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6601 - val_loss: 0.2605 - val_auc: 0.6414
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5103 - auc: 0.6240 - val_loss: 0.2607 - val_auc: 0.5646
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.6870 - val_loss: 0.2824 - val_auc: 0.6453
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6453 - val_loss: 0.2735 - val_auc: 0.5869
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6793 - val_loss: 0.2797 - val_auc: 0.5514
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4771 - auc: 0.6988 - val_loss: 0.2817 - val_auc: 0.5811
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6776 - val_loss: 0.2896 - val_auc: 0.5034
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.6847 - val_loss: 0.2872 - val_auc: 0.4516
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4941 - auc: 0.6885 - val_loss: 0.2899 - val_auc: 0.5417
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4893 - auc: 0.6613 - val_loss: 0.2882 - val_auc: 0.5477
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.7024 - val_loss: 0.3004 - val_auc: 0.5405
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7043 - val_loss: 0.2925 - val_auc: 0.5782
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4783 - auc: 0.6976 - val_loss: 0.2948 - val_auc: 0.5793
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4843 - auc: 0.6783 - val_loss: 0.2918 - val_auc: 0.5962
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.7062 - val_loss: 0.2973 - val_auc: 0.5117
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FAECA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8403888, 0), (0.76401573, 0), (0.5321763, 0), (0.444123, 1), (0.27805987, 0), (0.27782425, 0), (0.23587376, 0), (0.18769234, 0), (0.13673815, 0), (0.12321669, 1), (0.10986214, 1), (0.10299976, 0), (0.10253581, 0), (0.098466046, 0), (0.09353054, 0), (0.0893884, 0), (0.0718199, 1), (0.07169303, 0), (0.06875083, 0), (0.053463627, 0), (0.038038198, 0), (0.031712938, 0), (0.023260774, 0), (0.017086638, 0), (0.010268924, 0), (0.009121729, 0), (0.0077962657, 0), (0.0063620317, 0), (0.0053632655, 0), (0.004626897, 0), (0.004626897, 0), (0.004626897, 0), (0.004626897, 0), (0.004626897, 1), (0.004626897, 0), (0.004626897, 0), (0.0, 1)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350AB70558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/99 [==========================&gt;...] - ETA: 0s - loss: 0.4918 - auc: 0.5277WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350769D8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.4882 - auc: 0.5348 - val_loss: 0.3000 - val_auc: 0.6152
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.5357 - val_loss: 0.3034 - val_auc: 0.6284
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.5632 - val_loss: 0.3137 - val_auc: 0.4668
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4838 - auc: 0.5791 - val_loss: 0.3096 - val_auc: 0.5951
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4705 - auc: 0.6275 - val_loss: 0.3160 - val_auc: 0.4394
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4703 - auc: 0.6236 - val_loss: 0.2934 - val_auc: 0.6288
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.5619 - val_loss: 0.3059 - val_auc: 0.7145
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4814 - auc: 0.5863 - val_loss: 0.3084 - val_auc: 0.6473
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4700 - auc: 0.6436 - val_loss: 0.3147 - val_auc: 0.7046
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4560 - auc: 0.6620 - val_loss: 0.3070 - val_auc: 0.7222
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4729 - auc: 0.6248 - val_loss: 0.3062 - val_auc: 0.6288
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4720 - auc: 0.6435 - val_loss: 0.3067 - val_auc: 0.6760
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4619 - auc: 0.6600 - val_loss: 0.3091 - val_auc: 0.6313
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4612 - auc: 0.6614 - val_loss: 0.3072 - val_auc: 0.6419
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4668 - auc: 0.6328 - val_loss: 0.3082 - val_auc: 0.6073
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4628 - auc: 0.6680 - val_loss: 0.3172 - val_auc: 0.6366
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4698 - auc: 0.6522 - val_loss: 0.3132 - val_auc: 0.7086
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4617 - auc: 0.6479 - val_loss: 0.3043 - val_auc: 0.5830
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4708 - auc: 0.6291 - val_loss: 0.3164 - val_auc: 0.5355
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4677 - auc: 0.6582 - val_loss: 0.3123 - val_auc: 0.4885
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.5595627, 0), (0.4620713, 1), (0.45909223, 0), (0.38043192, 1), (0.23981941, 0), (0.23550439, 0), (0.20338887, 1), (0.16828609, 0), (0.1670583, 1), (0.16477622, 0), (0.15946613, 0), (0.14584345, 1), (0.13128813, 1), (0.12719996, 1), (0.121172376, 1), (0.07886696, 1), (0.047905084, 0), (0.030130057, 1), (0.01978745, 1), (0.0134430155, 1), (0.0011436748, 1), (0.0, 1), (0.0, 0), (0.0, 1), (0.0, 1), (0.0, 0), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 1), (0.0, 0), (0.0, 0), (0.0, 1), (0.0, 0), (0.0, 1), (0.0, 1), (0.0, 0)]
0.5
0.041666666666666664
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557BDBDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.6661 - auc: 0.5420WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB7678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.6698 - auc: 0.5378 - val_loss: 0.5194 - val_auc: 0.5886
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5918 - auc: 0.5772 - val_loss: 0.3794 - val_auc: 0.5973
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5479 - auc: 0.6331 - val_loss: 0.4570 - val_auc: 0.6741
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5445 - auc: 0.5975 - val_loss: 0.4539 - val_auc: 0.5942
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5246 - auc: 0.6229 - val_loss: 0.4250 - val_auc: 0.6510
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5115 - auc: 0.6416 - val_loss: 0.3882 - val_auc: 0.6065
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6725 - val_loss: 0.3470 - val_auc: 0.5554
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4819 - auc: 0.6972 - val_loss: 0.3326 - val_auc: 0.5349
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6825 - val_loss: 0.3803 - val_auc: 0.5750
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4838 - auc: 0.6868 - val_loss: 0.3344 - val_auc: 0.6060
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6814 - val_loss: 0.3614 - val_auc: 0.5829
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6899 - val_loss: 0.3630 - val_auc: 0.6043
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.6938 - val_loss: 0.3018 - val_auc: 0.6348
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4737 - auc: 0.7022 - val_loss: 0.3534 - val_auc: 0.5716
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4790 - auc: 0.7038 - val_loss: 0.3114 - val_auc: 0.5772
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.6908 - val_loss: 0.3136 - val_auc: 0.6147
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.6870 - val_loss: 0.3272 - val_auc: 0.5759
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4691 - auc: 0.7098 - val_loss: 0.2929 - val_auc: 0.5733
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4754 - auc: 0.7174 - val_loss: 0.2913 - val_auc: 0.5755
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.6892 - val_loss: 0.3017 - val_auc: 0.6444
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235038CF048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.95881355, 0), (0.90302575, 0), (0.90302575, 0), (0.90302575, 0), (0.90302575, 1), (0.8599032, 1), (0.83535814, 0), (0.8106147, 1), (0.7649915, 0), (0.758034, 0), (0.7458422, 1), (0.7439176, 0), (0.7435309, 0), (0.72232115, 1), (0.6881289, 0), (0.6876225, 0), (0.6798762, 1), (0.66478837, 0), (0.65310806, 0), (0.6525484, 1), (0.6408531, 0), (0.63328964, 1), (0.616212, 0), (0.57303, 0), (0.5122043, 0), (0.43168992, 1), (0.38784698, 0), (0.3862576, 0), (0.3493671, 0), (0.3441434, 0), (0.3380247, 0), (0.2548359, 1), (0.25237587, 1), (0.2019179, 0), (0.19491489, 0), (0.10815427, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002355829A798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.5460 - auc: 0.5547 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023509909A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.5327 - auc: 0.5591 - val_loss: 0.2481 - val_auc: 0.6915
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5158 - auc: 0.6076 - val_loss: 0.2645 - val_auc: 0.6204
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5292 - auc: 0.6122 - val_loss: 0.2636 - val_auc: 0.5794
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.6266 - val_loss: 0.2575 - val_auc: 0.6558
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4767 - auc: 0.7104 - val_loss: 0.2532 - val_auc: 0.6610
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5125 - auc: 0.6562 - val_loss: 0.2838 - val_auc: 0.5668
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5059 - auc: 0.6518 - val_loss: 0.2593 - val_auc: 0.6802
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5121 - auc: 0.6532 - val_loss: 0.2680 - val_auc: 0.7024
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5147 - auc: 0.6622 - val_loss: 0.2933 - val_auc: 0.6706
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5025 - auc: 0.6896 - val_loss: 0.2585 - val_auc: 0.6156
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.7080 - val_loss: 0.2933 - val_auc: 0.6274
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5277 - auc: 0.6201 - val_loss: 0.3015 - val_auc: 0.6313
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.6616 - val_loss: 0.2882 - val_auc: 0.6928
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5042 - auc: 0.6876 - val_loss: 0.2818 - val_auc: 0.7134
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6866 - val_loss: 0.2830 - val_auc: 0.7016
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.7089 - val_loss: 0.2810 - val_auc: 0.7134
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.7040 - val_loss: 0.3068 - val_auc: 0.7003
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4901 - auc: 0.7040 - val_loss: 0.2748 - val_auc: 0.6784
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.6698 - val_loss: 0.2755 - val_auc: 0.6872
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4964 - auc: 0.6741 - val_loss: 0.2734 - val_auc: 0.7134
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9754316, 0), (0.9732152, 0), (0.8474301, 0), (0.84557956, 0), (0.81809455, 0), (0.81440085, 0), (0.80913216, 0), (0.8018645, 0), (0.7924822, 0), (0.79213166, 0), (0.7785017, 0), (0.7725081, 1), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7725081, 0), (0.7427344, 0), (0.735706, 0), (0.6787643, 0), (0.6669101, 0), (0.6661352, 0), (0.6596704, 1), (0.6468949, 0), (0.6366265, 0), (0.60027486, 0), (0.52776, 0), (0.4591752, 1), (0.44478005, 0), (0.38406986, 1), (0.3345416, 0), (0.26628697, 0), (0.14654228, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F99948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/99 [==========================&gt;...] - ETA: 0s - loss: 0.5975 - auc: 0.4961WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235022583A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5858 - auc: 0.5119 - val_loss: 0.4241 - val_auc: 0.3725
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5331 - auc: 0.6158 - val_loss: 0.3217 - val_auc: 0.4551
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5238 - auc: 0.6237 - val_loss: 0.3694 - val_auc: 0.3676
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5108 - auc: 0.6509 - val_loss: 0.3338 - val_auc: 0.4024
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5064 - auc: 0.6508 - val_loss: 0.3216 - val_auc: 0.3864
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5144 - auc: 0.6409 - val_loss: 0.3510 - val_auc: 0.3714
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6490 - val_loss: 0.3283 - val_auc: 0.4543
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4822 - auc: 0.6974 - val_loss: 0.3073 - val_auc: 0.4163
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5121 - auc: 0.6575 - val_loss: 0.3171 - val_auc: 0.4233
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6549 - val_loss: 0.3139 - val_auc: 0.4930
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5062 - auc: 0.6597 - val_loss: 0.3304 - val_auc: 0.4019
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6752 - val_loss: 0.3051 - val_auc: 0.4882
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4948 - auc: 0.6910 - val_loss: 0.3136 - val_auc: 0.4051
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.6995 - val_loss: 0.3074 - val_auc: 0.4711
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6851 - val_loss: 0.3167 - val_auc: 0.4110
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.7043 - val_loss: 0.3062 - val_auc: 0.4356
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5051 - auc: 0.6876 - val_loss: 0.3359 - val_auc: 0.3963
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.7096 - val_loss: 0.3383 - val_auc: 0.4053
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4968 - auc: 0.6779 - val_loss: 0.3144 - val_auc: 0.4586
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6850 - val_loss: 0.3250 - val_auc: 0.4187
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.91929704, 0), (0.8238833, 0), (0.8210367, 1), (0.79681206, 0), (0.795346, 0), (0.7659693, 0), (0.75535184, 0), (0.7330199, 0), (0.721416, 0), (0.7200568, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.71980107, 0), (0.7029143, 0), (0.6970066, 0), (0.69396734, 0), (0.65346074, 0), (0.64218736, 0), (0.6195057, 0), (0.61217386, 1), (0.58923256, 0), (0.57855135, 0), (0.5782635, 0), (0.56809866, 0), (0.5610186, 0), (0.5333255, 0), (0.5126164, 0), (0.49148345, 0), (0.43247163, 0), (0.2780262, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502EF00D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.6060 - auc: 0.5170 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350AB70CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.6059 - auc: 0.5131 - val_loss: 0.4059 - val_auc: 0.6583
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5484 - auc: 0.5895 - val_loss: 0.4152 - val_auc: 0.6703
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5269 - auc: 0.6146 - val_loss: 0.3476 - val_auc: 0.7146
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5489 - auc: 0.5835 - val_loss: 0.3444 - val_auc: 0.7328
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5123 - auc: 0.6544 - val_loss: 0.3284 - val_auc: 0.7073
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6418 - val_loss: 0.3155 - val_auc: 0.7589
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6579 - val_loss: 0.3277 - val_auc: 0.6797
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5026 - auc: 0.6652 - val_loss: 0.3101 - val_auc: 0.7203
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5089 - auc: 0.6674 - val_loss: 0.2822 - val_auc: 0.7161
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5094 - auc: 0.6728 - val_loss: 0.2878 - val_auc: 0.7453
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.7091 - val_loss: 0.3175 - val_auc: 0.7250
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5115 - auc: 0.6574 - val_loss: 0.2842 - val_auc: 0.7786
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4832 - auc: 0.7099 - val_loss: 0.2691 - val_auc: 0.7297
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6970 - val_loss: 0.2685 - val_auc: 0.7401
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6875 - val_loss: 0.2635 - val_auc: 0.7099
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4992 - auc: 0.7024 - val_loss: 0.2920 - val_auc: 0.7479
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.7171 - val_loss: 0.2626 - val_auc: 0.8307
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.7033 - val_loss: 0.2598 - val_auc: 0.7865
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4829 - auc: 0.7150 - val_loss: 0.2580 - val_auc: 0.7682
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5069 - auc: 0.6944 - val_loss: 0.2620 - val_auc: 0.7328
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023557CC8288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9381408, 0), (0.8283667, 0), (0.73936456, 0), (0.7282861, 0), (0.6997138, 0), (0.6935625, 0), (0.6554238, 1), (0.63848484, 0), (0.6177574, 0), (0.6142936, 0), (0.6123913, 0), (0.6062751, 0), (0.60562503, 0), (0.6016812, 0), (0.59958464, 0), (0.596459, 0), (0.5956641, 0), (0.593636, 0), (0.5917256, 1), (0.5894141, 1), (0.5864093, 0), (0.58621037, 0), (0.5749961, 0), (0.5748561, 0), (0.55246145, 0), (0.5408095, 0), (0.54070646, 0), (0.4782949, 0), (0.47803223, 0), (0.45494148, 0), (0.30321708, 0), (0.3022663, 0), (0.24896057, 0), (0.2269784, 1), (0.21829362, 0), (0.16376925, 0), (0.0, 0)]
0.0
0.0
Siam
[0.4, 0.6, 0.0, 0.2, 0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.2, 0.0, 0.6, 0.0, 0.0, 0.5, 0.0, 0.0, 0.2, 0.0]
0.175
[0.2, 0.3333333333333333, 0.0, 0.25, 0.2, 0.125, 0.0, 1.0, 0.0, 0.1, 0.25, 0.0, 0.2, -1.0, 0.0, 0.041666666666666664, 0.0, 0.0, 0.5, 0.0]
0.16842105263157894
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[12]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502258798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/100 [=========================&gt;....] - ETA: 0s - loss: 0.5112 - auc: 0.5722 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502729708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5063 - auc: 0.5796 - val_loss: 0.3029 - val_auc: 0.4787
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6303 - val_loss: 0.3001 - val_auc: 0.4741
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4739 - auc: 0.6812 - val_loss: 0.3111 - val_auc: 0.3873
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4947 - auc: 0.6617 - val_loss: 0.2937 - val_auc: 0.4671
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4831 - auc: 0.6793 - val_loss: 0.3102 - val_auc: 0.5225
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4848 - auc: 0.6658 - val_loss: 0.2991 - val_auc: 0.4865
Epoch 7/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4821 - auc: 0.6845 - val_loss: 0.3115 - val_auc: 0.5957
Epoch 8/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4809 - auc: 0.6813 - val_loss: 0.2956 - val_auc: 0.5488
Epoch 9/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4884 - auc: 0.6606 - val_loss: 0.3054 - val_auc: 0.5941
Epoch 10/20
100/100 [==============================] - 1s 7ms/step - loss: 0.4741 - auc: 0.6723 - val_loss: 0.2974 - val_auc: 0.5513
Epoch 11/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4666 - auc: 0.7038 - val_loss: 0.2860 - val_auc: 0.5264
Epoch 12/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4725 - auc: 0.6955 - val_loss: 0.2991 - val_auc: 0.4819
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4709 - auc: 0.7003 - val_loss: 0.2770 - val_auc: 0.5638
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4816 - auc: 0.6820 - val_loss: 0.2917 - val_auc: 0.5762
Epoch 15/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4878 - auc: 0.6616 - val_loss: 0.3026 - val_auc: 0.5394
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4708 - auc: 0.6967 - val_loss: 0.2972 - val_auc: 0.4913
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4629 - auc: 0.7084 - val_loss: 0.2900 - val_auc: 0.5566
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4665 - auc: 0.6868 - val_loss: 0.2929 - val_auc: 0.4952
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4849 - auc: 0.6865 - val_loss: 0.2753 - val_auc: 0.5675
Epoch 20/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4638 - auc: 0.7035 - val_loss: 0.2858 - val_auc: 0.5430
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235085900D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.95939285, 0), (0.95051986, 0), (0.9442381, 1), (0.9400554, 0), (0.9334282, 0), (0.9324631, 0), (0.9160174, 1), (0.90691894, 0), (0.8991806, 0), (0.88039494, 1), (0.8768588, 1), (0.8768588, 0), (0.8768588, 0), (0.8768588, 0), (0.8768588, 0), (0.8758981, 1), (0.8731822, 0), (0.8037456, 1), (0.75889087, 1), (0.7587087, 0), (0.7198276, 0), (0.36481026, 1), (0.050879944, 1), (0.0, 0)]
0.4
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503BD9AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.5321 - auc: 0.5272WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235021A7E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 9ms/step - loss: 0.5348 - auc: 0.5229 - val_loss: 0.2808 - val_auc: 0.6596
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5101 - auc: 0.6212 - val_loss: 0.2640 - val_auc: 0.6881
Epoch 3/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5104 - auc: 0.5607 - val_loss: 0.2805 - val_auc: 0.5636
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4903 - auc: 0.6670 - val_loss: 0.2927 - val_auc: 0.6335
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4891 - auc: 0.6715 - val_loss: 0.2787 - val_auc: 0.6458
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5120 - auc: 0.6537 - val_loss: 0.2952 - val_auc: 0.6499
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4975 - auc: 0.6822 - val_loss: 0.2939 - val_auc: 0.6763
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4922 - auc: 0.6692 - val_loss: 0.2967 - val_auc: 0.6883
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4859 - auc: 0.6874 - val_loss: 0.3098 - val_auc: 0.6175
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5076 - auc: 0.6466 - val_loss: 0.3108 - val_auc: 0.6388
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5053 - auc: 0.6633 - val_loss: 0.2997 - val_auc: 0.7367
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4947 - auc: 0.6387 - val_loss: 0.3026 - val_auc: 0.7089
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5017 - auc: 0.6565 - val_loss: 0.3010 - val_auc: 0.6468
Epoch 14/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4859 - auc: 0.6781 - val_loss: 0.3008 - val_auc: 0.6465
Epoch 15/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4799 - auc: 0.6893 - val_loss: 0.3041 - val_auc: 0.6813
Epoch 16/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4953 - auc: 0.6835 - val_loss: 0.3057 - val_auc: 0.6257
Epoch 17/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4802 - auc: 0.6869 - val_loss: 0.2941 - val_auc: 0.5779
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4706 - auc: 0.7216 - val_loss: 0.2956 - val_auc: 0.6470
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4827 - auc: 0.7066 - val_loss: 0.3018 - val_auc: 0.6453
Epoch 20/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4733 - auc: 0.7079 - val_loss: 0.2984 - val_auc: 0.6654
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A77C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.7849623, 0), (0.75276136, 0), (0.7221931, 1), (0.71839976, 0), (0.7148233, 0), (0.71415144, 0), (0.71309054, 0), (0.7051699, 0), (0.6817144, 1), (0.67829144, 0), (0.67483723, 0), (0.6551225, 0), (0.64902174, 0), (0.6463917, 1), (0.62553877, 0), (0.61900264, 0), (0.61340606, 0), (0.59680444, 0), (0.5819868, 0), (0.51672834, 0), (0.49044752, 0), (0.48226684, 0), (0.47275266, 0), (0.0, 0)]
0.4
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503348828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.5306 - auc: 0.5514WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235099095E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 3s 8ms/step - loss: 0.5373 - auc: 0.5455 - val_loss: 0.3019 - val_auc: 0.7763
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5068 - auc: 0.6384 - val_loss: 0.2598 - val_auc: 0.6552
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5116 - auc: 0.6281 - val_loss: 0.2718 - val_auc: 0.6639
Epoch 4/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5158 - auc: 0.6302 - val_loss: 0.2577 - val_auc: 0.7170
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5156 - auc: 0.6321 - val_loss: 0.2674 - val_auc: 0.6753
Epoch 6/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5104 - auc: 0.6458 - val_loss: 0.2558 - val_auc: 0.7418
Epoch 7/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5137 - auc: 0.6419 - val_loss: 0.2456 - val_auc: 0.6134
Epoch 8/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5069 - auc: 0.6733 - val_loss: 0.2554 - val_auc: 0.6469
Epoch 9/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5021 - auc: 0.6675 - val_loss: 0.2768 - val_auc: 0.6624
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4903 - auc: 0.7079 - val_loss: 0.2696 - val_auc: 0.6665
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5014 - auc: 0.6853 - val_loss: 0.2792 - val_auc: 0.6887
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4952 - auc: 0.6869 - val_loss: 0.2534 - val_auc: 0.6665
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4897 - auc: 0.6893 - val_loss: 0.2813 - val_auc: 0.6959
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4787 - auc: 0.7153 - val_loss: 0.2623 - val_auc: 0.6773
Epoch 15/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4849 - auc: 0.7118 - val_loss: 0.2505 - val_auc: 0.6747
Epoch 16/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4859 - auc: 0.7150 - val_loss: 0.2629 - val_auc: 0.6871
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4756 - auc: 0.7238 - val_loss: 0.2451 - val_auc: 0.6825
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4893 - auc: 0.7080 - val_loss: 0.2407 - val_auc: 0.7031
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4908 - auc: 0.6962 - val_loss: 0.2390 - val_auc: 0.7021
Epoch 20/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4828 - auc: 0.7149 - val_loss: 0.2947 - val_auc: 0.6536
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF0DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.84080476, 0), (0.7767417, 0), (0.7693865, 0), (0.69513196, 0), (0.6445419, 0), (0.64330006, 0), (0.63696414, 0), (0.63625115, 0), (0.63128835, 0), (0.61577, 0), (0.61308306, 1), (0.60042876, 0), (0.59900284, 0), (0.5925143, 1), (0.58568627, 0), (0.5760108, 0), (0.57468265, 0), (0.5680925, 0), (0.55990034, 0), (0.55460936, 1), (0.5404635, 0), (0.50561476, 1), (0.49146968, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502B9CF78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/100 [==========================&gt;...] - ETA: 0s - loss: 0.5578 - auc: 0.5126WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023557BDB168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 7ms/step - loss: 0.5523 - auc: 0.5183 - val_loss: 0.3548 - val_auc: 0.6234
Epoch 2/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5330 - auc: 0.5637 - val_loss: 0.3381 - val_auc: 0.6085
Epoch 3/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5237 - auc: 0.5966 - val_loss: 0.3271 - val_auc: 0.4904
Epoch 4/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5121 - auc: 0.6314 - val_loss: 0.2828 - val_auc: 0.6094
Epoch 5/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4937 - auc: 0.6727 - val_loss: 0.2860 - val_auc: 0.4807
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5069 - auc: 0.6536 - val_loss: 0.2783 - val_auc: 0.4175
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5019 - auc: 0.6760 - val_loss: 0.2924 - val_auc: 0.5480
Epoch 8/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4976 - auc: 0.6845 - val_loss: 0.2682 - val_auc: 0.6877
Epoch 9/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4874 - auc: 0.6937 - val_loss: 0.2924 - val_auc: 0.6944
Epoch 10/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4986 - auc: 0.7135 - val_loss: 0.2962 - val_auc: 0.6330
Epoch 11/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5042 - auc: 0.6747 - val_loss: 0.2941 - val_auc: 0.7684
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5134 - auc: 0.6545 - val_loss: 0.3057 - val_auc: 0.6120
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4933 - auc: 0.6820 - val_loss: 0.3011 - val_auc: 0.5325
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4783 - auc: 0.7261 - val_loss: 0.2915 - val_auc: 0.5535
Epoch 15/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4854 - auc: 0.6817 - val_loss: 0.2955 - val_auc: 0.5962
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4773 - auc: 0.7111 - val_loss: 0.2854 - val_auc: 0.6304
Epoch 17/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4964 - auc: 0.6959 - val_loss: 0.2750 - val_auc: 0.5599
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4885 - auc: 0.7116 - val_loss: 0.2932 - val_auc: 0.5734
Epoch 19/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4818 - auc: 0.7137 - val_loss: 0.2893 - val_auc: 0.5532
Epoch 20/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4923 - auc: 0.6978 - val_loss: 0.3016 - val_auc: 0.5096
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502729E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7629309, 0), (0.71540326, 0), (0.604682, 0), (0.6015129, 0), (0.59702927, 0), (0.58761925, 0), (0.5753302, 0), (0.57148385, 0), (0.57095295, 0), (0.5695174, 0), (0.5576568, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.5569775, 0), (0.4668531, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502258438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/100 [============================&gt;.] - ETA: 0s - loss: 0.6475 - auc: 0.5392WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.6469 - auc: 0.5396 - val_loss: 0.4061 - val_auc: 0.6801
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5797 - auc: 0.5588 - val_loss: 0.4033 - val_auc: 0.4449
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5270 - auc: 0.6274 - val_loss: 0.4226 - val_auc: 0.5521
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5503 - auc: 0.5906 - val_loss: 0.4304 - val_auc: 0.5502
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5331 - auc: 0.6045 - val_loss: 0.3765 - val_auc: 0.5744
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5230 - auc: 0.5999 - val_loss: 0.3775 - val_auc: 0.6510
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6614 - val_loss: 0.3640 - val_auc: 0.5688
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6534 - val_loss: 0.3612 - val_auc: 0.6228
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5141 - auc: 0.6378 - val_loss: 0.3427 - val_auc: 0.5978
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5090 - auc: 0.6459 - val_loss: 0.3285 - val_auc: 0.6172
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4870 - auc: 0.6973 - val_loss: 0.3350 - val_auc: 0.5941
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6896 - val_loss: 0.3136 - val_auc: 0.6871
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4882 - auc: 0.6988 - val_loss: 0.3175 - val_auc: 0.6257
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4978 - auc: 0.6817 - val_loss: 0.3051 - val_auc: 0.6436
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6973 - val_loss: 0.2962 - val_auc: 0.6339
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.7144 - val_loss: 0.3165 - val_auc: 0.6775
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.7030 - val_loss: 0.3082 - val_auc: 0.6715
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4705 - auc: 0.7272 - val_loss: 0.3138 - val_auc: 0.7121
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.7093 - val_loss: 0.3040 - val_auc: 0.7340
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7063 - val_loss: 0.3226 - val_auc: 0.6987
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503880798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9622608, 0), (0.888432, 0), (0.88571364, 0), (0.8774151, 1), (0.85728294, 0), (0.85536844, 0), (0.85302776, 0), (0.8082003, 0), (0.80504394, 0), (0.7952254, 0), (0.7900616, 1), (0.7874225, 0), (0.76930356, 0), (0.7611819, 0), (0.7457087, 0), (0.73217714, 1), (0.69808984, 0), (0.69434816, 0), (0.654426, 0), (0.65091425, 1), (0.5954067, 0), (0.42325917, 0), (0.3682159, 0), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350AB704C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/100 [=========================&gt;....] - ETA: 0s - loss: 0.6100 - auc: 0.5002 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235095933A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.6015 - auc: 0.5020 - val_loss: 0.4093 - val_auc: 0.5450
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5588 - auc: 0.5520 - val_loss: 0.4090 - val_auc: 0.6579
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5350 - auc: 0.5764 - val_loss: 0.4507 - val_auc: 0.5904
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6361 - val_loss: 0.3421 - val_auc: 0.6407
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6456 - val_loss: 0.3577 - val_auc: 0.7224
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4962 - auc: 0.6631 - val_loss: 0.3593 - val_auc: 0.7072
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6541 - val_loss: 0.3264 - val_auc: 0.7302
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.6554 - val_loss: 0.3303 - val_auc: 0.6760
Epoch 9/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4835 - auc: 0.6808 - val_loss: 0.3418 - val_auc: 0.6954
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4721 - auc: 0.6904 - val_loss: 0.3415 - val_auc: 0.6663
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6999 - val_loss: 0.3323 - val_auc: 0.6891
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7017 - val_loss: 0.3187 - val_auc: 0.6782
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4846 - auc: 0.6987 - val_loss: 0.3184 - val_auc: 0.6485
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.6998 - val_loss: 0.3272 - val_auc: 0.6598
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7152 - val_loss: 0.3337 - val_auc: 0.6475
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4638 - auc: 0.7324 - val_loss: 0.3084 - val_auc: 0.6572
Epoch 17/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4897 - auc: 0.6811 - val_loss: 0.3149 - val_auc: 0.6789
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.6959 - val_loss: 0.2999 - val_auc: 0.6929
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6976 - val_loss: 0.3145 - val_auc: 0.6879
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4693 - auc: 0.7303 - val_loss: 0.3047 - val_auc: 0.6796
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503880F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.85333073, 1), (0.79409134, 0), (0.7859932, 0), (0.77536124, 0), (0.76330316, 0), (0.76201916, 0), (0.7602487, 0), (0.7598249, 0), (0.7597584, 0), (0.75551593, 1), (0.7532888, 0), (0.74506783, 1), (0.7354019, 0), (0.65199715, 0), (0.62142944, 0), (0.58071226, 0), (0.5445491, 0), (0.51190835, 0), (0.5111967, 1), (0.4602985, 0), (0.38701248, 1), (0.35577503, 0), (0.27759126, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504C01318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/100 [=========================&gt;....] - ETA: 0s - loss: 0.5311 - auc: 0.4896WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235044978B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5341 - auc: 0.4910 - val_loss: 0.2929 - val_auc: 0.6605
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5249 - auc: 0.5545 - val_loss: 0.2879 - val_auc: 0.6233
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.6357 - val_loss: 0.2903 - val_auc: 0.5653
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.6527 - val_loss: 0.3140 - val_auc: 0.6337
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6345 - val_loss: 0.2774 - val_auc: 0.6119
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6771 - val_loss: 0.2984 - val_auc: 0.6390
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.6708 - val_loss: 0.3005 - val_auc: 0.5916
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4653 - auc: 0.7105 - val_loss: 0.2919 - val_auc: 0.5329
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6552 - val_loss: 0.2979 - val_auc: 0.6066
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.6865 - val_loss: 0.2838 - val_auc: 0.6424
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4622 - auc: 0.6990 - val_loss: 0.2949 - val_auc: 0.4942
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.6892 - val_loss: 0.2909 - val_auc: 0.5916
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6464 - val_loss: 0.3022 - val_auc: 0.6105
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.6726 - val_loss: 0.2947 - val_auc: 0.6049
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.6652 - val_loss: 0.2937 - val_auc: 0.5278
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7092 - val_loss: 0.3121 - val_auc: 0.5094
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4754 - auc: 0.6980 - val_loss: 0.2847 - val_auc: 0.6132
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6914 - val_loss: 0.3065 - val_auc: 0.6286
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4762 - auc: 0.6955 - val_loss: 0.2880 - val_auc: 0.6700
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4745 - auc: 0.6921 - val_loss: 0.2779 - val_auc: 0.6371
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503F99EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.80792755, 0), (0.78640735, 1), (0.7663878, 0), (0.763091, 0), (0.763091, 0), (0.7470824, 0), (0.7465859, 0), (0.74155825, 1), (0.7338947, 1), (0.73159736, 0), (0.7314985, 1), (0.7286023, 0), (0.7231652, 0), (0.72197336, 0), (0.71364766, 0), (0.7121001, 0), (0.69897324, 0), (0.6925265, 0), (0.4960575, 1), (0.33496568, 0), (0.2611484, 0), (0.2216973, 1), (0.13504115, 1), (0.0, 0)]
0.4
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503BD94C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/100 [=========================&gt;....] - ETA: 0s - loss: 0.6629 - auc: 0.4839 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF0828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 7ms/step - loss: 0.6558 - auc: 0.4935 - val_loss: 0.6384 - val_auc: 0.5067
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5599 - auc: 0.5645 - val_loss: 0.4625 - val_auc: 0.5193
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5339 - auc: 0.6213 - val_loss: 0.4671 - val_auc: 0.6538
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5204 - auc: 0.6449 - val_loss: 0.3984 - val_auc: 0.5354
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5068 - auc: 0.6661 - val_loss: 0.4284 - val_auc: 0.5117
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5322 - auc: 0.6373 - val_loss: 0.4091 - val_auc: 0.6120
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.7038 - val_loss: 0.3443 - val_auc: 0.5722
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5141 - auc: 0.6569 - val_loss: 0.3763 - val_auc: 0.5825
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6796 - val_loss: 0.3576 - val_auc: 0.5336
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.6874 - val_loss: 0.3425 - val_auc: 0.5804
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5066 - auc: 0.6641 - val_loss: 0.3550 - val_auc: 0.5488
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.6996 - val_loss: 0.3451 - val_auc: 0.5137
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4850 - auc: 0.7038 - val_loss: 0.3312 - val_auc: 0.5570
Epoch 14/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4893 - auc: 0.7014 - val_loss: 0.3304 - val_auc: 0.5605
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7046 - val_loss: 0.3191 - val_auc: 0.4731
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5006 - auc: 0.6924 - val_loss: 0.3200 - val_auc: 0.5904
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.7127 - val_loss: 0.2993 - val_auc: 0.6529
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4825 - auc: 0.7309 - val_loss: 0.3120 - val_auc: 0.5898
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4695 - auc: 0.7312 - val_loss: 0.2998 - val_auc: 0.4971
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7094 - val_loss: 0.3148 - val_auc: 0.5351
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235099090D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9859496, 0), (0.982671, 0), (0.9741059, 0), (0.9608034, 1), (0.95798844, 0), (0.9520702, 0), (0.93074954, 0), (0.894906, 0), (0.8837818, 0), (0.8197813, 0), (0.808072, 0), (0.8008769, 0), (0.79108787, 0), (0.78595597, 0), (0.77642226, 0), (0.7370053, 0), (0.7024722, 0), (0.5349567, 0), (0.45405203, 0), (0.43658078, 0), (0.4212115, 0), (0.39280242, 0), (0.06837035, 0), (0.0, 0)]
0.2
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503FF1C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/100 [=========================&gt;....] - ETA: 0s - loss: 0.5422 - auc: 0.5430WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235038CF438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5355 - auc: 0.5502 - val_loss: 0.3213 - val_auc: 0.5463
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5067 - auc: 0.6467 - val_loss: 0.3315 - val_auc: 0.6471
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5118 - auc: 0.6198 - val_loss: 0.3116 - val_auc: 0.5902
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6619 - val_loss: 0.2997 - val_auc: 0.6426
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5021 - auc: 0.6648 - val_loss: 0.3131 - val_auc: 0.5586
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6508 - val_loss: 0.3355 - val_auc: 0.5501
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6725 - val_loss: 0.3340 - val_auc: 0.5619
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.6950 - val_loss: 0.3250 - val_auc: 0.6221
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6544 - val_loss: 0.3055 - val_auc: 0.7016
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6691 - val_loss: 0.3198 - val_auc: 0.5871
Epoch 11/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4892 - auc: 0.6984 - val_loss: 0.3267 - val_auc: 0.5704
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4909 - auc: 0.6989 - val_loss: 0.3292 - val_auc: 0.6974
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6762 - val_loss: 0.3281 - val_auc: 0.5980
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4926 - auc: 0.7065 - val_loss: 0.3222 - val_auc: 0.6390
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4938 - auc: 0.7037 - val_loss: 0.3193 - val_auc: 0.5746
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6927 - val_loss: 0.3184 - val_auc: 0.5689
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4814 - auc: 0.7140 - val_loss: 0.3076 - val_auc: 0.5965
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.7020 - val_loss: 0.3272 - val_auc: 0.5497
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.6838 - val_loss: 0.3110 - val_auc: 0.5664
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.7111 - val_loss: 0.3113 - val_auc: 0.6054
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9758954, 0), (0.9758954, 0), (0.97521293, 0), (0.9626844, 0), (0.9616413, 1), (0.9568553, 0), (0.9548614, 0), (0.95393646, 0), (0.9439845, 0), (0.94170976, 0), (0.93863606, 0), (0.9341168, 0), (0.92152643, 0), (0.91616094, 0), (0.9101865, 0), (0.9095029, 0), (0.7824272, 0), (0.662719, 0), (0.46647972, 0), (0.451141, 0), (0.41231114, 0), (0.34933355, 0), (0.32127088, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023E0708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/100 [=========================&gt;....] - ETA: 0s - loss: 0.5127 - auc: 0.5698 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350A17FC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 7ms/step - loss: 0.5232 - auc: 0.5647 - val_loss: 0.3222 - val_auc: 0.5541
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.6434 - val_loss: 0.3474 - val_auc: 0.5971
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5100 - auc: 0.6212 - val_loss: 0.3298 - val_auc: 0.5853
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6584 - val_loss: 0.3577 - val_auc: 0.5004
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4882 - auc: 0.6829 - val_loss: 0.3127 - val_auc: 0.6178
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6700 - val_loss: 0.3079 - val_auc: 0.6017
Epoch 7/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4933 - auc: 0.6582 - val_loss: 0.3244 - val_auc: 0.4349
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.6779 - val_loss: 0.3366 - val_auc: 0.5077
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4833 - auc: 0.6860 - val_loss: 0.3380 - val_auc: 0.4568
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.6964 - val_loss: 0.3339 - val_auc: 0.5500
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4780 - auc: 0.6980 - val_loss: 0.3231 - val_auc: 0.5324
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.7093 - val_loss: 0.3255 - val_auc: 0.5207
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4578 - auc: 0.7240 - val_loss: 0.3281 - val_auc: 0.4952
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4702 - auc: 0.7145 - val_loss: 0.3196 - val_auc: 0.5172
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4688 - auc: 0.7185 - val_loss: 0.3279 - val_auc: 0.5042
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4680 - auc: 0.7000 - val_loss: 0.3170 - val_auc: 0.5486
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.7104 - val_loss: 0.3115 - val_auc: 0.5988
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4597 - auc: 0.7228 - val_loss: 0.3375 - val_auc: 0.5317
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6861 - val_loss: 0.3330 - val_auc: 0.5440
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4612 - auc: 0.7296 - val_loss: 0.3378 - val_auc: 0.5098
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235083249D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9047233, 0), (0.88141286, 0), (0.79728204, 0), (0.7922626, 0), (0.78991747, 0), (0.7867309, 0), (0.78579384, 0), (0.7812995, 0), (0.7787879, 1), (0.7740228, 1), (0.7642564, 0), (0.75043356, 1), (0.7466977, 1), (0.7460982, 0), (0.7457509, 0), (0.74564826, 0), (0.6824943, 1), (0.67991674, 0), (0.6295632, 0), (0.3228047, 0), (0.30350423, 0), (0.29829514, 0), (0.27941632, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B5B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - ETA: 0s - loss: 0.6186 - auc: 0.5919WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FF1AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.6186 - auc: 0.5919 - val_loss: 0.6203 - val_auc: 0.5071
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5960 - auc: 0.5259 - val_loss: 0.4286 - val_auc: 0.5115
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5352 - auc: 0.6081 - val_loss: 0.4541 - val_auc: 0.5499
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5216 - auc: 0.6540 - val_loss: 0.3710 - val_auc: 0.6473
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5150 - auc: 0.6498 - val_loss: 0.3565 - val_auc: 0.6443
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5145 - auc: 0.6557 - val_loss: 0.3606 - val_auc: 0.6388
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5121 - auc: 0.6480 - val_loss: 0.3483 - val_auc: 0.7102
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.6902 - val_loss: 0.3297 - val_auc: 0.6514
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.7039 - val_loss: 0.3133 - val_auc: 0.7307
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4870 - auc: 0.7031 - val_loss: 0.3158 - val_auc: 0.6938
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.7083 - val_loss: 0.3081 - val_auc: 0.6938
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.6981 - val_loss: 0.3017 - val_auc: 0.6570
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6804 - val_loss: 0.2971 - val_auc: 0.7199
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6805 - val_loss: 0.2879 - val_auc: 0.7426
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.7070 - val_loss: 0.2941 - val_auc: 0.7455
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.7412 - val_loss: 0.3127 - val_auc: 0.8077
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6706 - val_loss: 0.2968 - val_auc: 0.7805
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4968 - auc: 0.6905 - val_loss: 0.3019 - val_auc: 0.7444
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4783 - auc: 0.7179 - val_loss: 0.2910 - val_auc: 0.7452
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.7324 - val_loss: 0.2750 - val_auc: 0.7660
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235021A7948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9255346, 0), (0.8857455, 0), (0.8480054, 0), (0.8369254, 0), (0.8358826, 0), (0.82836854, 0), (0.82825434, 0), (0.8189834, 0), (0.79909587, 0), (0.79739684, 0), (0.79332364, 0), (0.7834187, 0), (0.7796232, 0), (0.76971054, 0), (0.7535202, 1), (0.71579546, 0), (0.701761, 0), (0.5452567, 0), (0.50368494, 0), (0.27277023, 0), (0.25977564, 1), (0.14554608, 0), (0.07337833, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557F37EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - ETA: 0s - loss: 0.5822 - auc: 0.5425WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503F994C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5822 - auc: 0.5425 - val_loss: 0.4153 - val_auc: 0.3877
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5468 - auc: 0.6187 - val_loss: 0.3468 - val_auc: 0.4117
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5282 - auc: 0.6194 - val_loss: 0.3455 - val_auc: 0.4032
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5334 - auc: 0.5956 - val_loss: 0.3647 - val_auc: 0.3170
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6497 - val_loss: 0.3233 - val_auc: 0.4061
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5135 - auc: 0.6387 - val_loss: 0.3308 - val_auc: 0.4047
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6508 - val_loss: 0.3126 - val_auc: 0.4465
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4992 - auc: 0.6562 - val_loss: 0.3235 - val_auc: 0.5377
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6811 - val_loss: 0.3095 - val_auc: 0.4333
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5065 - auc: 0.6536 - val_loss: 0.2863 - val_auc: 0.5015
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.6668 - val_loss: 0.2996 - val_auc: 0.4681
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.7007 - val_loss: 0.3023 - val_auc: 0.6114
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6740 - val_loss: 0.3003 - val_auc: 0.5137
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6972 - val_loss: 0.2964 - val_auc: 0.6094
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.7045 - val_loss: 0.2874 - val_auc: 0.4892
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4898 - auc: 0.6933 - val_loss: 0.3106 - val_auc: 0.5091
Epoch 17/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4924 - auc: 0.6911 - val_loss: 0.3049 - val_auc: 0.5064
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5016 - auc: 0.6946 - val_loss: 0.2973 - val_auc: 0.4880
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4771 - auc: 0.7057 - val_loss: 0.3072 - val_auc: 0.5743
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5009 - auc: 0.6922 - val_loss: 0.2863 - val_auc: 0.5205
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235085905E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.681247, 0), (0.6767662, 0), (0.67406666, 0), (0.66522086, 0), (0.6558743, 0), (0.65339935, 0), (0.649874, 0), (0.6491859, 0), (0.6487298, 0), (0.6482886, 1), (0.64799553, 0), (0.6408788, 0), (0.6332792, 0), (0.61625606, 0), (0.52307266, 0), (0.48002306, 0), (0.4505825, 0), (0.37044668, 0), (0.34411982, 0), (0.28224626, 0), (0.26852775, 0), (0.13599823, 0), (0.04085957, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350AB709D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 94/100 [===========================&gt;..] - ETA: 0s - loss: 0.5139 - auc: 0.5518WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350239AA68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 9ms/step - loss: 0.5121 - auc: 0.5672 - val_loss: 0.2747 - val_auc: 0.5434
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4927 - auc: 0.6010 - val_loss: 0.2889 - val_auc: 0.4653
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5044 - auc: 0.6110 - val_loss: 0.2981 - val_auc: 0.4744
Epoch 4/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4862 - auc: 0.6524 - val_loss: 0.2731 - val_auc: 0.5374
Epoch 5/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4990 - auc: 0.6190 - val_loss: 0.2828 - val_auc: 0.6770
Epoch 6/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4788 - auc: 0.6472 - val_loss: 0.2768 - val_auc: 0.5722
Epoch 7/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4899 - auc: 0.6349 - val_loss: 0.2847 - val_auc: 0.3660
Epoch 8/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5002 - auc: 0.5926 - val_loss: 0.2891 - val_auc: 0.3852
Epoch 9/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4851 - auc: 0.6677 - val_loss: 0.2950 - val_auc: 0.3102
Epoch 10/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4835 - auc: 0.6260 - val_loss: 0.3157 - val_auc: 0.4260
Epoch 11/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4753 - auc: 0.6808 - val_loss: 0.2857 - val_auc: 0.4669
Epoch 12/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4709 - auc: 0.6502 - val_loss: 0.2952 - val_auc: 0.4938
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4778 - auc: 0.7078 - val_loss: 0.2801 - val_auc: 0.4961
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4694 - auc: 0.6866 - val_loss: 0.3007 - val_auc: 0.4326
Epoch 15/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4790 - auc: 0.6771 - val_loss: 0.2773 - val_auc: 0.5143
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4904 - auc: 0.6558 - val_loss: 0.2854 - val_auc: 0.4659
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4701 - auc: 0.6955 - val_loss: 0.3058 - val_auc: 0.4510
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4770 - auc: 0.6698 - val_loss: 0.2925 - val_auc: 0.4677
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4635 - auc: 0.7007 - val_loss: 0.3058 - val_auc: 0.4173
Epoch 20/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4778 - auc: 0.6966 - val_loss: 0.2978 - val_auc: 0.4702
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF0B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.8528025, 1), (0.7884859, 1), (0.7679717, 0), (0.6732095, 0), (0.65948373, 1), (0.6586301, 1), (0.65767187, 0), (0.6231208, 1), (0.6154803, 1), (0.6147909, 0), (0.6099582, 0), (0.606512, 1), (0.6001576, 1), (0.59231466, 0), (0.5795271, 0), (0.55392885, 0), (0.5528753, 0), (0.5403147, 0), (0.4823646, 0), (0.39747792, 1), (0.39493185, 0), (0.38631532, 0), (0.36949453, 0), (0.0, 0)]
0.6
0.3
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235076E15E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.5507 - auc: 0.5128WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023508100318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 3s 9ms/step - loss: 0.5394 - auc: 0.5178 - val_loss: 0.2854 - val_auc: 0.5143
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5174 - auc: 0.6000 - val_loss: 0.2792 - val_auc: 0.3984
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5123 - auc: 0.6512 - val_loss: 0.2762 - val_auc: 0.6235
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5151 - auc: 0.6120 - val_loss: 0.2756 - val_auc: 0.5108
Epoch 5/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5019 - auc: 0.6463 - val_loss: 0.2679 - val_auc: 0.5127
Epoch 6/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5144 - auc: 0.6255 - val_loss: 0.2720 - val_auc: 0.6143
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5096 - auc: 0.6410 - val_loss: 0.2761 - val_auc: 0.6193
Epoch 8/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4961 - auc: 0.6629 - val_loss: 0.2664 - val_auc: 0.5011
Epoch 9/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4969 - auc: 0.6820 - val_loss: 0.2818 - val_auc: 0.6783
Epoch 10/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5265 - auc: 0.6267 - val_loss: 0.2670 - val_auc: 0.5926
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4953 - auc: 0.6660 - val_loss: 0.2710 - val_auc: 0.6730
Epoch 12/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4975 - auc: 0.6592 - val_loss: 0.2649 - val_auc: 0.6521
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4867 - auc: 0.6931 - val_loss: 0.2618 - val_auc: 0.6331
Epoch 14/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5016 - auc: 0.6651 - val_loss: 0.2705 - val_auc: 0.6431
Epoch 15/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4864 - auc: 0.6903 - val_loss: 0.2618 - val_auc: 0.7040
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4930 - auc: 0.6779 - val_loss: 0.2595 - val_auc: 0.6762
Epoch 17/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4953 - auc: 0.6747 - val_loss: 0.2573 - val_auc: 0.6862
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4991 - auc: 0.6832 - val_loss: 0.2730 - val_auc: 0.6574
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4872 - auc: 0.6921 - val_loss: 0.2574 - val_auc: 0.6026
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4845 - auc: 0.7072 - val_loss: 0.2697 - val_auc: 0.6460
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023558298C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8456209, 0), (0.8048405, 0), (0.75397825, 0), (0.7429917, 0), (0.62511647, 0), (0.6084665, 0), (0.49049658, 0), (0.45050278, 0), (0.4455162, 0), (0.44377834, 0), (0.4402922, 0), (0.41461137, 0), (0.3873839, 0), (0.38180536, 0), (0.38082114, 0), (0.38074592, 0), (0.36488518, 0), (0.35082576, 0), (0.33289868, 0), (0.32824838, 0), (0.22850618, 0), (0.16940577, 0), (0.13591048, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B58B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 92/100 [==========================&gt;...] - ETA: 0s - loss: 0.6051 - auc: 0.5317WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235038CF798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 9ms/step - loss: 0.5940 - auc: 0.5380 - val_loss: 0.5006 - val_auc: 0.6025
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5227 - auc: 0.6258 - val_loss: 0.4702 - val_auc: 0.4958
Epoch 3/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5343 - auc: 0.5944 - val_loss: 0.4663 - val_auc: 0.6747
Epoch 4/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4981 - auc: 0.6452 - val_loss: 0.4125 - val_auc: 0.3387
Epoch 5/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4814 - auc: 0.7074 - val_loss: 0.3481 - val_auc: 0.4672
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4934 - auc: 0.6649 - val_loss: 0.3939 - val_auc: 0.4432
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4842 - auc: 0.6618 - val_loss: 0.3664 - val_auc: 0.5622
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4739 - auc: 0.7073 - val_loss: 0.3361 - val_auc: 0.6540
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4924 - auc: 0.6769 - val_loss: 0.3745 - val_auc: 0.4537
Epoch 10/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4816 - auc: 0.6926 - val_loss: 0.3735 - val_auc: 0.4603
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4854 - auc: 0.6912 - val_loss: 0.3538 - val_auc: 0.5807
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4699 - auc: 0.7041 - val_loss: 0.3598 - val_auc: 0.4831
Epoch 13/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4807 - auc: 0.7070 - val_loss: 0.3465 - val_auc: 0.6633
Epoch 14/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4866 - auc: 0.6940 - val_loss: 0.3284 - val_auc: 0.6087
Epoch 15/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.7266 - val_loss: 0.3474 - val_auc: 0.6107
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4717 - auc: 0.7128 - val_loss: 0.3311 - val_auc: 0.6070
Epoch 17/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4699 - auc: 0.7315 - val_loss: 0.3244 - val_auc: 0.6410
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4727 - auc: 0.7104 - val_loss: 0.3318 - val_auc: 0.6254
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4669 - auc: 0.7179 - val_loss: 0.3357 - val_auc: 0.5597
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4660 - auc: 0.7232 - val_loss: 0.3356 - val_auc: 0.5731
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9383473, 0), (0.885668, 0), (0.8844245, 0), (0.8733163, 0), (0.8724948, 1), (0.86698043, 0), (0.8646994, 1), (0.8646994, 0), (0.8646994, 0), (0.8646994, 0), (0.8589522, 1), (0.85709375, 0), (0.8539864, 0), (0.8440248, 0), (0.7995085, 0), (0.78928256, 1), (0.77505714, 0), (0.7126419, 0), (0.5706265, 0), (0.5210829, 0), (0.4877832, 1), (0.4744414, 0), (0.26579413, 0), (0.0, 1)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503FAE798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/100 [===========================&gt;..] - ETA: 0s - loss: 0.5679 - auc: 0.5007WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235095938B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.5673 - auc: 0.5001 - val_loss: 0.4703 - val_auc: 0.4312
Epoch 2/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5120 - auc: 0.5643 - val_loss: 0.4397 - val_auc: 0.3839
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4871 - auc: 0.5873 - val_loss: 0.4301 - val_auc: 0.5363
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5009 - auc: 0.5691 - val_loss: 0.4499 - val_auc: 0.5195
Epoch 5/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4588 - auc: 0.6649 - val_loss: 0.4234 - val_auc: 0.4978
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4544 - auc: 0.6723 - val_loss: 0.4062 - val_auc: 0.5875
Epoch 7/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4544 - auc: 0.6666 - val_loss: 0.4163 - val_auc: 0.5687
Epoch 8/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4749 - auc: 0.6228 - val_loss: 0.4026 - val_auc: 0.5958
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4492 - auc: 0.6851 - val_loss: 0.3984 - val_auc: 0.5682
Epoch 10/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4456 - auc: 0.7083 - val_loss: 0.4044 - val_auc: 0.5661
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4660 - auc: 0.6486 - val_loss: 0.3928 - val_auc: 0.5993
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4437 - auc: 0.7058 - val_loss: 0.3890 - val_auc: 0.5951
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4503 - auc: 0.6856 - val_loss: 0.3935 - val_auc: 0.6149
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4534 - auc: 0.6776 - val_loss: 0.3923 - val_auc: 0.5787
Epoch 15/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4566 - auc: 0.6721 - val_loss: 0.3833 - val_auc: 0.6070
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4436 - auc: 0.6934 - val_loss: 0.3801 - val_auc: 0.5907
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4565 - auc: 0.6722 - val_loss: 0.3803 - val_auc: 0.6054
Epoch 18/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4415 - auc: 0.7105 - val_loss: 0.3814 - val_auc: 0.6045
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4627 - auc: 0.6536 - val_loss: 0.3855 - val_auc: 0.5797
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4459 - auc: 0.6900 - val_loss: 0.3797 - val_auc: 0.6017
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509593E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9170316, 1), (0.8696013, 1), (0.86052597, 1), (0.8598544, 1), (0.8477232, 0), (0.8438967, 0), (0.84145224, 0), (0.8406075, 1), (0.83693963, 1), (0.8361344, 1), (0.82929975, 0), (0.8107949, 1), (0.7688668, 0), (0.7230348, 1), (0.6012643, 0), (0.4847506, 1), (0.4834661, 0), (0.4356085, 1), (0.41279635, 0), (0.36623526, 1), (0.32342994, 1), (0.03203828, 1), (0.0004972509, 1), (0.0, 0)]
1.0
0.3125
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023508590288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/100 [=========================&gt;....] - ETA: 0s - loss: 0.5542 - auc: 0.5119WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235044974C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.5538 - auc: 0.5241 - val_loss: 0.3840 - val_auc: 0.2975
Epoch 2/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4989 - auc: 0.6568 - val_loss: 0.3411 - val_auc: 0.3106
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5104 - auc: 0.6050 - val_loss: 0.3494 - val_auc: 0.4632
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5018 - auc: 0.6453 - val_loss: 0.3276 - val_auc: 0.4735
Epoch 5/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4938 - auc: 0.6590 - val_loss: 0.3313 - val_auc: 0.4394
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4905 - auc: 0.6630 - val_loss: 0.3308 - val_auc: 0.3991
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4800 - auc: 0.6886 - val_loss: 0.3456 - val_auc: 0.5354
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.6899 - val_loss: 0.3078 - val_auc: 0.5615
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4826 - auc: 0.7040 - val_loss: 0.3004 - val_auc: 0.5671
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4535 - auc: 0.7497 - val_loss: 0.3154 - val_auc: 0.5109
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.7065 - val_loss: 0.3187 - val_auc: 0.5029
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6907 - val_loss: 0.3151 - val_auc: 0.4637
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4889 - auc: 0.6704 - val_loss: 0.3271 - val_auc: 0.4848
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4725 - auc: 0.7114 - val_loss: 0.3255 - val_auc: 0.4806
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.7025 - val_loss: 0.3277 - val_auc: 0.4753
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4692 - auc: 0.7000 - val_loss: 0.3284 - val_auc: 0.4432
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6882 - val_loss: 0.3040 - val_auc: 0.5559
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4634 - auc: 0.7183 - val_loss: 0.3155 - val_auc: 0.5232
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.6987 - val_loss: 0.3305 - val_auc: 0.5885
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6873 - val_loss: 0.3260 - val_auc: 0.5553
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB70438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9950951, 0), (0.9784843, 0), (0.9784843, 0), (0.9784843, 0), (0.9766938, 0), (0.9702015, 0), (0.9637678, 0), (0.9612657, 0), (0.9606373, 0), (0.9586679, 0), (0.95438933, 0), (0.942337, 0), (0.94081724, 1), (0.94026756, 0), (0.9398954, 0), (0.92531174, 0), (0.896144, 1), (0.8853679, 0), (0.85235935, 0), (0.76208264, 1), (0.66075563, 0), (0.65239537, 1), (0.0020989606, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/100 [===========================&gt;..] - ETA: 0s - loss: 0.5830 - auc: 0.5277WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350769D708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 7ms/step - loss: 0.5804 - auc: 0.5322 - val_loss: 0.3644 - val_auc: 0.6083
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5623 - auc: 0.5458 - val_loss: 0.3297 - val_auc: 0.7029
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5245 - auc: 0.5976 - val_loss: 0.3049 - val_auc: 0.6927
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5177 - auc: 0.6179 - val_loss: 0.3102 - val_auc: 0.6234
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5038 - auc: 0.6564 - val_loss: 0.3226 - val_auc: 0.6495
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5066 - auc: 0.6479 - val_loss: 0.3009 - val_auc: 0.7012
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5137 - auc: 0.6318 - val_loss: 0.2814 - val_auc: 0.6430
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.6917 - val_loss: 0.2794 - val_auc: 0.7065
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6754 - val_loss: 0.2895 - val_auc: 0.6702
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4919 - auc: 0.6804 - val_loss: 0.2826 - val_auc: 0.6371
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4781 - auc: 0.7206 - val_loss: 0.2857 - val_auc: 0.6247
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6950 - val_loss: 0.2694 - val_auc: 0.6584
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6899 - val_loss: 0.2969 - val_auc: 0.5818
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.7011 - val_loss: 0.2920 - val_auc: 0.6384
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4716 - auc: 0.7225 - val_loss: 0.2887 - val_auc: 0.6522
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6852 - val_loss: 0.2696 - val_auc: 0.6865
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6704 - val_loss: 0.2732 - val_auc: 0.7202
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4936 - auc: 0.6892 - val_loss: 0.2710 - val_auc: 0.6796
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.7135 - val_loss: 0.2861 - val_auc: 0.7183
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.7201 - val_loss: 0.2593 - val_auc: 0.6888
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235024904C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.96758264, 0), (0.9568687, 0), (0.9460544, 0), (0.9337187, 0), (0.9321214, 0), (0.9115684, 0), (0.8849181, 0), (0.84355265, 0), (0.8082878, 0), (0.7771225, 0), (0.7721192, 0), (0.7648645, 0), (0.73678213, 0), (0.6183447, 0), (0.51464057, 0), (0.2975434, 0), (0.2126342, 0), (0.16839164, 0), (0.16298714, 0), (0.09313399, 1), (0.087235935, 1), (0.021188308, 0), (0.019504534, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A6F678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 98/100 [============================&gt;.] - ETA: 0s - loss: 0.5734 - auc: 0.5238WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.5712 - auc: 0.5226 - val_loss: 0.4159 - val_auc: 0.3424
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5351 - auc: 0.5949 - val_loss: 0.4183 - val_auc: 0.3421
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5364 - auc: 0.5902 - val_loss: 0.3660 - val_auc: 0.4249
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6370 - val_loss: 0.3145 - val_auc: 0.3830
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5232 - auc: 0.6099 - val_loss: 0.3284 - val_auc: 0.3997
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5186 - auc: 0.6054 - val_loss: 0.3323 - val_auc: 0.4073
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6348 - val_loss: 0.3146 - val_auc: 0.5330
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5160 - auc: 0.6292 - val_loss: 0.3173 - val_auc: 0.4360
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6594 - val_loss: 0.3165 - val_auc: 0.4480
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6703 - val_loss: 0.2953 - val_auc: 0.4982
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4964 - auc: 0.6611 - val_loss: 0.3122 - val_auc: 0.4918
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6611 - val_loss: 0.3219 - val_auc: 0.4673
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6945 - val_loss: 0.3132 - val_auc: 0.4675
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6721 - val_loss: 0.3158 - val_auc: 0.5398
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6966 - val_loss: 0.3080 - val_auc: 0.5573
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6670 - val_loss: 0.3044 - val_auc: 0.5184
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6614 - val_loss: 0.2962 - val_auc: 0.4985
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4790 - auc: 0.7109 - val_loss: 0.2913 - val_auc: 0.6146
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6681 - val_loss: 0.3286 - val_auc: 0.5980
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4887 - auc: 0.6958 - val_loss: 0.3155 - val_auc: 0.5687
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.97969955, 0), (0.9561707, 0), (0.955631, 0), (0.9456729, 0), (0.9340181, 0), (0.93237585, 0), (0.9298889, 0), (0.9220762, 1), (0.9216171, 0), (0.9183703, 0), (0.91393673, 0), (0.9127586, 0), (0.90929246, 0), (0.90091515, 0), (0.8779639, 0), (0.8722239, 0), (0.85249835, 0), (0.82128125, 0), (0.80216527, 0), (0.7228531, 0), (0.66627324, 0), (0.6657815, 0), (0.5221632, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350769D948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/100 [==========================&gt;...] - ETA: 0s - loss: 0.5942 - auc: 0.5321WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF0EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 7ms/step - loss: 0.5882 - auc: 0.5358 - val_loss: 0.4611 - val_auc: 0.5272
Epoch 2/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5483 - auc: 0.5884 - val_loss: 0.4572 - val_auc: 0.5484
Epoch 3/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5333 - auc: 0.6311 - val_loss: 0.4760 - val_auc: 0.7811
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5279 - auc: 0.6270 - val_loss: 0.3901 - val_auc: 0.5035
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5353 - auc: 0.6085 - val_loss: 0.3421 - val_auc: 0.7241
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6621 - val_loss: 0.3053 - val_auc: 0.7824
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5260 - auc: 0.6341 - val_loss: 0.3351 - val_auc: 0.7051
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6398 - val_loss: 0.3008 - val_auc: 0.7060
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5095 - auc: 0.6530 - val_loss: 0.3003 - val_auc: 0.7172
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4869 - auc: 0.6865 - val_loss: 0.3022 - val_auc: 0.6986
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.6578 - val_loss: 0.3030 - val_auc: 0.7427
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5017 - auc: 0.6841 - val_loss: 0.2994 - val_auc: 0.6921
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4941 - auc: 0.6931 - val_loss: 0.2958 - val_auc: 0.6939
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6779 - val_loss: 0.2827 - val_auc: 0.7176
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4943 - auc: 0.6803 - val_loss: 0.2864 - val_auc: 0.7193
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6973 - val_loss: 0.2882 - val_auc: 0.7301
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.7019 - val_loss: 0.2731 - val_auc: 0.7655
Epoch 18/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5006 - auc: 0.6779 - val_loss: 0.2919 - val_auc: 0.7098
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5031 - auc: 0.6727 - val_loss: 0.2897 - val_auc: 0.7012
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6961 - val_loss: 0.2965 - val_auc: 0.7375
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB5E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9976448, 1), (0.968983, 0), (0.96574575, 0), (0.9656053, 0), (0.9652613, 0), (0.9649882, 0), (0.9646898, 0), (0.9646108, 0), (0.96461034, 0), (0.96454823, 0), (0.96448857, 0), (0.96440345, 0), (0.96440095, 0), (0.9642992, 0), (0.96422184, 0), (0.9622162, 1), (0.9442212, 0), (0.94419056, 0), (0.9208174, 0), (0.8448475, 0), (0.7864085, 0), (0.74168825, 0), (0.49259773, 0), (0.0, 0)]
0.4
0.6666666666666666
Siam
[0.4, 0.4, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4]
0.19
[0.2, 0.5, 0.0, 0.0, 0.25, 0.2, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3, -1.0, 0.0, 0.3125, 0.0, 0.0, 0.0, 0.6666666666666666]
0.19364035087719297
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[13]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">0.75</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023508324CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/101 [==========================&gt;...] - ETA: 0s - loss: 0.5174 - auc: 0.5246WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502FB0CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 7ms/step - loss: 0.5177 - auc: 0.5220 - val_loss: 0.3107 - val_auc: 0.4529
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6136 - val_loss: 0.3045 - val_auc: 0.5086
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.6416 - val_loss: 0.2856 - val_auc: 0.5706
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6260 - val_loss: 0.2942 - val_auc: 0.5929
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6334 - val_loss: 0.2977 - val_auc: 0.4282
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6737 - val_loss: 0.2870 - val_auc: 0.6809
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.6621 - val_loss: 0.3085 - val_auc: 0.6275
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.6430 - val_loss: 0.2865 - val_auc: 0.4660
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6321 - val_loss: 0.3090 - val_auc: 0.4852
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.6828 - val_loss: 0.2905 - val_auc: 0.4711
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4622 - auc: 0.7037 - val_loss: 0.2986 - val_auc: 0.4611
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4703 - auc: 0.6845 - val_loss: 0.3039 - val_auc: 0.5168
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6457 - val_loss: 0.3111 - val_auc: 0.4676
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.6509 - val_loss: 0.3090 - val_auc: 0.4950
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4707 - auc: 0.6706 - val_loss: 0.3093 - val_auc: 0.4791
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4605 - auc: 0.6998 - val_loss: 0.3066 - val_auc: 0.4742
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.6636 - val_loss: 0.3070 - val_auc: 0.5526
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4732 - auc: 0.6667 - val_loss: 0.3090 - val_auc: 0.5966
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6792 - val_loss: 0.3076 - val_auc: 0.5433
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4605 - auc: 0.7031 - val_loss: 0.2999 - val_auc: 0.5344
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B5318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.99599123, 1), (0.9517737, 1), (0.89734566, 0), (0.8427262, 0), (0.7955175, 0), (0.78976685, 1), (0.78976685, 0), (0.78894305, 0), (0.62906975, 1), (0.58799475, 0), (0.033161346, 1), (0.0, 0)]
0.6
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/101 [========================&gt;.....] - ETA: 0s - loss: 0.5376 - auc: 0.5514WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350AB70048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.5316 - auc: 0.5596 - val_loss: 0.2570 - val_auc: 0.8215
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5107 - auc: 0.6386 - val_loss: 0.2317 - val_auc: 0.6828
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6396 - val_loss: 0.2381 - val_auc: 0.7123
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5139 - auc: 0.6308 - val_loss: 0.2438 - val_auc: 0.7799
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6395 - val_loss: 0.2826 - val_auc: 0.7006
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6658 - val_loss: 0.2514 - val_auc: 0.7268
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.7032 - val_loss: 0.2752 - val_auc: 0.6804
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4936 - auc: 0.6711 - val_loss: 0.2632 - val_auc: 0.6721
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4811 - auc: 0.6803 - val_loss: 0.2579 - val_auc: 0.7332
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6447 - val_loss: 0.2594 - val_auc: 0.6073
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4803 - auc: 0.6695 - val_loss: 0.2689 - val_auc: 0.6030
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4870 - auc: 0.6870 - val_loss: 0.2640 - val_auc: 0.6604
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4843 - auc: 0.7016 - val_loss: 0.2692 - val_auc: 0.6568
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4711 - auc: 0.7160 - val_loss: 0.2690 - val_auc: 0.7368
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4832 - auc: 0.7078 - val_loss: 0.2659 - val_auc: 0.7180
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6870 - val_loss: 0.2635 - val_auc: 0.7406
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4809 - auc: 0.6999 - val_loss: 0.2663 - val_auc: 0.6816
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6924 - val_loss: 0.2719 - val_auc: 0.6142
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.7204 - val_loss: 0.2756 - val_auc: 0.7028
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4830 - auc: 0.6940 - val_loss: 0.2738 - val_auc: 0.7475
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235580A03A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.79901147, 0), (0.57775384, 1), (0.33356097, 0), (0.29854172, 0), (0.1568036, 0), (0.050699286, 1), (0.050699286, 0), (0.050699286, 1), (0.050699286, 0), (0.050699286, 0), (0.047012545, 0), (0.0, 0)]
0.6666666666666666
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B5A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.5392 - auc: 0.5297WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503F995E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5361 - auc: 0.5336 - val_loss: 0.2783 - val_auc: 0.4683
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5145 - auc: 0.6045 - val_loss: 0.2704 - val_auc: 0.4675
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.6104 - val_loss: 0.2525 - val_auc: 0.4919
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.6463 - val_loss: 0.2832 - val_auc: 0.4801
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5128 - auc: 0.6568 - val_loss: 0.2739 - val_auc: 0.4372
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6712 - val_loss: 0.2955 - val_auc: 0.4600
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5062 - auc: 0.6543 - val_loss: 0.2819 - val_auc: 0.4372
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6671 - val_loss: 0.2961 - val_auc: 0.4505
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6966 - val_loss: 0.2954 - val_auc: 0.4747
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4749 - auc: 0.7145 - val_loss: 0.2908 - val_auc: 0.4640
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6924 - val_loss: 0.2938 - val_auc: 0.4174
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.7035 - val_loss: 0.3065 - val_auc: 0.4309
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6745 - val_loss: 0.2998 - val_auc: 0.4537
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6799 - val_loss: 0.2919 - val_auc: 0.4983
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.7028 - val_loss: 0.2949 - val_auc: 0.5521
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6766 - val_loss: 0.2956 - val_auc: 0.5541
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4774 - auc: 0.7186 - val_loss: 0.3011 - val_auc: 0.5184
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5025 - auc: 0.6891 - val_loss: 0.2869 - val_auc: 0.5633
Epoch 19/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4882 - auc: 0.7030 - val_loss: 0.2936 - val_auc: 0.5233
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.7115 - val_loss: 0.3004 - val_auc: 0.5843
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023557BDB3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.79638344, 0), (0.6460205, 0), (0.5170999, 0), (0.5111426, 0), (0.40459433, 0), (0.3999025, 0), (0.36970097, 0), (0.36260843, 0), (0.33994606, 0), (0.2268371, 0), (0.20614055, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502EF0438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 98/101 [============================&gt;.] - ETA: 0s - loss: 0.7724 - auc: 0.4889WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502258828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.7699 - auc: 0.4901 - val_loss: 0.5776 - val_auc: 0.6330
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6102 - auc: 0.5786 - val_loss: 0.5876 - val_auc: 0.7283
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6107 - auc: 0.5636 - val_loss: 0.6747 - val_auc: 0.6373
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5513 - auc: 0.6237 - val_loss: 0.4556 - val_auc: 0.6200
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5577 - auc: 0.6174 - val_loss: 0.4825 - val_auc: 0.5944
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5352 - auc: 0.6467 - val_loss: 0.4145 - val_auc: 0.5987
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5146 - auc: 0.6658 - val_loss: 0.4110 - val_auc: 0.5999
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5185 - auc: 0.6743 - val_loss: 0.4150 - val_auc: 0.5910
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6694 - val_loss: 0.3928 - val_auc: 0.6554
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6883 - val_loss: 0.4090 - val_auc: 0.6359
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6933 - val_loss: 0.4309 - val_auc: 0.4781
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5066 - auc: 0.6587 - val_loss: 0.4010 - val_auc: 0.6091
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4919 - auc: 0.6809 - val_loss: 0.3934 - val_auc: 0.4974
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6820 - val_loss: 0.3675 - val_auc: 0.6649
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4819 - auc: 0.7049 - val_loss: 0.3728 - val_auc: 0.5155
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7066 - val_loss: 0.3771 - val_auc: 0.5861
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.7249 - val_loss: 0.3619 - val_auc: 0.6137
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4808 - auc: 0.7158 - val_loss: 0.3553 - val_auc: 0.5843
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4940 - auc: 0.6798 - val_loss: 0.3507 - val_auc: 0.5648
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.7117 - val_loss: 0.3323 - val_auc: 0.6019
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235594A7558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98066527, 0), (0.94435173, 1), (0.93514496, 0), (0.89476806, 0), (0.8830986, 0), (0.87952983, 0), (0.8620875, 0), (0.8537211, 0), (0.84313905, 0), (0.7618314, 0), (0.6905003, 0), (0.0, 0)]
0.2
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504497678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.6852 - auc: 0.5389WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502FB0B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.6822 - auc: 0.5411 - val_loss: 0.7308 - val_auc: 0.6448
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6218 - auc: 0.5592 - val_loss: 0.7595 - val_auc: 0.6766
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5679 - auc: 0.6159 - val_loss: 0.5386 - val_auc: 0.6190
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5300 - auc: 0.6421 - val_loss: 0.6323 - val_auc: 0.7029
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5212 - auc: 0.6574 - val_loss: 0.4691 - val_auc: 0.7565
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.7028 - val_loss: 0.4850 - val_auc: 0.5703
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6787 - val_loss: 0.4506 - val_auc: 0.6182
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6749 - val_loss: 0.4752 - val_auc: 0.6706
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.6548 - val_loss: 0.4487 - val_auc: 0.6359
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6677 - val_loss: 0.3939 - val_auc: 0.6216
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7149 - val_loss: 0.4023 - val_auc: 0.6292
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4887 - auc: 0.7023 - val_loss: 0.3973 - val_auc: 0.6437
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6895 - val_loss: 0.3990 - val_auc: 0.6562
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6972 - val_loss: 0.4208 - val_auc: 0.6414
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4864 - auc: 0.7087 - val_loss: 0.3848 - val_auc: 0.6292
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4679 - auc: 0.7325 - val_loss: 0.3565 - val_auc: 0.6125
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.7123 - val_loss: 0.3451 - val_auc: 0.6846
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6935 - val_loss: 0.3683 - val_auc: 0.6779
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7091 - val_loss: 0.3339 - val_auc: 0.6313
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4692 - auc: 0.7274 - val_loss: 0.3541 - val_auc: 0.6958
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239AAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.91632724, 0), (0.8692843, 0), (0.8648832, 0), (0.84855735, 0), (0.7961409, 1), (0.72706926, 0), (0.62152064, 0), (0.58074486, 0), (0.56798923, 0), (0.30065426, 0), (0.045480087, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A774C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.5509 - auc: 0.5014WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350812F798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5484 - auc: 0.5049 - val_loss: 0.3419 - val_auc: 0.6533
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6151 - val_loss: 0.3054 - val_auc: 0.6544
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5105 - auc: 0.5847 - val_loss: 0.3507 - val_auc: 0.6850
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5128 - auc: 0.6107 - val_loss: 0.3312 - val_auc: 0.6234
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.6095 - val_loss: 0.3224 - val_auc: 0.6480
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.6736 - val_loss: 0.3264 - val_auc: 0.6335
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.6862 - val_loss: 0.3337 - val_auc: 0.5193
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.6903 - val_loss: 0.3144 - val_auc: 0.6141
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.6886 - val_loss: 0.3358 - val_auc: 0.5720
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6737 - val_loss: 0.3173 - val_auc: 0.6348
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4647 - auc: 0.7192 - val_loss: 0.3402 - val_auc: 0.5759
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4781 - auc: 0.6852 - val_loss: 0.3212 - val_auc: 0.5991
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.6962 - val_loss: 0.3278 - val_auc: 0.6483
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4836 - auc: 0.6972 - val_loss: 0.3331 - val_auc: 0.6157
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6565 - val_loss: 0.3422 - val_auc: 0.5704
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6857 - val_loss: 0.3465 - val_auc: 0.5733
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.6865 - val_loss: 0.3263 - val_auc: 0.6166
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.7078 - val_loss: 0.3301 - val_auc: 0.6176
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4865 - auc: 0.6895 - val_loss: 0.3225 - val_auc: 0.5982
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.6872 - val_loss: 0.3203 - val_auc: 0.6840
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A6F318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.763985, 0), (0.6808454, 0), (0.6512235, 0), (0.57730454, 0), (0.5110703, 0), (0.49704733, 0), (0.45051455, 1), (0.35125467, 0), (0.30360514, 0), (0.25002813, 0), (0.10081261, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 94/101 [==========================&gt;...] - ETA: 0s - loss: 0.6283 - auc: 0.5036WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DB048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 7ms/step - loss: 0.6312 - auc: 0.5025 - val_loss: 0.4253 - val_auc: 0.4983
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5680 - auc: 0.5371 - val_loss: 0.5487 - val_auc: 0.4429
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5419 - auc: 0.5817 - val_loss: 0.4981 - val_auc: 0.4124
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5112 - auc: 0.6300 - val_loss: 0.4069 - val_auc: 0.6141
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5276 - auc: 0.5844 - val_loss: 0.4138 - val_auc: 0.4028
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5093 - auc: 0.6041 - val_loss: 0.3936 - val_auc: 0.5651
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6501 - val_loss: 0.3774 - val_auc: 0.5459
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.6846 - val_loss: 0.3615 - val_auc: 0.5533
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4597 - auc: 0.6948 - val_loss: 0.3670 - val_auc: 0.5732
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.6617 - val_loss: 0.3685 - val_auc: 0.5370
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4766 - auc: 0.6808 - val_loss: 0.3501 - val_auc: 0.5386
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4759 - auc: 0.6844 - val_loss: 0.3559 - val_auc: 0.5394
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4649 - auc: 0.6898 - val_loss: 0.3580 - val_auc: 0.5574
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6868 - val_loss: 0.3587 - val_auc: 0.5189
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4661 - auc: 0.7095 - val_loss: 0.3576 - val_auc: 0.5278
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4804 - auc: 0.6970 - val_loss: 0.3511 - val_auc: 0.5300
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4620 - auc: 0.7113 - val_loss: 0.3556 - val_auc: 0.5261
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4616 - auc: 0.7085 - val_loss: 0.3461 - val_auc: 0.5574
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4594 - auc: 0.7233 - val_loss: 0.3532 - val_auc: 0.5631
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4522 - auc: 0.7274 - val_loss: 0.3407 - val_auc: 0.5694
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A6FF78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9858095, 0), (0.9416358, 0), (0.932072, 0), (0.92172724, 0), (0.91229683, 0), (0.8588461, 1), (0.8444302, 0), (0.8320569, 0), (0.70856225, 0), (0.6086955, 0), (0.0021321992, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350A17F438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/101 [==========================&gt;...] - ETA: 0s - loss: 0.6144 - auc: 0.5435WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350239A318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 7ms/step - loss: 0.6146 - auc: 0.5431 - val_loss: 0.3387 - val_auc: 0.5354
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5311 - auc: 0.6370 - val_loss: 0.2573 - val_auc: 0.5064
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5359 - auc: 0.6171 - val_loss: 0.3537 - val_auc: 0.5512
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5419 - auc: 0.5879 - val_loss: 0.3180 - val_auc: 0.5754
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5144 - auc: 0.6255 - val_loss: 0.3134 - val_auc: 0.5338
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5063 - auc: 0.6494 - val_loss: 0.3201 - val_auc: 0.5544
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5062 - auc: 0.6533 - val_loss: 0.3548 - val_auc: 0.5686
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5054 - auc: 0.6523 - val_loss: 0.2874 - val_auc: 0.5564
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6716 - val_loss: 0.2702 - val_auc: 0.5267
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4915 - auc: 0.6797 - val_loss: 0.2883 - val_auc: 0.5512
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6742 - val_loss: 0.3011 - val_auc: 0.5954
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4973 - auc: 0.6911 - val_loss: 0.2859 - val_auc: 0.5757
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6835 - val_loss: 0.2824 - val_auc: 0.5921
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5049 - auc: 0.6581 - val_loss: 0.2821 - val_auc: 0.6340
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4824 - auc: 0.6887 - val_loss: 0.2772 - val_auc: 0.5715
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.7083 - val_loss: 0.2846 - val_auc: 0.5499
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.7046 - val_loss: 0.2928 - val_auc: 0.5245
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6815 - val_loss: 0.2852 - val_auc: 0.6092
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6982 - val_loss: 0.2861 - val_auc: 0.5641
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4815 - auc: 0.6985 - val_loss: 0.2872 - val_auc: 0.5338
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235023E01F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7534474, 0), (0.3942007, 0), (0.36767957, 0), (0.31311288, 1), (0.2908554, 0), (0.27887493, 0), (0.18036836, 0), (0.16137053, 0), (0.1465905, 0), (0.123913206, 0), (0.09450831, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235044975E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/101 [===========================&gt;..] - ETA: 0s - loss: 0.5255 - auc: 0.5627WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 7ms/step - loss: 0.5260 - auc: 0.5642 - val_loss: 0.3281 - val_auc: 0.6088
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5184 - auc: 0.5911 - val_loss: 0.3477 - val_auc: 0.6142
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.6467 - val_loss: 0.2934 - val_auc: 0.4355
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.6551 - val_loss: 0.2903 - val_auc: 0.5850
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4976 - auc: 0.6580 - val_loss: 0.2922 - val_auc: 0.4769
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6491 - val_loss: 0.2762 - val_auc: 0.6247
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.6683 - val_loss: 0.2816 - val_auc: 0.5045
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4829 - auc: 0.6840 - val_loss: 0.2909 - val_auc: 0.5507
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6682 - val_loss: 0.3016 - val_auc: 0.5773
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4734 - auc: 0.7112 - val_loss: 0.2984 - val_auc: 0.5514
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.6761 - val_loss: 0.2993 - val_auc: 0.5778
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.6885 - val_loss: 0.3196 - val_auc: 0.5678
Epoch 13/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4746 - auc: 0.6985 - val_loss: 0.3176 - val_auc: 0.6121
Epoch 14/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4853 - auc: 0.6942 - val_loss: 0.2884 - val_auc: 0.6597
Epoch 15/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4789 - auc: 0.6960 - val_loss: 0.3027 - val_auc: 0.6261
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4713 - auc: 0.7164 - val_loss: 0.2829 - val_auc: 0.6142
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4810 - auc: 0.7002 - val_loss: 0.3037 - val_auc: 0.5826
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4700 - auc: 0.7118 - val_loss: 0.3019 - val_auc: 0.6830
Epoch 19/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4943 - auc: 0.6753 - val_loss: 0.2859 - val_auc: 0.6099
Epoch 20/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4943 - auc: 0.6902 - val_loss: 0.2889 - val_auc: 0.6283
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350497E798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9461242, 1), (0.9093379, 0), (0.8496912, 0), (0.8447468, 0), (0.7557958, 0), (0.75487626, 0), (0.7336187, 0), (0.65568054, 0), (0.60512775, 0), (0.20021254, 0), (0.17969513, 0), (0.0, 0)]
0.4
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503346B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 96/101 [===========================&gt;..] - ETA: 0s - loss: 0.6506 - auc: 0.5492WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235044974C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 3s 9ms/step - loss: 0.6438 - auc: 0.5523 - val_loss: 0.4099 - val_auc: 0.6063
Epoch 2/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5543 - auc: 0.6189 - val_loss: 0.5102 - val_auc: 0.6449
Epoch 3/20
101/101 [==============================] - 1s 6ms/step - loss: 0.5470 - auc: 0.6132 - val_loss: 0.3986 - val_auc: 0.6569
Epoch 4/20
101/101 [==============================] - 1s 6ms/step - loss: 0.5261 - auc: 0.6419 - val_loss: 0.4305 - val_auc: 0.6306
Epoch 5/20
101/101 [==============================] - 1s 6ms/step - loss: 0.5055 - auc: 0.6667 - val_loss: 0.4651 - val_auc: 0.5815
Epoch 6/20
101/101 [==============================] - 1s 6ms/step - loss: 0.4965 - auc: 0.6642 - val_loss: 0.4513 - val_auc: 0.5691
Epoch 7/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5107 - auc: 0.6467 - val_loss: 0.4538 - val_auc: 0.6374
Epoch 8/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4676 - auc: 0.7057 - val_loss: 0.4192 - val_auc: 0.5782
Epoch 9/20
101/101 [==============================] - 1s 6ms/step - loss: 0.4653 - auc: 0.7179 - val_loss: 0.4147 - val_auc: 0.6031
Epoch 10/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4917 - auc: 0.6536 - val_loss: 0.4178 - val_auc: 0.6270
Epoch 11/20
101/101 [==============================] - 1s 6ms/step - loss: 0.4688 - auc: 0.6941 - val_loss: 0.4018 - val_auc: 0.6366
Epoch 12/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4805 - auc: 0.6938 - val_loss: 0.3788 - val_auc: 0.5945
Epoch 13/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4741 - auc: 0.6940 - val_loss: 0.3850 - val_auc: 0.6008
Epoch 14/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4703 - auc: 0.6978 - val_loss: 0.3650 - val_auc: 0.5744
Epoch 15/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4601 - auc: 0.7266 - val_loss: 0.4056 - val_auc: 0.5774
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4677 - auc: 0.7079 - val_loss: 0.3813 - val_auc: 0.5312
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4515 - auc: 0.7307 - val_loss: 0.3815 - val_auc: 0.5276
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4704 - auc: 0.7178 - val_loss: 0.3694 - val_auc: 0.5204
Epoch 19/20
101/101 [==============================] - 1s 6ms/step - loss: 0.4693 - auc: 0.7121 - val_loss: 0.3802 - val_auc: 0.5614
Epoch 20/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4771 - auc: 0.7075 - val_loss: 0.3931 - val_auc: 0.5577
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A77DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8004635, 0), (0.6017278, 0), (0.5816731, 0), (0.56761485, 0), (0.5668425, 0), (0.562899, 1), (0.5136931, 0), (0.41600776, 0), (0.40340438, 0), (0.36980447, 0), (0.06792577, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235582983A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/101 [============================&gt;.] - ETA: 0s - loss: 0.5289 - auc: 0.5667WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C014C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 9ms/step - loss: 0.5308 - auc: 0.5639 - val_loss: 0.3169 - val_auc: 0.4346
Epoch 2/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5126 - auc: 0.6312 - val_loss: 0.2994 - val_auc: 0.5718
Epoch 3/20
101/101 [==============================] - 1s 6ms/step - loss: 0.5166 - auc: 0.6140 - val_loss: 0.2828 - val_auc: 0.4961
Epoch 4/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5002 - auc: 0.6645 - val_loss: 0.3016 - val_auc: 0.6372
Epoch 5/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5046 - auc: 0.6597 - val_loss: 0.2920 - val_auc: 0.6756
Epoch 6/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4904 - auc: 0.7015 - val_loss: 0.2612 - val_auc: 0.6186
Epoch 7/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5000 - auc: 0.6649 - val_loss: 0.2790 - val_auc: 0.7036
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4927 - auc: 0.6839 - val_loss: 0.2781 - val_auc: 0.6186
Epoch 9/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4933 - auc: 0.6855 - val_loss: 0.2947 - val_auc: 0.6166
Epoch 10/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5000 - auc: 0.6700 - val_loss: 0.2947 - val_auc: 0.6176
Epoch 11/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4995 - auc: 0.6972 - val_loss: 0.2646 - val_auc: 0.7307
Epoch 12/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5037 - auc: 0.6645 - val_loss: 0.2827 - val_auc: 0.6630
Epoch 13/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4815 - auc: 0.7171 - val_loss: 0.2827 - val_auc: 0.6463
Epoch 14/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4820 - auc: 0.6994 - val_loss: 0.2654 - val_auc: 0.6740
Epoch 15/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4796 - auc: 0.7151 - val_loss: 0.2829 - val_auc: 0.5863
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4885 - auc: 0.7003 - val_loss: 0.2704 - val_auc: 0.6888
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4952 - auc: 0.6824 - val_loss: 0.2775 - val_auc: 0.6273
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4728 - auc: 0.7335 - val_loss: 0.2704 - val_auc: 0.6398
Epoch 19/20
101/101 [==============================] - 1s 6ms/step - loss: 0.4881 - auc: 0.7108 - val_loss: 0.2691 - val_auc: 0.7307
Epoch 20/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4766 - auc: 0.7264 - val_loss: 0.2798 - val_auc: 0.7419
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B5C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8723338, 0), (0.79915196, 0), (0.71699345, 0), (0.7164071, 0), (0.7142634, 0), (0.7100118, 0), (0.70458263, 0), (0.68591386, 0), (0.56341344, 0), (0.45119166, 0), (0.1534822, 0), (0.0, 1)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235027298B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.6853 - auc: 0.5164WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235076519D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.6863 - auc: 0.5159 - val_loss: 0.5105 - val_auc: 0.6672
Epoch 2/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5883 - auc: 0.5907 - val_loss: 0.4526 - val_auc: 0.6315
Epoch 3/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5784 - auc: 0.5738 - val_loss: 0.4586 - val_auc: 0.6220
Epoch 4/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5237 - auc: 0.6516 - val_loss: 0.3628 - val_auc: 0.6978
Epoch 5/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5453 - auc: 0.6115 - val_loss: 0.4025 - val_auc: 0.5959
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5175 - auc: 0.6515 - val_loss: 0.3684 - val_auc: 0.7182
Epoch 7/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4946 - auc: 0.6933 - val_loss: 0.3582 - val_auc: 0.5884
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4890 - auc: 0.7046 - val_loss: 0.3240 - val_auc: 0.5581
Epoch 9/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5008 - auc: 0.6706 - val_loss: 0.3243 - val_auc: 0.5415
Epoch 10/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4980 - auc: 0.6745 - val_loss: 0.3282 - val_auc: 0.5130
Epoch 11/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4981 - auc: 0.6677 - val_loss: 0.3480 - val_auc: 0.4974
Epoch 12/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4904 - auc: 0.6853 - val_loss: 0.3245 - val_auc: 0.6267
Epoch 13/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5030 - auc: 0.6778 - val_loss: 0.3352 - val_auc: 0.5818
Epoch 14/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4926 - auc: 0.6849 - val_loss: 0.3193 - val_auc: 0.6485
Epoch 15/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4913 - auc: 0.6987 - val_loss: 0.3095 - val_auc: 0.6200
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4952 - auc: 0.6880 - val_loss: 0.3181 - val_auc: 0.6416
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4682 - auc: 0.7079 - val_loss: 0.3170 - val_auc: 0.6220
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4732 - auc: 0.7241 - val_loss: 0.2766 - val_auc: 0.6779
Epoch 19/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4776 - auc: 0.7210 - val_loss: 0.2980 - val_auc: 0.6586
Epoch 20/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4818 - auc: 0.7125 - val_loss: 0.3122 - val_auc: 0.6742
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503094E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9366324, 0), (0.822307, 0), (0.77827656, 0), (0.7781573, 0), (0.75985634, 0), (0.7554792, 0), (0.6929809, 0), (0.69191575, 0), (0.5794146, 0), (0.5516217, 0), (0.010612444, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F993A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 98/101 [============================&gt;.] - ETA: 0s - loss: 0.5267 - auc: 0.5817WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.5263 - auc: 0.5872 - val_loss: 0.4293 - val_auc: 0.4139
Epoch 2/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5062 - auc: 0.6163 - val_loss: 0.3868 - val_auc: 0.4678
Epoch 3/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5070 - auc: 0.6181 - val_loss: 0.3933 - val_auc: 0.5350
Epoch 4/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5012 - auc: 0.6073 - val_loss: 0.3742 - val_auc: 0.5812
Epoch 5/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4904 - auc: 0.6134 - val_loss: 0.3617 - val_auc: 0.3792
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4787 - auc: 0.6597 - val_loss: 0.3605 - val_auc: 0.3709
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4703 - auc: 0.6649 - val_loss: 0.3640 - val_auc: 0.7162
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4718 - auc: 0.6834 - val_loss: 0.3485 - val_auc: 0.5485
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6339 - val_loss: 0.3417 - val_auc: 0.5817
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.6921 - val_loss: 0.3505 - val_auc: 0.5157
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4776 - auc: 0.6774 - val_loss: 0.3409 - val_auc: 0.5426
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4706 - auc: 0.6899 - val_loss: 0.3525 - val_auc: 0.5494
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.6727 - val_loss: 0.3496 - val_auc: 0.5319
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.6805 - val_loss: 0.3479 - val_auc: 0.6556
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4672 - auc: 0.6800 - val_loss: 0.3427 - val_auc: 0.6033
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.6925 - val_loss: 0.3466 - val_auc: 0.6467
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.6646 - val_loss: 0.3531 - val_auc: 0.6188
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4581 - auc: 0.7233 - val_loss: 0.3414 - val_auc: 0.6122
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4769 - auc: 0.6857 - val_loss: 0.3477 - val_auc: 0.5423
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4663 - auc: 0.7089 - val_loss: 0.3509 - val_auc: 0.4885
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502FB0CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.42648122, 1), (0.37703004, 0), (0.3537411, 0), (0.35342148, 0), (0.35074243, 1), (0.35039756, 0), (0.35039756, 1), (0.35039756, 0), (0.34988484, 0), (0.30267206, 1), (0.014576848, 0), (0.0, 0)]
1.0
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235582980D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/101 [=========================&gt;....] - ETA: 0s - loss: 0.5299 - auc: 0.5772WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350339C828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5224 - auc: 0.5695 - val_loss: 0.2754 - val_auc: 0.6314
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5138 - auc: 0.6188 - val_loss: 0.2493 - val_auc: 0.3682
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.5961 - val_loss: 0.2589 - val_auc: 0.5725
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5103 - auc: 0.6409 - val_loss: 0.2548 - val_auc: 0.3943
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5037 - auc: 0.6326 - val_loss: 0.2508 - val_auc: 0.4578
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5089 - auc: 0.6264 - val_loss: 0.2612 - val_auc: 0.4910
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5103 - auc: 0.6561 - val_loss: 0.2576 - val_auc: 0.4443
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6548 - val_loss: 0.2577 - val_auc: 0.5345
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6586 - val_loss: 0.2603 - val_auc: 0.4874
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6765 - val_loss: 0.2499 - val_auc: 0.5000
Epoch 11/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5008 - auc: 0.6816 - val_loss: 0.2586 - val_auc: 0.5187
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.6906 - val_loss: 0.2614 - val_auc: 0.5006
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4873 - auc: 0.6971 - val_loss: 0.2689 - val_auc: 0.4623
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4685 - auc: 0.7230 - val_loss: 0.2566 - val_auc: 0.4913
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6934 - val_loss: 0.2592 - val_auc: 0.5474
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6833 - val_loss: 0.2607 - val_auc: 0.5422
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4990 - auc: 0.6668 - val_loss: 0.2603 - val_auc: 0.5232
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4778 - auc: 0.7278 - val_loss: 0.2525 - val_auc: 0.5235
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7118 - val_loss: 0.2631 - val_auc: 0.5354
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6821 - val_loss: 0.2625 - val_auc: 0.5403
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF05E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8470861, 0), (0.79643893, 0), (0.7817346, 0), (0.74660665, 0), (0.739532, 0), (0.73118645, 0), (0.72845215, 0), (0.7254423, 0), (0.7200827, 0), (0.71687424, 1), (0.45525786, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235036DB798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 98/101 [============================&gt;.] - ETA: 0s - loss: 0.7670 - auc: 0.5234WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350812F438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.7571 - auc: 0.5298 - val_loss: 0.4052 - val_auc: 0.3720
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6545 - auc: 0.5664 - val_loss: 0.5324 - val_auc: 0.4280
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5547 - auc: 0.6489 - val_loss: 0.3717 - val_auc: 0.4852
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5555 - auc: 0.6245 - val_loss: 0.4550 - val_auc: 0.5260
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5188 - auc: 0.6662 - val_loss: 0.4396 - val_auc: 0.5455
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6494 - val_loss: 0.4030 - val_auc: 0.4909
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.6518 - val_loss: 0.4466 - val_auc: 0.4494
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5128 - auc: 0.6412 - val_loss: 0.4486 - val_auc: 0.4768
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5136 - auc: 0.6432 - val_loss: 0.4829 - val_auc: 0.5342
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4892 - auc: 0.6740 - val_loss: 0.4177 - val_auc: 0.6159
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4754 - auc: 0.6858 - val_loss: 0.3692 - val_auc: 0.5838
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4711 - auc: 0.7102 - val_loss: 0.3885 - val_auc: 0.5364
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6887 - val_loss: 0.3817 - val_auc: 0.5057
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6819 - val_loss: 0.3667 - val_auc: 0.4865
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.6949 - val_loss: 0.4056 - val_auc: 0.4756
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4710 - auc: 0.7081 - val_loss: 0.3780 - val_auc: 0.5310
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.6913 - val_loss: 0.3683 - val_auc: 0.5485
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4634 - auc: 0.7209 - val_loss: 0.3774 - val_auc: 0.5201
Epoch 19/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4810 - auc: 0.7193 - val_loss: 0.3597 - val_auc: 0.4868
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4761 - auc: 0.6956 - val_loss: 0.3623 - val_auc: 0.4930
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235076E10D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9454952, 0), (0.862274, 0), (0.8576372, 0), (0.84801346, 1), (0.84764016, 0), (0.8198087, 0), (0.81922394, 0), (0.71603984, 0), (0.6320862, 0), (0.55358374, 0), (0.34852606, 1), (0.0, 0)]
0.4
0.6666666666666666
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023557F37E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.5402 - auc: 0.5262WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504A77DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5359 - auc: 0.5302 - val_loss: 0.5066 - val_auc: 0.4020
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.5374 - val_loss: 0.4737 - val_auc: 0.3818
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5076 - auc: 0.5155 - val_loss: 0.4747 - val_auc: 0.4576
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4824 - auc: 0.5608 - val_loss: 0.4554 - val_auc: 0.5035
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.5971 - val_loss: 0.4566 - val_auc: 0.5204
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4668 - auc: 0.6152 - val_loss: 0.4499 - val_auc: 0.5516
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4726 - auc: 0.5944 - val_loss: 0.4597 - val_auc: 0.5172
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4680 - auc: 0.6019 - val_loss: 0.4548 - val_auc: 0.5156
Epoch 9/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4585 - auc: 0.6563 - val_loss: 0.4540 - val_auc: 0.5705
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4545 - auc: 0.6622 - val_loss: 0.4610 - val_auc: 0.4950
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4530 - auc: 0.6791 - val_loss: 0.4680 - val_auc: 0.5028
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.6572 - val_loss: 0.4653 - val_auc: 0.5186
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4528 - auc: 0.6669 - val_loss: 0.4637 - val_auc: 0.5425
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4597 - auc: 0.6456 - val_loss: 0.4631 - val_auc: 0.5644
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4554 - auc: 0.6579 - val_loss: 0.4692 - val_auc: 0.5521
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4521 - auc: 0.6823 - val_loss: 0.4724 - val_auc: 0.5356
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4596 - auc: 0.6436 - val_loss: 0.4738 - val_auc: 0.4848
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4588 - auc: 0.6567 - val_loss: 0.4709 - val_auc: 0.5360
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.6741 - val_loss: 0.4578 - val_auc: 0.6299
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4326 - auc: 0.7218 - val_loss: 0.4806 - val_auc: 0.5156
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502FB05E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (1.0, 0), (1.0, 1), (0.99865496, 1), (0.86815435, 0), (0.85056144, 1), (0.83076084, 1), (0.7958496, 0), (0.20836511, 1), (0.15335822, 0), (0.1315259, 0), (0.02368884, 0), (0.0, 1)]
0.4
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504C01558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/101 [=========================&gt;....] - ETA: 0s - loss: 0.5000 - auc: 0.5754WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503094EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5082 - auc: 0.5730 - val_loss: 0.3039 - val_auc: 0.4328
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.6324 - val_loss: 0.2963 - val_auc: 0.3828
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5068 - auc: 0.5923 - val_loss: 0.2970 - val_auc: 0.4195
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.6399 - val_loss: 0.3080 - val_auc: 0.4320
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6758 - val_loss: 0.3145 - val_auc: 0.4514
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4771 - auc: 0.6835 - val_loss: 0.3337 - val_auc: 0.3887
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.6859 - val_loss: 0.3086 - val_auc: 0.3906
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6614 - val_loss: 0.3350 - val_auc: 0.3345
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4799 - auc: 0.6735 - val_loss: 0.3094 - val_auc: 0.4217
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.6601 - val_loss: 0.3082 - val_auc: 0.4523
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4802 - auc: 0.6731 - val_loss: 0.3282 - val_auc: 0.3816
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.6649 - val_loss: 0.3364 - val_auc: 0.3758
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4708 - auc: 0.6840 - val_loss: 0.3048 - val_auc: 0.4221
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4720 - auc: 0.6954 - val_loss: 0.3248 - val_auc: 0.4229
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4815 - auc: 0.6770 - val_loss: 0.3205 - val_auc: 0.3940
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.7058 - val_loss: 0.3250 - val_auc: 0.4143
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4677 - auc: 0.7007 - val_loss: 0.3317 - val_auc: 0.4120
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6916 - val_loss: 0.3218 - val_auc: 0.3856
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4586 - auc: 0.7224 - val_loss: 0.3089 - val_auc: 0.3872
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.6946 - val_loss: 0.3121 - val_auc: 0.4324
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235095939D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8593614, 0), (0.83489954, 1), (0.7977325, 0), (0.74086696, 0), (0.74086696, 0), (0.74086696, 0), (0.74086696, 0), (0.74086696, 1), (0.7005362, 0), (0.6518032, 0), (0.15306768, 0), (0.0, 1)]
0.2
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B5A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.5889 - auc: 0.5291WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286CC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.5865 - auc: 0.5301 - val_loss: 0.3733 - val_auc: 0.5875
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5420 - auc: 0.5750 - val_loss: 0.3636 - val_auc: 0.6825
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5227 - auc: 0.6167 - val_loss: 0.4056 - val_auc: 0.5912
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5113 - auc: 0.6401 - val_loss: 0.3760 - val_auc: 0.5705
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6365 - val_loss: 0.3401 - val_auc: 0.5769
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6791 - val_loss: 0.3228 - val_auc: 0.6126
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.6750 - val_loss: 0.3568 - val_auc: 0.5653
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6687 - val_loss: 0.3399 - val_auc: 0.5751
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6934 - val_loss: 0.3128 - val_auc: 0.6062
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.7149 - val_loss: 0.3253 - val_auc: 0.6102
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6713 - val_loss: 0.3085 - val_auc: 0.6045
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6653 - val_loss: 0.3222 - val_auc: 0.6022
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6635 - val_loss: 0.3166 - val_auc: 0.5852
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.7039 - val_loss: 0.3086 - val_auc: 0.5884
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.6896 - val_loss: 0.2926 - val_auc: 0.6405
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7139 - val_loss: 0.3006 - val_auc: 0.6393
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4877 - auc: 0.7106 - val_loss: 0.2850 - val_auc: 0.6028
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6949 - val_loss: 0.3137 - val_auc: 0.6077
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7282 - val_loss: 0.3122 - val_auc: 0.6007
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4649 - auc: 0.7477 - val_loss: 0.3144 - val_auc: 0.5774
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509593E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9749941, 0), (0.9580883, 0), (0.94992006, 0), (0.9295487, 0), (0.92838, 0), (0.81980133, 0), (0.6257393, 0), (0.1438333, 0), (0.10753906, 0), (0.09174618, 1), (0.040918123, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A6F948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - ETA: 0s - loss: 0.5310 - auc: 0.5606WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502FB0168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5310 - auc: 0.5606 - val_loss: 0.2644 - val_auc: 0.6140
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5166 - auc: 0.6285 - val_loss: 0.2351 - val_auc: 0.5740
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5065 - auc: 0.6592 - val_loss: 0.2363 - val_auc: 0.5708
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5142 - auc: 0.6144 - val_loss: 0.2637 - val_auc: 0.5852
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.6649 - val_loss: 0.2546 - val_auc: 0.4724
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.6601 - val_loss: 0.2632 - val_auc: 0.6287
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4991 - auc: 0.6660 - val_loss: 0.2552 - val_auc: 0.6042
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6841 - val_loss: 0.2704 - val_auc: 0.4744
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4778 - auc: 0.7095 - val_loss: 0.2653 - val_auc: 0.4888
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6735 - val_loss: 0.2517 - val_auc: 0.5806
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6738 - val_loss: 0.2594 - val_auc: 0.5233
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6438 - val_loss: 0.2718 - val_auc: 0.5219
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6832 - val_loss: 0.2719 - val_auc: 0.4522
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4918 - auc: 0.6962 - val_loss: 0.2710 - val_auc: 0.4493
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6751 - val_loss: 0.2753 - val_auc: 0.5553
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7248 - val_loss: 0.2754 - val_auc: 0.5009
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6686 - val_loss: 0.2646 - val_auc: 0.5472
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.7092 - val_loss: 0.2777 - val_auc: 0.5127
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4825 - auc: 0.7029 - val_loss: 0.2650 - val_auc: 0.5751
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6802 - val_loss: 0.2694 - val_auc: 0.6114
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504AB7318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.75910753, 0), (0.7241283, 0), (0.70914173, 0), (0.70885724, 0), (0.70810264, 0), (0.7057679, 0), (0.7017535, 0), (0.6856302, 0), (0.6747731, 0), (0.6737151, 0), (0.67228574, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 98/101 [============================&gt;.] - ETA: 0s - loss: 0.5291 - auc: 0.5486WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0C0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5314 - auc: 0.5444 - val_loss: 0.2592 - val_auc: 0.4095
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5153 - auc: 0.6130 - val_loss: 0.2731 - val_auc: 0.6099
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6455 - val_loss: 0.2919 - val_auc: 0.5541
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5156 - auc: 0.6425 - val_loss: 0.2910 - val_auc: 0.5184
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5037 - auc: 0.6699 - val_loss: 0.2733 - val_auc: 0.4820
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5072 - auc: 0.6261 - val_loss: 0.2755 - val_auc: 0.5274
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6603 - val_loss: 0.2620 - val_auc: 0.5255
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6733 - val_loss: 0.2850 - val_auc: 0.5425
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6950 - val_loss: 0.2800 - val_auc: 0.5776
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7198 - val_loss: 0.2702 - val_auc: 0.5793
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.7008 - val_loss: 0.2563 - val_auc: 0.4349
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6733 - val_loss: 0.2742 - val_auc: 0.5909
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4729 - auc: 0.7219 - val_loss: 0.2893 - val_auc: 0.5612
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4722 - auc: 0.7449 - val_loss: 0.2814 - val_auc: 0.6227
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.7017 - val_loss: 0.2970 - val_auc: 0.5725
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.7163 - val_loss: 0.2858 - val_auc: 0.5805
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.7021 - val_loss: 0.3004 - val_auc: 0.5863
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.7232 - val_loss: 0.2882 - val_auc: 0.5622
Epoch 19/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4729 - auc: 0.7165 - val_loss: 0.2865 - val_auc: 0.5493
Epoch 20/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4878 - auc: 0.6998 - val_loss: 0.2816 - val_auc: 0.5670
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023508100948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7156624, 0), (0.71250105, 0), (0.5170345, 0), (0.4910755, 0), (0.4826793, 1), (0.46744743, 0), (0.4527268, 0), (0.326963, 0), (0.2324169, 0), (0.22897176, 0), (0.19747101, 0), (0.0, 0)]
0.0
0.0
Siam
[0.6, 0.6666666666666666, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.4, 0.2, 0.0, 0.0, 0.0]
0.19333333333333333
[0.5, 0.5, -1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, -1.0, 0.2, 0.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.0, -1.0, 0.0]
0.26666666666666666
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[14]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350AB70E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.5505 - auc: 0.5189WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FAE4C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5442 - auc: 0.5417 - val_loss: 0.3245 - val_auc: 0.4984
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5177 - auc: 0.6022 - val_loss: 0.3009 - val_auc: 0.5376
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6233 - val_loss: 0.2848 - val_auc: 0.3349
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6289 - val_loss: 0.2983 - val_auc: 0.3804
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6404 - val_loss: 0.2785 - val_auc: 0.3556
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6580 - val_loss: 0.2928 - val_auc: 0.4106
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7038 - val_loss: 0.3020 - val_auc: 0.5418
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6552 - val_loss: 0.2943 - val_auc: 0.4624
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.6985 - val_loss: 0.3002 - val_auc: 0.4693
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6657 - val_loss: 0.2837 - val_auc: 0.5683
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.6796 - val_loss: 0.2705 - val_auc: 0.6169
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6709 - val_loss: 0.2683 - val_auc: 0.5873
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7078 - val_loss: 0.3072 - val_auc: 0.5339
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6864 - val_loss: 0.3060 - val_auc: 0.5741
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.6840 - val_loss: 0.3108 - val_auc: 0.4672
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6713 - val_loss: 0.2853 - val_auc: 0.4704
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.6783 - val_loss: 0.2967 - val_auc: 0.5206
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4650 - auc: 0.7060 - val_loss: 0.2804 - val_auc: 0.6190
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4620 - auc: 0.7404 - val_loss: 0.2848 - val_auc: 0.5677
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4661 - auc: 0.7338 - val_loss: 0.2756 - val_auc: 0.5233
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235083249D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8588222, 1), (0.79105043, 0), (0.7284763, 1), (0.7053892, 0), (0.6382421, 0), (0.6141496, 1), (0.5939457, 1), (0.58026606, 1), (0.57617056, 0), (0.5575538, 1), (0.553049, 1), (0.54135567, 1), (0.53662723, 1), (0.5257422, 0), (0.52525383, 0), (0.5168949, 0), (0.5167157, 0), (0.5164598, 0), (0.51004684, 0), (0.507053, 0), (0.50625014, 0), (0.5037979, 1), (0.5035318, 0), (0.5027166, 0), (0.5016764, 0), (0.4991257, 0), (0.4983246, 0), (0.4982038, 0), (0.49656126, 0), (0.49586686, 0), (0.4955326, 0), (0.49521738, 0), (0.49499178, 0), (0.49389195, 1), (0.49388754, 0), (0.49267137, 0), (0.49264932, 0), (0.49206823, 1), (0.49092737, 1), (0.49091625, 0), (0.4898937, 1), (0.4868036, 0), (0.47564954, 0), (0.47365788, 0), (0.44623148, 0), (0.43307504, 0), (0.31743726, 0), (0.2578001, 1), (0.07779354, 1), (0.0, 0)]
0.5
0.3125
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350A17F708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.5631 - auc: 0.5399WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5465 - auc: 0.5522 - val_loss: 0.3069 - val_auc: 0.5466
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5584 - auc: 0.5011 - val_loss: 0.3222 - val_auc: 0.6820
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6338 - val_loss: 0.3017 - val_auc: 0.4598
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5100 - auc: 0.6504 - val_loss: 0.3015 - val_auc: 0.6656
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6779 - val_loss: 0.2935 - val_auc: 0.6519
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6667 - val_loss: 0.2631 - val_auc: 0.5159
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5146 - auc: 0.6225 - val_loss: 0.2801 - val_auc: 0.5032
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6628 - val_loss: 0.2793 - val_auc: 0.4746
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.7002 - val_loss: 0.2646 - val_auc: 0.7376
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5049 - auc: 0.6662 - val_loss: 0.2880 - val_auc: 0.6799
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6811 - val_loss: 0.2768 - val_auc: 0.5016
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.6640 - val_loss: 0.2682 - val_auc: 0.5730
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4915 - auc: 0.7073 - val_loss: 0.2724 - val_auc: 0.5524
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5121 - auc: 0.6707 - val_loss: 0.2743 - val_auc: 0.6312
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6780 - val_loss: 0.2709 - val_auc: 0.6106
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.6795 - val_loss: 0.2630 - val_auc: 0.6354
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.7006 - val_loss: 0.2666 - val_auc: 0.6111
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.7140 - val_loss: 0.2589 - val_auc: 0.5831
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4949 - auc: 0.6656 - val_loss: 0.2747 - val_auc: 0.5508
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7186 - val_loss: 0.2861 - val_auc: 0.6296
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B5C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98655194, 1), (0.9014219, 1), (0.82821494, 1), (0.7944235, 0), (0.7930469, 0), (0.7900769, 0), (0.78642184, 0), (0.76685697, 0), (0.7528977, 0), (0.73862445, 0), (0.7279238, 0), (0.72254544, 0), (0.7219684, 0), (0.7181834, 0), (0.71781003, 0), (0.7168803, 0), (0.7152802, 1), (0.71415865, 0), (0.71165407, 0), (0.7106737, 0), (0.70849603, 0), (0.7070116, 0), (0.70513505, 0), (0.7042023, 0), (0.7040941, 0), (0.7018892, 1), (0.7008842, 0), (0.70053387, 0), (0.6951896, 0), (0.69340706, 0), (0.689468, 0), (0.68730384, 0), (0.6858884, 0), (0.6843113, 1), (0.6838642, 0), (0.6838287, 1), (0.6807718, 1), (0.67932296, 1), (0.6790655, 0), (0.6776488, 0), (0.6760198, 0), (0.65608394, 0), (0.59288514, 1), (0.544812, 0), (0.5005134, 0), (0.40592664, 0), (0.39499682, 0), (0.29768994, 0), (0.29306838, 0), (0.0, 0)]
0.3
0.3
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023509CD81F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.8485 - auc: 0.5043WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286C5E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.8306 - auc: 0.5040 - val_loss: 0.7248 - val_auc: 0.5614
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6482 - auc: 0.5544 - val_loss: 0.6724 - val_auc: 0.5005
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6275 - auc: 0.5694 - val_loss: 0.5954 - val_auc: 0.6048
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5735 - auc: 0.6207 - val_loss: 0.6228 - val_auc: 0.4836
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5725 - auc: 0.6036 - val_loss: 0.6376 - val_auc: 0.5735
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5455 - auc: 0.6416 - val_loss: 0.5338 - val_auc: 0.5889
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5241 - auc: 0.6602 - val_loss: 0.5270 - val_auc: 0.4831
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5376 - auc: 0.6393 - val_loss: 0.4724 - val_auc: 0.6370
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5235 - auc: 0.6520 - val_loss: 0.4775 - val_auc: 0.4249
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5191 - auc: 0.6541 - val_loss: 0.4551 - val_auc: 0.4762
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5199 - auc: 0.6599 - val_loss: 0.4438 - val_auc: 0.6444
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5095 - auc: 0.6604 - val_loss: 0.3957 - val_auc: 0.6354
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.7051 - val_loss: 0.3653 - val_auc: 0.6524
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6857 - val_loss: 0.3579 - val_auc: 0.6540
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5059 - auc: 0.6730 - val_loss: 0.3942 - val_auc: 0.6481
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6890 - val_loss: 0.3608 - val_auc: 0.6217
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5036 - auc: 0.6686 - val_loss: 0.3307 - val_auc: 0.6730
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.7121 - val_loss: 0.3264 - val_auc: 0.7037
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5100 - auc: 0.6663 - val_loss: 0.3395 - val_auc: 0.7323
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.6974 - val_loss: 0.3274 - val_auc: 0.6275
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502B9C8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.96217614, 0), (0.9546646, 0), (0.9439277, 0), (0.86415404, 0), (0.84430975, 0), (0.81496394, 0), (0.80951977, 0), (0.8094407, 0), (0.80827457, 0), (0.8037306, 0), (0.80350083, 0), (0.8026117, 0), (0.80223846, 0), (0.80220765, 0), (0.80163187, 0), (0.80149883, 0), (0.80079544, 0), (0.7973393, 0), (0.79321414, 1), (0.793032, 0), (0.79255927, 0), (0.7915164, 0), (0.7842405, 0), (0.78332275, 0), (0.77556133, 0), (0.7706207, 0), (0.7701235, 0), (0.7681649, 0), (0.7568236, 0), (0.7462649, 0), (0.7419594, 0), (0.739342, 0), (0.7352339, 1), (0.7068317, 0), (0.7016149, 0), (0.6941909, 0), (0.69381386, 1), (0.66008794, 0), (0.6154543, 0), (0.5660222, 0), (0.55854326, 0), (0.5236857, 0), (0.4922748, 1), (0.48934537, 0), (0.46716473, 0), (0.43580842, 0), (0.35724065, 0), (0.34233603, 0), (0.19083774, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504A6FD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.6246 - auc: 0.5164WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023508324438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 7ms/step - loss: 0.6192 - auc: 0.5116 - val_loss: 0.5026 - val_auc: 0.5265
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5639 - auc: 0.5771 - val_loss: 0.4180 - val_auc: 0.7508
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5307 - auc: 0.6369 - val_loss: 0.4556 - val_auc: 0.6704
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5261 - auc: 0.6482 - val_loss: 0.4645 - val_auc: 0.3423
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6550 - val_loss: 0.4246 - val_auc: 0.6667
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5254 - auc: 0.6414 - val_loss: 0.3993 - val_auc: 0.6339
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6770 - val_loss: 0.3472 - val_auc: 0.7280
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5183 - auc: 0.6582 - val_loss: 0.3186 - val_auc: 0.7587
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6566 - val_loss: 0.3269 - val_auc: 0.7910
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.7211 - val_loss: 0.3528 - val_auc: 0.5577
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.7052 - val_loss: 0.3538 - val_auc: 0.4677
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.7110 - val_loss: 0.3346 - val_auc: 0.3730
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.7230 - val_loss: 0.3406 - val_auc: 0.4984
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6952 - val_loss: 0.3448 - val_auc: 0.6423
Epoch 15/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4971 - auc: 0.7005 - val_loss: 0.3235 - val_auc: 0.6651
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4938 - auc: 0.6897 - val_loss: 0.2880 - val_auc: 0.8529
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7213 - val_loss: 0.3250 - val_auc: 0.5873
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.7080 - val_loss: 0.3065 - val_auc: 0.6058
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4745 - auc: 0.7452 - val_loss: 0.3226 - val_auc: 0.6122
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.7140 - val_loss: 0.3151 - val_auc: 0.5280
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502FB0288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.96026295, 0), (0.9464201, 0), (0.94434595, 1), (0.93314445, 0), (0.92818093, 0), (0.92666495, 0), (0.92637366, 0), (0.9258718, 0), (0.925514, 0), (0.9236943, 1), (0.9207461, 0), (0.9203379, 0), (0.9166774, 0), (0.912423, 0), (0.91196054, 0), (0.911191, 0), (0.9106925, 0), (0.9106617, 1), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.9106617, 0), (0.909582, 0), (0.8974818, 0), (0.878127, 1), (0.87803394, 0), (0.8647816, 0), (0.85798275, 0), (0.8481925, 0), (0.8366516, 0), (0.78213984, 0), (0.7796199, 0), (0.75457793, 0), (0.73752743, 0), (0.7033886, 0), (0.66115063, 0), (0.65418696, 0), (0.6509249, 0), (0.599718, 0), (0.5396278, 0), (0.5154702, 0), (0.45442605, 1), (0.4358162, 0), (0.3991282, 0), (0.37123597, 0), (0.0, 0)]
0.1
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502258DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/97 [==========================&gt;...] - ETA: 0s - loss: 0.5519 - auc: 0.4615WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5483 - auc: 0.4742 - val_loss: 0.3252 - val_auc: 0.6270
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5138 - auc: 0.6288 - val_loss: 0.3102 - val_auc: 0.6090
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5144 - auc: 0.6556 - val_loss: 0.2799 - val_auc: 0.5275
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5146 - auc: 0.6457 - val_loss: 0.3060 - val_auc: 0.5550
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5108 - auc: 0.6555 - val_loss: 0.2883 - val_auc: 0.7228
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6881 - val_loss: 0.3185 - val_auc: 0.7074
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5047 - auc: 0.6827 - val_loss: 0.3323 - val_auc: 0.6741
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5090 - auc: 0.6766 - val_loss: 0.2661 - val_auc: 0.7042
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4765 - auc: 0.7298 - val_loss: 0.2606 - val_auc: 0.7730
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6890 - val_loss: 0.3008 - val_auc: 0.6169
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.7183 - val_loss: 0.2880 - val_auc: 0.6825
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.7079 - val_loss: 0.3120 - val_auc: 0.6598
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7178 - val_loss: 0.2745 - val_auc: 0.6730
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.7382 - val_loss: 0.2894 - val_auc: 0.6878
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4724 - auc: 0.7284 - val_loss: 0.3215 - val_auc: 0.7026
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4822 - auc: 0.7278 - val_loss: 0.2805 - val_auc: 0.6931
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.7412 - val_loss: 0.3046 - val_auc: 0.5963
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4741 - auc: 0.7244 - val_loss: 0.2956 - val_auc: 0.5794
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4765 - auc: 0.7337 - val_loss: 0.3055 - val_auc: 0.5847
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4738 - auc: 0.7473 - val_loss: 0.3065 - val_auc: 0.6048
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350812FEE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9449915, 0), (0.8834788, 0), (0.7949173, 0), (0.72374314, 0), (0.69477457, 0), (0.6808948, 0), (0.6735621, 0), (0.6622881, 0), (0.657802, 0), (0.6572201, 0), (0.6426683, 0), (0.64123064, 0), (0.6383215, 0), (0.6349117, 0), (0.63359475, 0), (0.6293536, 0), (0.6276451, 1), (0.6272243, 0), (0.6257631, 0), (0.6195229, 1), (0.6187501, 0), (0.6179244, 1), (0.61516666, 0), (0.61357003, 0), (0.6070694, 0), (0.6058153, 0), (0.60118663, 1), (0.6005099, 0), (0.59896266, 0), (0.59721416, 1), (0.5707523, 0), (0.56570363, 1), (0.5587097, 0), (0.5534715, 0), (0.5291497, 0), (0.47954085, 0), (0.4743314, 0), (0.43563184, 0), (0.43343157, 0), (0.4011491, 0), (0.3880212, 0), (0.38236615, 0), (0.3401271, 0), (0.3309533, 0), (0.27043104, 0), (0.26077324, 0), (0.21868803, 0), (0.1932422, 0), (0.12708622, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
84/97 [========================&gt;.....] - ETA: 0s - loss: 0.6013 - auc: 0.5597WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502490678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.6017 - auc: 0.5616 - val_loss: 0.6503 - val_auc: 0.7794
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5681 - auc: 0.5737 - val_loss: 0.4377 - val_auc: 0.7841
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5615 - auc: 0.5913 - val_loss: 0.4709 - val_auc: 0.6868
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5418 - auc: 0.6180 - val_loss: 0.4804 - val_auc: 0.6217
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5084 - auc: 0.6762 - val_loss: 0.3908 - val_auc: 0.4492
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6704 - val_loss: 0.3983 - val_auc: 0.3751
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5214 - auc: 0.6387 - val_loss: 0.3601 - val_auc: 0.5360
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6633 - val_loss: 0.3485 - val_auc: 0.5667
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4892 - auc: 0.6840 - val_loss: 0.3141 - val_auc: 0.7624
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4998 - auc: 0.6720 - val_loss: 0.3413 - val_auc: 0.5429
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.7034 - val_loss: 0.3395 - val_auc: 0.5175
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4798 - auc: 0.7039 - val_loss: 0.3182 - val_auc: 0.5741
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6810 - val_loss: 0.3075 - val_auc: 0.5693
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5141 - auc: 0.6705 - val_loss: 0.3163 - val_auc: 0.6185
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6901 - val_loss: 0.3215 - val_auc: 0.5037
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.7028 - val_loss: 0.2917 - val_auc: 0.6053
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4627 - auc: 0.7371 - val_loss: 0.3396 - val_auc: 0.5693
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.7097 - val_loss: 0.3356 - val_auc: 0.5291
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.7284 - val_loss: 0.3044 - val_auc: 0.6735
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4649 - auc: 0.7381 - val_loss: 0.2994 - val_auc: 0.6751
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A6F828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98903614, 0), (0.9633779, 1), (0.9303771, 1), (0.8761082, 0), (0.8629392, 0), (0.85742265, 1), (0.85405606, 0), (0.8507322, 0), (0.82990587, 0), (0.82744205, 0), (0.82026625, 0), (0.8108654, 0), (0.78764665, 0), (0.7846379, 0), (0.78257334, 0), (0.77896684, 0), (0.77777684, 0), (0.75925547, 0), (0.75735873, 0), (0.7427975, 1), (0.7419028, 1), (0.73184204, 1), (0.71744263, 1), (0.71471435, 0), (0.71433264, 0), (0.70477253, 0), (0.7028909, 0), (0.6906033, 0), (0.67690223, 1), (0.6712661, 0), (0.664945, 0), (0.63375056, 0), (0.6220501, 1), (0.61257684, 0), (0.6023178, 0), (0.5759121, 1), (0.5586419, 0), (0.5416674, 0), (0.5361013, 1), (0.5307228, 0), (0.49917263, 0), (0.47987983, 0), (0.44414333, 0), (0.40072915, 0), (0.39777353, 0), (0.29925302, 0), (0.28994444, 0), (0.26144597, 0), (0.24541393, 0), (0.0, 0)]
0.3
0.2727272727272727
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235038804C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/97 [==========================&gt;...] - ETA: 0s - loss: 0.6019 - auc: 0.5611WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235044974C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.6024 - auc: 0.5681 - val_loss: 0.4300 - val_auc: 0.7307
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5389 - auc: 0.6079 - val_loss: 0.4743 - val_auc: 0.7365
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5466 - auc: 0.5878 - val_loss: 0.4305 - val_auc: 0.6921
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5306 - auc: 0.6133 - val_loss: 0.4229 - val_auc: 0.6566
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5241 - auc: 0.6261 - val_loss: 0.3626 - val_auc: 0.7042
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5150 - auc: 0.6310 - val_loss: 0.4137 - val_auc: 0.6291
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.6856 - val_loss: 0.3410 - val_auc: 0.6989
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4734 - auc: 0.7039 - val_loss: 0.3229 - val_auc: 0.8132
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7022 - val_loss: 0.3227 - val_auc: 0.6974
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4714 - auc: 0.7140 - val_loss: 0.3285 - val_auc: 0.6646
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.7009 - val_loss: 0.3178 - val_auc: 0.6365
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6841 - val_loss: 0.3138 - val_auc: 0.6873
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.6915 - val_loss: 0.3294 - val_auc: 0.6376
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6494 - val_loss: 0.3320 - val_auc: 0.6815
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6999 - val_loss: 0.3268 - val_auc: 0.7481
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4671 - auc: 0.7285 - val_loss: 0.3201 - val_auc: 0.6704
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4804 - auc: 0.7016 - val_loss: 0.3281 - val_auc: 0.6481
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4811 - auc: 0.7226 - val_loss: 0.3120 - val_auc: 0.6317
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7186 - val_loss: 0.3159 - val_auc: 0.6344
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.7147 - val_loss: 0.2921 - val_auc: 0.7138
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350497E558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98222077, 0), (0.9764324, 1), (0.9633787, 0), (0.9388685, 0), (0.9384954, 0), (0.9257745, 0), (0.9131101, 0), (0.9104327, 0), (0.9080754, 1), (0.87522995, 0), (0.8717919, 0), (0.8647351, 0), (0.85435516, 0), (0.8539997, 1), (0.845775, 0), (0.8375063, 0), (0.8359963, 0), (0.82817835, 1), (0.82566637, 0), (0.8194697, 1), (0.818771, 0), (0.81178945, 1), (0.8059731, 1), (0.7867682, 1), (0.7535099, 0), (0.74891853, 0), (0.74245065, 1), (0.73155063, 1), (0.7120933, 0), (0.69156617, 1), (0.69060844, 0), (0.66742915, 0), (0.6007275, 0), (0.56380886, 0), (0.561174, 0), (0.5262694, 0), (0.5121019, 0), (0.5035794, 0), (0.50227886, 0), (0.45534548, 0), (0.44957688, 0), (0.41220593, 0), (0.40866485, 0), (0.30902767, 0), (0.29324937, 1), (0.28814325, 0), (0.18110532, 0), (0.15729319, 1), (0.15571807, 1), (0.0, 0)]
0.2
0.14285714285714285
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350239AD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.6980 - auc: 0.4632WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DB948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 8ms/step - loss: 0.6874 - auc: 0.4726 - val_loss: 0.5534 - val_auc: 0.6429
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5914 - auc: 0.5228 - val_loss: 0.4895 - val_auc: 0.6715
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5484 - auc: 0.6024 - val_loss: 0.3546 - val_auc: 0.4476
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5308 - auc: 0.6302 - val_loss: 0.3747 - val_auc: 0.5948
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5338 - auc: 0.6001 - val_loss: 0.3875 - val_auc: 0.5590
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5076 - auc: 0.6473 - val_loss: 0.3550 - val_auc: 0.5527
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5133 - auc: 0.6392 - val_loss: 0.3211 - val_auc: 0.6209
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5159 - auc: 0.6389 - val_loss: 0.3278 - val_auc: 0.6557
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6949 - val_loss: 0.2970 - val_auc: 0.6446
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5025 - auc: 0.6803 - val_loss: 0.2896 - val_auc: 0.5641
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.7013 - val_loss: 0.2970 - val_auc: 0.5601
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.7044 - val_loss: 0.2998 - val_auc: 0.6190
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.6970 - val_loss: 0.2758 - val_auc: 0.6060
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.7066 - val_loss: 0.2960 - val_auc: 0.5663
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4869 - auc: 0.6991 - val_loss: 0.2862 - val_auc: 0.5215
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.7186 - val_loss: 0.2768 - val_auc: 0.5848
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.7151 - val_loss: 0.2746 - val_auc: 0.5959
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5099 - auc: 0.6908 - val_loss: 0.2854 - val_auc: 0.5957
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.7107 - val_loss: 0.2979 - val_auc: 0.4984
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.7100 - val_loss: 0.3007 - val_auc: 0.5394
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350812FAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.94032216, 0), (0.86153483, 0), (0.8131594, 0), (0.80406046, 0), (0.76613694, 0), (0.7336945, 0), (0.7249067, 1), (0.7083586, 0), (0.6712855, 0), (0.66960806, 0), (0.6499414, 0), (0.63602406, 0), (0.6213667, 0), (0.61709356, 1), (0.61082286, 0), (0.61076653, 0), (0.6051007, 0), (0.601735, 0), (0.59565026, 0), (0.58919835, 0), (0.5830111, 0), (0.5818679, 0), (0.58067405, 0), (0.57756305, 0), (0.5766152, 0), (0.57641125, 0), (0.57539964, 0), (0.5692686, 0), (0.5635008, 0), (0.54868865, 0), (0.53071773, 0), (0.52611095, 0), (0.5254043, 0), (0.5104681, 0), (0.48890707, 0), (0.4821791, 0), (0.47235635, 0), (0.460426, 0), (0.45383364, 0), (0.4411581, 0), (0.4183496, 0), (0.40459037, 0), (0.3958444, 0), (0.3556184, 0), (0.29022652, 0), (0.2871628, 0), (0.28279725, 0), (0.25741363, 0), (0.21578628, 0), (0.0, 0)]
0.1
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503FAE708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/97 [==========================&gt;...] - ETA: 0s - loss: 0.7300 - auc: 0.5074WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.7253 - auc: 0.5158 - val_loss: 0.8295 - val_auc: 0.4587
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6435 - auc: 0.5381 - val_loss: 0.7185 - val_auc: 0.7349
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6148 - auc: 0.5782 - val_loss: 0.6392 - val_auc: 0.5143
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5528 - auc: 0.6325 - val_loss: 0.5430 - val_auc: 0.7021
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5749 - auc: 0.5996 - val_loss: 0.5394 - val_auc: 0.6899
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5229 - auc: 0.6544 - val_loss: 0.4665 - val_auc: 0.5979
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6780 - val_loss: 0.3861 - val_auc: 0.5963
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6968 - val_loss: 0.4001 - val_auc: 0.7217
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5171 - auc: 0.6800 - val_loss: 0.4241 - val_auc: 0.6450
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5075 - auc: 0.6769 - val_loss: 0.4423 - val_auc: 0.6249
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6850 - val_loss: 0.4435 - val_auc: 0.6037
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6886 - val_loss: 0.4100 - val_auc: 0.6598
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6890 - val_loss: 0.4393 - val_auc: 0.5772
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4782 - auc: 0.7307 - val_loss: 0.3936 - val_auc: 0.7032
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4948 - auc: 0.7026 - val_loss: 0.4222 - val_auc: 0.6571
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4889 - auc: 0.7070 - val_loss: 0.4088 - val_auc: 0.6286
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7148 - val_loss: 0.4110 - val_auc: 0.6175
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4809 - auc: 0.7120 - val_loss: 0.3648 - val_auc: 0.6339
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4650 - auc: 0.7432 - val_loss: 0.3868 - val_auc: 0.6201
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.7170 - val_loss: 0.3645 - val_auc: 0.6360
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509CD8EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.97187215, 0), (0.97172517, 0), (0.9407236, 0), (0.9331591, 1), (0.92738545, 0), (0.9234516, 0), (0.9230089, 1), (0.920768, 0), (0.91444814, 0), (0.9121095, 0), (0.90532094, 0), (0.90492135, 1), (0.90147877, 0), (0.89966804, 1), (0.8990621, 0), (0.8963568, 0), (0.8958452, 0), (0.8886643, 0), (0.8846342, 1), (0.8811074, 0), (0.8804392, 0), (0.87866586, 0), (0.87803715, 0), (0.8715393, 0), (0.8703822, 1), (0.86280376, 0), (0.86238897, 0), (0.8623624, 0), (0.85863733, 0), (0.8547878, 0), (0.85215163, 0), (0.85076475, 0), (0.84398055, 1), (0.8044099, 0), (0.7863514, 0), (0.72849643, 0), (0.6347051, 0), (0.63363487, 0), (0.63089806, 0), (0.55139095, 0), (0.4999888, 0), (0.48941833, 0), (0.4490062, 0), (0.40550134, 0), (0.3523468, 0), (0.34450197, 0), (0.3307347, 1), (0.20024115, 0), (0.19612752, 0), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235022581F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.6552 - auc: 0.5103WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286CC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.6432 - auc: 0.5111 - val_loss: 0.6071 - val_auc: 0.8370
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5580 - auc: 0.6027 - val_loss: 0.3953 - val_auc: 0.7201
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5646 - auc: 0.5824 - val_loss: 0.5196 - val_auc: 0.7101
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6773 - val_loss: 0.4243 - val_auc: 0.5873
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5309 - auc: 0.6214 - val_loss: 0.3940 - val_auc: 0.7116
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6738 - val_loss: 0.3370 - val_auc: 0.8238
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6478 - val_loss: 0.3284 - val_auc: 0.7259
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6601 - val_loss: 0.3117 - val_auc: 0.8376
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6888 - val_loss: 0.3042 - val_auc: 0.7164
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4758 - auc: 0.7107 - val_loss: 0.2967 - val_auc: 0.6831
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.7040 - val_loss: 0.3078 - val_auc: 0.6577
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6843 - val_loss: 0.3126 - val_auc: 0.5937
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6698 - val_loss: 0.3112 - val_auc: 0.5910
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.6789 - val_loss: 0.2670 - val_auc: 0.6545
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6813 - val_loss: 0.2970 - val_auc: 0.6042
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4744 - auc: 0.6937 - val_loss: 0.2733 - val_auc: 0.5534
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.6855 - val_loss: 0.2678 - val_auc: 0.6148
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4870 - auc: 0.6946 - val_loss: 0.2681 - val_auc: 0.5968
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7413 - val_loss: 0.2589 - val_auc: 0.6508
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6951 - val_loss: 0.2710 - val_auc: 0.6196
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023558298828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9926045, 0), (0.9633633, 0), (0.92624646, 0), (0.88868326, 1), (0.8818963, 0), (0.8653455, 0), (0.8467183, 0), (0.83196646, 0), (0.83053875, 0), (0.82447994, 0), (0.8168811, 1), (0.8049224, 1), (0.8021723, 0), (0.79619837, 1), (0.7859504, 0), (0.7837587, 0), (0.7812496, 1), (0.78057194, 1), (0.778191, 0), (0.777964, 0), (0.7722857, 1), (0.7701537, 1), (0.76215357, 1), (0.76124007, 0), (0.75717777, 0), (0.7489715, 1), (0.742112, 0), (0.72862655, 1), (0.6920708, 0), (0.68315953, 0), (0.6643259, 0), (0.65914506, 0), (0.6318862, 0), (0.61441344, 1), (0.6014426, 0), (0.5728814, 0), (0.53363013, 0), (0.52333164, 0), (0.52263546, 0), (0.44179428, 1), (0.42189208, 0), (0.40312028, 0), (0.3819461, 0), (0.33444864, 1), (0.31918612, 0), (0.30328137, 0), (0.2862477, 0), (0.22709084, 0), (0.21523245, 0), (0.0, 0)]
0.1
0.07142857142857142
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023CF0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/97 [=========================&gt;....] - ETA: 0s - loss: 0.5547 - auc: 0.5276WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235022583A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.5561 - auc: 0.5365 - val_loss: 0.2813 - val_auc: 0.5667
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5377 - auc: 0.5938 - val_loss: 0.3105 - val_auc: 0.5937
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5258 - auc: 0.6205 - val_loss: 0.2577 - val_auc: 0.6159
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.6598 - val_loss: 0.2715 - val_auc: 0.3434
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5124 - auc: 0.6636 - val_loss: 0.3054 - val_auc: 0.3630
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5117 - auc: 0.6461 - val_loss: 0.2992 - val_auc: 0.5651
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6601 - val_loss: 0.2941 - val_auc: 0.6217
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5098 - auc: 0.6623 - val_loss: 0.2969 - val_auc: 0.5481
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5196 - auc: 0.6444 - val_loss: 0.2748 - val_auc: 0.6127
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4849 - auc: 0.7022 - val_loss: 0.3013 - val_auc: 0.6698
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6692 - val_loss: 0.2811 - val_auc: 0.6185
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5144 - auc: 0.6772 - val_loss: 0.2936 - val_auc: 0.5243
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5152 - auc: 0.6684 - val_loss: 0.3087 - val_auc: 0.5847
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6849 - val_loss: 0.2675 - val_auc: 0.5942
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.7041 - val_loss: 0.2824 - val_auc: 0.4735
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6943 - val_loss: 0.2749 - val_auc: 0.4376
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.7183 - val_loss: 0.2925 - val_auc: 0.4460
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6806 - val_loss: 0.3171 - val_auc: 0.4492
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6856 - val_loss: 0.3029 - val_auc: 0.5101
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4986 - auc: 0.7107 - val_loss: 0.2633 - val_auc: 0.5672
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235083245E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99844617, 0), (0.92299706, 1), (0.87588584, 0), (0.86660415, 0), (0.85444516, 0), (0.84852415, 0), (0.8373189, 0), (0.82830095, 1), (0.8191852, 0), (0.7923317, 0), (0.7893171, 0), (0.78533185, 0), (0.78453356, 0), (0.78245294, 0), (0.77368283, 0), (0.7598549, 0), (0.7489049, 0), (0.7431224, 0), (0.74273896, 0), (0.7377754, 0), (0.73659426, 0), (0.73432696, 0), (0.7328095, 0), (0.7309425, 0), (0.7262084, 0), (0.7246995, 0), (0.72398657, 0), (0.7148758, 0), (0.7146134, 0), (0.70904654, 0), (0.7089889, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 1), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7046744, 0), (0.7002469, 0), (0.61009765, 0), (0.5817382, 0), (0.3981602, 0), (0.3831833, 0), (0.32555404, 1), (0.29779226, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235580A0288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/97 [=========================&gt;....] - ETA: 0s - loss: 0.5158 - auc: 0.5853WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350A17F708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5286 - auc: 0.5727 - val_loss: 0.3048 - val_auc: 0.3859
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5374 - auc: 0.5844 - val_loss: 0.2933 - val_auc: 0.4484
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5292 - auc: 0.5504 - val_loss: 0.2818 - val_auc: 0.4130
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5102 - auc: 0.6550 - val_loss: 0.3096 - val_auc: 0.4427
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6772 - val_loss: 0.2706 - val_auc: 0.5462
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.6431 - val_loss: 0.3038 - val_auc: 0.4818
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6530 - val_loss: 0.2939 - val_auc: 0.4908
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5215 - auc: 0.6415 - val_loss: 0.2876 - val_auc: 0.4902
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6724 - val_loss: 0.2954 - val_auc: 0.4212
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6644 - val_loss: 0.2878 - val_auc: 0.4470
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.6966 - val_loss: 0.2912 - val_auc: 0.4658
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6712 - val_loss: 0.2679 - val_auc: 0.4978
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5083 - auc: 0.6491 - val_loss: 0.2789 - val_auc: 0.5690
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6507 - val_loss: 0.3082 - val_auc: 0.4538
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.6729 - val_loss: 0.2797 - val_auc: 0.4908
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5055 - auc: 0.6671 - val_loss: 0.2992 - val_auc: 0.4766
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5042 - auc: 0.6592 - val_loss: 0.2825 - val_auc: 0.5209
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4856 - auc: 0.6958 - val_loss: 0.2950 - val_auc: 0.5728
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4943 - auc: 0.7025 - val_loss: 0.2743 - val_auc: 0.5584
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6914 - val_loss: 0.2838 - val_auc: 0.5215
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509CD81F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9829094, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 1), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.9705485, 0), (0.96961546, 0), (0.96756, 0), (0.96685153, 0), (0.95014036, 0), (0.94618636, 0), (0.9437519, 0), (0.93848723, 0), (0.911221, 1), (0.90435076, 0), (0.8999566, 0), (0.8979681, 0), (0.89526254, 0), (0.881477, 0), (0.8769081, 0), (0.8550984, 0), (0.83919287, 0), (0.8076516, 0), (0.8053054, 0), (0.7988408, 0), (0.7829545, 0), (0.76648235, 0), (0.7519075, 0), (0.7449707, 0), (0.7330385, 0), (0.6898067, 0), (0.67879707, 0), (0.67786473, 0), (0.6709861, 0), (0.6528605, 0), (0.6392448, 0), (0.5271022, 0), (0.4367303, 0), (0.38602403, 0), (0.32229632, 0), (0.0, 0)]
0.1
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
93/97 [===========================&gt;..] - ETA: 0s - loss: 0.5820 - auc: 0.5124 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0CCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.5915 - auc: 0.5038 - val_loss: 0.3797 - val_auc: 0.3429
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5387 - auc: 0.5695 - val_loss: 0.3640 - val_auc: 0.5476
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5281 - auc: 0.5937 - val_loss: 0.3412 - val_auc: 0.5460
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5253 - auc: 0.5985 - val_loss: 0.3674 - val_auc: 0.6460
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6536 - val_loss: 0.3175 - val_auc: 0.6460
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.6641 - val_loss: 0.3255 - val_auc: 0.5423
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4758 - auc: 0.6932 - val_loss: 0.3344 - val_auc: 0.6693
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4918 - auc: 0.6617 - val_loss: 0.2911 - val_auc: 0.6508
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4918 - auc: 0.6726 - val_loss: 0.3310 - val_auc: 0.6175
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.6803 - val_loss: 0.3142 - val_auc: 0.5989
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.6859 - val_loss: 0.2913 - val_auc: 0.6011
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.7162 - val_loss: 0.3129 - val_auc: 0.5164
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6794 - val_loss: 0.2931 - val_auc: 0.5921
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.7074 - val_loss: 0.3038 - val_auc: 0.5249
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6868 - val_loss: 0.2889 - val_auc: 0.5751
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4814 - auc: 0.6871 - val_loss: 0.3149 - val_auc: 0.5772
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.6884 - val_loss: 0.2943 - val_auc: 0.5989
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6841 - val_loss: 0.2818 - val_auc: 0.5672
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4628 - auc: 0.7091 - val_loss: 0.2764 - val_auc: 0.6090
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4629 - auc: 0.7168 - val_loss: 0.2860 - val_auc: 0.5302
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF11F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.939809, 0), (0.9264962, 1), (0.85320973, 0), (0.8512711, 1), (0.83963096, 0), (0.80650145, 0), (0.8032333, 1), (0.7919964, 0), (0.7785864, 0), (0.77712566, 1), (0.77500236, 0), (0.77040076, 1), (0.76627666, 0), (0.7620955, 0), (0.7516726, 1), (0.7401011, 0), (0.7368333, 0), (0.7287191, 0), (0.7270381, 0), (0.7256172, 1), (0.7210206, 1), (0.70650136, 1), (0.7029919, 0), (0.6884369, 1), (0.6875871, 1), (0.6777302, 0), (0.67218643, 0), (0.6646208, 0), (0.6505324, 0), (0.64873564, 0), (0.64552426, 0), (0.6442624, 1), (0.64345473, 1), (0.6417014, 0), (0.63939387, 0), (0.62602365, 0), (0.61937714, 1), (0.59625274, 0), (0.5843354, 0), (0.5821214, 0), (0.56764203, 0), (0.56653386, 1), (0.54093903, 1), (0.44588766, 0), (0.4122183, 0), (0.36455125, 0), (0.3566511, 1), (0.33728018, 0), (0.32994524, 0), (0.0, 0)]
0.4
0.2222222222222222
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504C01F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.7814 - auc: 0.5083WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 6ms/step - loss: 0.7788 - auc: 0.5056 - val_loss: 0.5230 - val_auc: 0.5954
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.6129 - auc: 0.5803 - val_loss: 0.4510 - val_auc: 0.4324
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5622 - auc: 0.6262 - val_loss: 0.4527 - val_auc: 0.5134
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5619 - auc: 0.6142 - val_loss: 0.4051 - val_auc: 0.4980
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5428 - auc: 0.6137 - val_loss: 0.3778 - val_auc: 0.5142
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5397 - auc: 0.6320 - val_loss: 0.4240 - val_auc: 0.6316
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5290 - auc: 0.6385 - val_loss: 0.3819 - val_auc: 0.6138
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5247 - auc: 0.6323 - val_loss: 0.3612 - val_auc: 0.5174
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5112 - auc: 0.6745 - val_loss: 0.3844 - val_auc: 0.5743
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5099 - auc: 0.6586 - val_loss: 0.3444 - val_auc: 0.4906
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6622 - val_loss: 0.4148 - val_auc: 0.5010
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5041 - auc: 0.6605 - val_loss: 0.3744 - val_auc: 0.5373
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4815 - auc: 0.7147 - val_loss: 0.3564 - val_auc: 0.5432
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7267 - val_loss: 0.3267 - val_auc: 0.6001
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5027 - auc: 0.6935 - val_loss: 0.3413 - val_auc: 0.5698
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5134 - auc: 0.6632 - val_loss: 0.3569 - val_auc: 0.5780
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6882 - val_loss: 0.3352 - val_auc: 0.5837
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.7050 - val_loss: 0.3276 - val_auc: 0.5430
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.7247 - val_loss: 0.3062 - val_auc: 0.5032
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.7109 - val_loss: 0.3253 - val_auc: 0.5564
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF1AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98705125, 0), (0.9633364, 0), (0.9560452, 0), (0.949901, 0), (0.9478731, 0), (0.9425601, 0), (0.93948436, 1), (0.9365938, 0), (0.89344525, 0), (0.88842213, 0), (0.8826533, 0), (0.8803475, 0), (0.87828207, 0), (0.8653551, 0), (0.86006266, 0), (0.8583369, 0), (0.85345227, 0), (0.8490274, 0), (0.8430136, 0), (0.8414624, 0), (0.83840233, 0), (0.80878556, 0), (0.7982304, 0), (0.7855493, 0), (0.7754359, 0), (0.76837015, 0), (0.71269804, 0), (0.7111538, 0), (0.7012342, 0), (0.69691825, 0), (0.6713289, 0), (0.65411675, 0), (0.64981127, 0), (0.6444447, 0), (0.6306892, 0), (0.6282021, 0), (0.61568785, 0), (0.5526444, 0), (0.5250788, 0), (0.51755846, 0), (0.49424186, 0), (0.468104, 0), (0.41970295, 0), (0.40967798, 0), (0.3939656, 0), (0.38810304, 0), (0.38188788, 0), (0.35657793, 0), (0.34884015, 0), (0.0, 0)]
0.1
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502F0C798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/97 [=========================&gt;....] - ETA: 0s - loss: 0.6952 - auc: 0.5187WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023509CD80D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 6ms/step - loss: 0.6851 - auc: 0.5258 - val_loss: 0.4014 - val_auc: 0.6392
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5775 - auc: 0.5956 - val_loss: 0.4595 - val_auc: 0.5772
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5462 - auc: 0.6338 - val_loss: 0.5384 - val_auc: 0.5915
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5659 - auc: 0.5748 - val_loss: 0.4231 - val_auc: 0.4037
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5348 - auc: 0.6245 - val_loss: 0.4005 - val_auc: 0.4751
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5132 - auc: 0.6484 - val_loss: 0.3803 - val_auc: 0.5423
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.6316 - val_loss: 0.4346 - val_auc: 0.4593
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5042 - auc: 0.6683 - val_loss: 0.3642 - val_auc: 0.5201
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.6983 - val_loss: 0.3149 - val_auc: 0.5201
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6796 - val_loss: 0.3684 - val_auc: 0.5503
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.6884 - val_loss: 0.3254 - val_auc: 0.5947
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4989 - auc: 0.6551 - val_loss: 0.3227 - val_auc: 0.5667
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4915 - auc: 0.6928 - val_loss: 0.3320 - val_auc: 0.5884
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4864 - auc: 0.6876 - val_loss: 0.3199 - val_auc: 0.5656
Epoch 15/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.6882 - val_loss: 0.3167 - val_auc: 0.5720
Epoch 16/20
97/97 [==============================] - ETA: 0s - loss: 0.4908 - auc: 0.705 - 0s 4ms/step - loss: 0.4777 - auc: 0.7074 - val_loss: 0.2957 - val_auc: 0.5831
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4805 - auc: 0.6982 - val_loss: 0.3134 - val_auc: 0.5032
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4762 - auc: 0.6990 - val_loss: 0.2848 - val_auc: 0.5640
Epoch 19/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6897 - val_loss: 0.3121 - val_auc: 0.5349
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4922 - auc: 0.6991 - val_loss: 0.3176 - val_auc: 0.4815
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF01F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.60329306, 1), (0.58193207, 0), (0.5799405, 0), (0.57924914, 0), (0.5648626, 0), (0.5556384, 0), (0.55275685, 0), (0.5525985, 0), (0.552557, 1), (0.5493332, 0), (0.54905105, 0), (0.54848266, 1), (0.5451844, 0), (0.542355, 0), (0.54130715, 1), (0.5400933, 0), (0.53834224, 0), (0.53531295, 0), (0.5336714, 1), (0.5291832, 0), (0.52861965, 1), (0.5275145, 0), (0.5238989, 0), (0.5238989, 0), (0.5238989, 1), (0.5238989, 0), (0.5238989, 1), (0.5238989, 0), (0.5238989, 0), (0.5165265, 0), (0.5148495, 0), (0.51033264, 0), (0.5077268, 0), (0.5028029, 1), (0.4995796, 0), (0.49251705, 0), (0.4924577, 0), (0.4879826, 1), (0.48525536, 0), (0.4745463, 0), (0.46937832, 0), (0.4656073, 0), (0.41538352, 0), (0.40407726, 1), (0.37079504, 1), (0.2832961, 0), (0.24397022, 0), (0.23622711, 0), (0.23401901, 0), (0.0, 0)]
0.3
0.23076923076923078
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502B6DC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.5644 - auc: 0.4865WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB78B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 1s 8ms/step - loss: 0.5690 - auc: 0.4836 - val_loss: 0.3436 - val_auc: 0.4884
Epoch 2/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5127 - auc: 0.5660 - val_loss: 0.2976 - val_auc: 0.6429
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5133 - auc: 0.5684 - val_loss: 0.3244 - val_auc: 0.7630
Epoch 4/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4729 - auc: 0.6398 - val_loss: 0.3464 - val_auc: 0.6582
Epoch 5/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4882 - auc: 0.6059 - val_loss: 0.2920 - val_auc: 0.7127
Epoch 6/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4756 - auc: 0.6180 - val_loss: 0.3212 - val_auc: 0.5778
Epoch 7/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4533 - auc: 0.6817 - val_loss: 0.2547 - val_auc: 0.7164
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4662 - auc: 0.6604 - val_loss: 0.3051 - val_auc: 0.6582
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4608 - auc: 0.6842 - val_loss: 0.2795 - val_auc: 0.7354
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4545 - auc: 0.6893 - val_loss: 0.2666 - val_auc: 0.7423
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4575 - auc: 0.6744 - val_loss: 0.2996 - val_auc: 0.6762
Epoch 12/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4514 - auc: 0.6956 - val_loss: 0.2880 - val_auc: 0.6646
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4626 - auc: 0.6797 - val_loss: 0.2774 - val_auc: 0.7333
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4584 - auc: 0.6824 - val_loss: 0.2783 - val_auc: 0.6317
Epoch 15/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4579 - auc: 0.6937 - val_loss: 0.2767 - val_auc: 0.7307
Epoch 16/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4621 - auc: 0.6795 - val_loss: 0.2903 - val_auc: 0.7349
Epoch 17/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4522 - auc: 0.6914 - val_loss: 0.2681 - val_auc: 0.6582
Epoch 18/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4584 - auc: 0.6768 - val_loss: 0.2772 - val_auc: 0.7587
Epoch 19/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4635 - auc: 0.6814 - val_loss: 0.3060 - val_auc: 0.7243
Epoch 20/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4519 - auc: 0.6966 - val_loss: 0.2345 - val_auc: 0.7984
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A773A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8137477, 1), (0.7619571, 1), (0.75665826, 0), (0.7359043, 1), (0.72616416, 1), (0.72612274, 0), (0.7238255, 1), (0.72309715, 1), (0.71824306, 1), (0.7153053, 1), (0.7090929, 1), (0.703318, 0), (0.7021632, 0), (0.69576925, 1), (0.68596023, 1), (0.6813082, 1), (0.6502746, 0), (0.6463513, 0), (0.63591284, 1), (0.6160747, 0), (0.6160309, 1), (0.60932463, 0), (0.60568386, 1), (0.5691384, 1), (0.55817443, 0), (0.5396576, 1), (0.52864313, 0), (0.5163162, 1), (0.51464856, 1), (0.49473864, 1), (0.4927853, 1), (0.4454505, 0), (0.4373557, 1), (0.4329778, 1), (0.418893, 0), (0.27597848, 1), (0.26233315, 0), (0.2612096, 1), (0.24533126, 1), (0.23990397, 1), (0.23874688, 0), (0.2234795, 1), (0.2184876, 1), (0.14683072, 1), (0.13577966, 1), (0.12943992, 1), (0.12898251, 0), (0.017316483, 1), (0.0069581787, 0), (0.0, 1)]
0.7
0.20588235294117646
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235021A75E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.5722 - auc: 0.5255WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503094B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 9ms/step - loss: 0.5714 - auc: 0.5257 - val_loss: 0.3106 - val_auc: 0.6804
Epoch 2/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5244 - auc: 0.5947 - val_loss: 0.3036 - val_auc: 0.6164
Epoch 3/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5095 - auc: 0.6472 - val_loss: 0.2829 - val_auc: 0.7317
Epoch 4/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5106 - auc: 0.6213 - val_loss: 0.2936 - val_auc: 0.5979
Epoch 5/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4941 - auc: 0.6522 - val_loss: 0.2792 - val_auc: 0.6608
Epoch 6/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4929 - auc: 0.6562 - val_loss: 0.2391 - val_auc: 0.7508
Epoch 7/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5007 - auc: 0.6786 - val_loss: 0.2687 - val_auc: 0.7037
Epoch 8/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4873 - auc: 0.6847 - val_loss: 0.2656 - val_auc: 0.6439
Epoch 9/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4858 - auc: 0.6838 - val_loss: 0.2838 - val_auc: 0.6439
Epoch 10/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4818 - auc: 0.7069 - val_loss: 0.2780 - val_auc: 0.5370
Epoch 11/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4818 - auc: 0.7206 - val_loss: 0.2773 - val_auc: 0.5804
Epoch 12/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4871 - auc: 0.7197 - val_loss: 0.2852 - val_auc: 0.5159
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4877 - auc: 0.6838 - val_loss: 0.2881 - val_auc: 0.5730
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4780 - auc: 0.7150 - val_loss: 0.2608 - val_auc: 0.5794
Epoch 15/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4766 - auc: 0.7272 - val_loss: 0.2638 - val_auc: 0.6185
Epoch 16/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4781 - auc: 0.7065 - val_loss: 0.2794 - val_auc: 0.6714
Epoch 17/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4605 - auc: 0.7345 - val_loss: 0.3019 - val_auc: 0.6693
Epoch 18/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4923 - auc: 0.7041 - val_loss: 0.2635 - val_auc: 0.7175
Epoch 19/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4810 - auc: 0.7054 - val_loss: 0.2803 - val_auc: 0.6571
Epoch 20/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4604 - auc: 0.7472 - val_loss: 0.2953 - val_auc: 0.6074
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF11F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7075829, 0), (0.68162996, 0), (0.6103998, 0), (0.5595871, 1), (0.5551318, 0), (0.53748214, 0), (0.5346112, 0), (0.5344243, 1), (0.5329863, 0), (0.5324682, 0), (0.5317016, 1), (0.53147954, 1), (0.53028494, 0), (0.5277443, 0), (0.5272625, 1), (0.5226373, 0), (0.52205616, 0), (0.52149373, 0), (0.5177307, 0), (0.51459575, 0), (0.51429445, 0), (0.5137932, 0), (0.5116931, 0), (0.5021339, 0), (0.49960452, 1), (0.4993052, 0), (0.4955267, 0), (0.49434757, 0), (0.4907034, 0), (0.48167786, 0), (0.4800077, 0), (0.47492748, 0), (0.46780318, 0), (0.46025747, 0), (0.4593499, 0), (0.45564735, 1), (0.43594375, 0), (0.42415884, 1), (0.42180467, 0), (0.38845518, 0), (0.38230675, 1), (0.3345788, 1), (0.3212339, 1), (0.3139671, 0), (0.31383318, 0), (0.28430295, 0), (0.24464832, 0), (0.16411088, 0), (0.027477939, 1), (0.0, 0)]
0.2
0.16666666666666666
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/97 [==========================&gt;...] - ETA: 0s - loss: 0.5314 - auc: 0.5680WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502258A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 11ms/step - loss: 0.5347 - auc: 0.5703 - val_loss: 0.3006 - val_auc: 0.6317
Epoch 2/20
97/97 [==============================] - 1s 6ms/step - loss: 0.5199 - auc: 0.6121 - val_loss: 0.2863 - val_auc: 0.7794
Epoch 3/20
97/97 [==============================] - 1s 6ms/step - loss: 0.5180 - auc: 0.5938 - val_loss: 0.2755 - val_auc: 0.6698
Epoch 4/20
97/97 [==============================] - 1s 6ms/step - loss: 0.5066 - auc: 0.6515 - val_loss: 0.3059 - val_auc: 0.5169
Epoch 5/20
97/97 [==============================] - 1s 6ms/step - loss: 0.5205 - auc: 0.6489 - val_loss: 0.2558 - val_auc: 0.7429
Epoch 6/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5175 - auc: 0.6545 - val_loss: 0.2732 - val_auc: 0.4746
Epoch 7/20
97/97 [==============================] - 1s 6ms/step - loss: 0.5067 - auc: 0.6796 - val_loss: 0.2739 - val_auc: 0.5254
Epoch 8/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5016 - auc: 0.6779 - val_loss: 0.2859 - val_auc: 0.5794
Epoch 9/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5161 - auc: 0.6676 - val_loss: 0.3052 - val_auc: 0.6095
Epoch 10/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5050 - auc: 0.6992 - val_loss: 0.2994 - val_auc: 0.6222
Epoch 11/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4929 - auc: 0.7039 - val_loss: 0.2909 - val_auc: 0.5556
Epoch 12/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5018 - auc: 0.6938 - val_loss: 0.2557 - val_auc: 0.5979
Epoch 13/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4982 - auc: 0.6832 - val_loss: 0.2986 - val_auc: 0.6767
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5024 - auc: 0.6824 - val_loss: 0.3009 - val_auc: 0.6714
Epoch 15/20
97/97 [==============================] - 1s 5ms/step - loss: 0.4974 - auc: 0.6995 - val_loss: 0.2954 - val_auc: 0.6201
Epoch 16/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4863 - auc: 0.7183 - val_loss: 0.3167 - val_auc: 0.6413
Epoch 17/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4948 - auc: 0.7140 - val_loss: 0.2835 - val_auc: 0.5968
Epoch 18/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4953 - auc: 0.6894 - val_loss: 0.2913 - val_auc: 0.6201
Epoch 19/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4918 - auc: 0.7180 - val_loss: 0.2871 - val_auc: 0.5989
Epoch 20/20
97/97 [==============================] - 1s 6ms/step - loss: 0.4768 - auc: 0.7308 - val_loss: 0.3049 - val_auc: 0.5460
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B50D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8390033, 0), (0.777118, 0), (0.7063668, 0), (0.7001411, 1), (0.65808266, 0), (0.6537936, 0), (0.63102657, 0), (0.6252681, 0), (0.61172265, 0), (0.6059798, 0), (0.5834571, 0), (0.5827575, 0), (0.57219887, 0), (0.5527153, 0), (0.55209106, 0), (0.54761297, 0), (0.5469788, 0), (0.5344963, 0), (0.5244494, 0), (0.52256554, 0), (0.51812154, 0), (0.5114381, 0), (0.5082592, 0), (0.5046139, 0), (0.5042372, 0), (0.50216013, 0), (0.50068665, 0), (0.49358022, 0), (0.49264118, 0), (0.489371, 1), (0.48845753, 1), (0.48599705, 0), (0.48247656, 0), (0.47682458, 0), (0.4761791, 0), (0.4752435, 0), (0.46971774, 0), (0.45939845, 0), (0.45386901, 0), (0.45230913, 0), (0.4497295, 0), (0.43166167, 0), (0.4169884, 0), (0.41582516, 0), (0.3662279, 0), (0.34941742, 0), (0.33642083, 1), (0.2566945, 0), (0.140747, 1), (0.0, 0)]
0.1
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503485D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/97 [===========================&gt;..] - ETA: 0s - loss: 0.6783 - auc: 0.5086WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350497E438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 8ms/step - loss: 0.6792 - auc: 0.5042 - val_loss: 0.6040 - val_auc: 0.6263
Epoch 2/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5820 - auc: 0.5889 - val_loss: 0.5435 - val_auc: 0.4220
Epoch 3/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5555 - auc: 0.6162 - val_loss: 0.5662 - val_auc: 0.5709
Epoch 4/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5396 - auc: 0.6409 - val_loss: 0.5198 - val_auc: 0.5017
Epoch 5/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5371 - auc: 0.6371 - val_loss: 0.4753 - val_auc: 0.6028
Epoch 6/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5227 - auc: 0.6505 - val_loss: 0.4312 - val_auc: 0.5292
Epoch 7/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5384 - auc: 0.6282 - val_loss: 0.4318 - val_auc: 0.5141
Epoch 8/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5104 - auc: 0.6504 - val_loss: 0.4154 - val_auc: 0.6237
Epoch 9/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5037 - auc: 0.6777 - val_loss: 0.3824 - val_auc: 0.5571
Epoch 10/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4962 - auc: 0.7009 - val_loss: 0.3587 - val_auc: 0.5820
Epoch 11/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4923 - auc: 0.6981 - val_loss: 0.3187 - val_auc: 0.6310
Epoch 12/20
97/97 [==============================] - 1s 5ms/step - loss: 0.5032 - auc: 0.6963 - val_loss: 0.3697 - val_auc: 0.5111
Epoch 13/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4898 - auc: 0.6982 - val_loss: 0.3421 - val_auc: 0.5786
Epoch 14/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4950 - auc: 0.7032 - val_loss: 0.3521 - val_auc: 0.6384
Epoch 15/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4942 - auc: 0.7067 - val_loss: 0.3743 - val_auc: 0.6011
Epoch 16/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4944 - auc: 0.7071 - val_loss: 0.3264 - val_auc: 0.6048
Epoch 17/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4890 - auc: 0.7018 - val_loss: 0.3057 - val_auc: 0.6411
Epoch 18/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4991 - auc: 0.6952 - val_loss: 0.3374 - val_auc: 0.5645
Epoch 19/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4909 - auc: 0.7062 - val_loss: 0.3345 - val_auc: 0.4919
Epoch 20/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4733 - auc: 0.7296 - val_loss: 0.3197 - val_auc: 0.5806
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235021A7CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.6663685, 0), (0.6054319, 1), (0.58731395, 0), (0.58464736, 0), (0.57888186, 0), (0.57787526, 0), (0.5722909, 0), (0.56658596, 0), (0.5606182, 0), (0.56030023, 0), (0.558929, 0), (0.55743766, 0), (0.5543526, 0), (0.55404764, 0), (0.5539773, 0), (0.5519321, 0), (0.550976, 0), (0.55066264, 1), (0.5500959, 0), (0.5495278, 0), (0.54952353, 0), (0.5437794, 0), (0.5423452, 0), (0.5415724, 0), (0.53887457, 0), (0.5379727, 0), (0.5319024, 0), (0.5317791, 0), (0.5176567, 1), (0.5152057, 0), (0.5125668, 0), (0.5034553, 0), (0.4677077, 0), (0.4664958, 0), (0.46444157, 0), (0.45863745, 0), (0.45636603, 0), (0.4473906, 0), (0.43997055, 0), (0.42307535, 0), (0.40501678, 0), (0.38229278, 0), (0.37340024, 0), (0.35041916, 0), (0.3423978, 0), (0.24353538, 0), (0.24147569, 0), (0.17065634, 0), (0.1338275, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F99CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
93/97 [===========================&gt;..] - ETA: 0s - loss: 0.5391 - auc: 0.5684WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DB048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/97 [==============================] - 2s 7ms/step - loss: 0.5424 - auc: 0.5550 - val_loss: 0.2520 - val_auc: 0.6968
Epoch 2/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5345 - auc: 0.5730 - val_loss: 0.2941 - val_auc: 0.5667
Epoch 3/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5249 - auc: 0.5801 - val_loss: 0.2868 - val_auc: 0.6333
Epoch 4/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5126 - auc: 0.6373 - val_loss: 0.2538 - val_auc: 0.6677
Epoch 5/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5147 - auc: 0.6409 - val_loss: 0.2479 - val_auc: 0.6894
Epoch 6/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5168 - auc: 0.6360 - val_loss: 0.2578 - val_auc: 0.7265
Epoch 7/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5289 - auc: 0.6164 - val_loss: 0.2591 - val_auc: 0.5339
Epoch 8/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5130 - auc: 0.6499 - val_loss: 0.2571 - val_auc: 0.6328
Epoch 9/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5072 - auc: 0.6922 - val_loss: 0.2537 - val_auc: 0.6937
Epoch 10/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.6684 - val_loss: 0.2691 - val_auc: 0.6471
Epoch 11/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5157 - auc: 0.6406 - val_loss: 0.2555 - val_auc: 0.7402
Epoch 12/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6928 - val_loss: 0.2280 - val_auc: 0.7852
Epoch 13/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6592 - val_loss: 0.2490 - val_auc: 0.7360
Epoch 14/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6905 - val_loss: 0.2360 - val_auc: 0.7407
Epoch 15/20
97/97 [==============================] - 0s 5ms/step - loss: 0.5075 - auc: 0.6869 - val_loss: 0.2347 - val_auc: 0.7323
Epoch 16/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.7013 - val_loss: 0.2383 - val_auc: 0.7201
Epoch 17/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5052 - auc: 0.6777 - val_loss: 0.2268 - val_auc: 0.7407
Epoch 18/20
97/97 [==============================] - 0s 4ms/step - loss: 0.5046 - auc: 0.6836 - val_loss: 0.2393 - val_auc: 0.7016
Epoch 19/20
97/97 [==============================] - 0s 5ms/step - loss: 0.4968 - auc: 0.6905 - val_loss: 0.2312 - val_auc: 0.7693
Epoch 20/20
97/97 [==============================] - 0s 4ms/step - loss: 0.4864 - auc: 0.7166 - val_loss: 0.2346 - val_auc: 0.7508
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503094D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98450035, 0), (0.9488726, 0), (0.90968007, 0), (0.82991964, 0), (0.7610235, 0), (0.6966494, 0), (0.69561166, 0), (0.6939206, 0), (0.69273907, 0), (0.68580186, 0), (0.68429774, 0), (0.6834245, 0), (0.68270165, 1), (0.68233085, 0), (0.67969847, 0), (0.67755616, 0), (0.67679274, 0), (0.6759978, 0), (0.67394215, 1), (0.673612, 0), (0.6687263, 0), (0.6687263, 0), (0.6687263, 0), (0.6687263, 0), (0.6687263, 0), (0.6687263, 0), (0.6687263, 0), (0.666511, 0), (0.65814, 0), (0.6499873, 0), (0.636047, 0), (0.601564, 1), (0.5928265, 0), (0.5713996, 0), (0.53881353, 0), (0.53434795, 0), (0.5318742, 0), (0.48212197, 0), (0.46573368, 0), (0.4498897, 0), (0.397638, 0), (0.38893571, 0), (0.38872445, 1), (0.35630938, 0), (0.32080495, 0), (0.25321966, 0), (0.21213989, 0), (0.2116213, 0), (0.19647594, 0), (0.0, 0)]
0.0
0.0
Siam
[0.5, 0.3, 0.0, 0.1, 0.0, 0.3, 0.2, 0.1, 0.2, 0.1, 0.2, 0.1, 0.4, 0.1, 0.3, 0.7, 0.2, 0.1, 0.2, 0.0]
0.20500000000000002
[0.3125, 0.3, 0.0, 0.2, 0.0, 0.2727272727272727, 0.14285714285714285, 0.5, 0.25, 0.07142857142857142, 0.5, 0.5, 0.2222222222222222, 1.0, 0.23076923076923078, 0.20588235294117646, 0.16666666666666666, 0.2, 0.5, 0.0]
0.2787526729806142
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[15]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350A17FA68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5854 - auc: 0.5635WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235022588B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 7ms/step - loss: 0.5798 - auc: 0.5622 - val_loss: 0.3636 - val_auc: 0.4255
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5449 - auc: 0.5930 - val_loss: 0.4875 - val_auc: 0.4960
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5336 - auc: 0.6048 - val_loss: 0.3993 - val_auc: 0.4250
Epoch 4/20
98/98 [==============================] - 0s 5ms/step - loss: 0.5258 - auc: 0.6004 - val_loss: 0.3605 - val_auc: 0.4228
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6507 - val_loss: 0.3415 - val_auc: 0.5419
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6596 - val_loss: 0.3042 - val_auc: 0.5247
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.6899 - val_loss: 0.3255 - val_auc: 0.6124
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4913 - auc: 0.6586 - val_loss: 0.3476 - val_auc: 0.6182
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4760 - auc: 0.6997 - val_loss: 0.2952 - val_auc: 0.6093
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4809 - auc: 0.6911 - val_loss: 0.2806 - val_auc: 0.6332
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4700 - auc: 0.7114 - val_loss: 0.3086 - val_auc: 0.5794
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.7059 - val_loss: 0.3019 - val_auc: 0.5392
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4604 - auc: 0.7150 - val_loss: 0.2958 - val_auc: 0.6966
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4735 - auc: 0.7112 - val_loss: 0.3080 - val_auc: 0.5767
Epoch 15/20
98/98 [==============================] - 0s 5ms/step - loss: 0.4800 - auc: 0.7038 - val_loss: 0.2912 - val_auc: 0.5666
Epoch 16/20
98/98 [==============================] - 0s 5ms/step - loss: 0.4754 - auc: 0.7163 - val_loss: 0.3232 - val_auc: 0.5362
Epoch 17/20
98/98 [==============================] - 0s 5ms/step - loss: 0.4661 - auc: 0.7154 - val_loss: 0.3010 - val_auc: 0.5825
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4701 - auc: 0.7182 - val_loss: 0.2957 - val_auc: 0.6058
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4702 - auc: 0.7115 - val_loss: 0.2852 - val_auc: 0.6186
Epoch 20/20
98/98 [==============================] - 0s 5ms/step - loss: 0.4670 - auc: 0.7144 - val_loss: 0.2986 - val_auc: 0.6512
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502FB03A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.8497081, 0), (0.7797315, 0), (0.74584013, 1), (0.7157343, 0), (0.7136056, 0), (0.7033185, 1), (0.68130934, 1), (0.6771952, 0), (0.674322, 0), (0.67331904, 0), (0.65344816, 0), (0.6512228, 0), (0.64726895, 1), (0.64410424, 0), (0.6360851, 1), (0.6293667, 1), (0.62727034, 0), (0.62394404, 0), (0.60782963, 1), (0.6006411, 0), (0.5994199, 0), (0.59537333, 1), (0.58968645, 0), (0.5859316, 0), (0.5849463, 1), (0.58267426, 0), (0.5782227, 0), (0.5755375, 0), (0.57492006, 0), (0.57415706, 1), (0.567439, 1), (0.56262344, 0), (0.562, 0), (0.56042427, 0), (0.5570149, 0), (0.54576045, 0), (0.49298146, 0), (0.46410456, 0), (0.4393078, 0), (0.3683878, 1), (0.33107364, 0), (0.2813818, 1), (0.23867087, 0), (0.052677896, 1), (0.0, 0)]
0.4
0.26666666666666666
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502EF00D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/98 [=========================&gt;....] - ETA: 0s - loss: 0.7247 - auc: 0.4832WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504723288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.7054 - auc: 0.4953 - val_loss: 0.5613 - val_auc: 0.5503
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5832 - auc: 0.6119 - val_loss: 0.5018 - val_auc: 0.7826
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5591 - auc: 0.6317 - val_loss: 0.4400 - val_auc: 0.7840
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5736 - auc: 0.5928 - val_loss: 0.4207 - val_auc: 0.5088
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5216 - auc: 0.6491 - val_loss: 0.4134 - val_auc: 0.6349
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5318 - auc: 0.6304 - val_loss: 0.4578 - val_auc: 0.5617
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5254 - auc: 0.6304 - val_loss: 0.4253 - val_auc: 0.5913
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6736 - val_loss: 0.4076 - val_auc: 0.4960
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6626 - val_loss: 0.3749 - val_auc: 0.6653
Epoch 10/20
98/98 [==============================] - 0s 5ms/step - loss: 0.5115 - auc: 0.6608 - val_loss: 0.3727 - val_auc: 0.5291
Epoch 11/20
98/98 [==============================] - 0s 5ms/step - loss: 0.4874 - auc: 0.7043 - val_loss: 0.3482 - val_auc: 0.6997
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.6826 - val_loss: 0.3471 - val_auc: 0.5758
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.7044 - val_loss: 0.3405 - val_auc: 0.5661
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6920 - val_loss: 0.3435 - val_auc: 0.7086
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6792 - val_loss: 0.2992 - val_auc: 0.7875
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.6886 - val_loss: 0.2923 - val_auc: 0.8166
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.6894 - val_loss: 0.3198 - val_auc: 0.7130
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4721 - auc: 0.7007 - val_loss: 0.2925 - val_auc: 0.7086
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.6811 - val_loss: 0.2952 - val_auc: 0.7209
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4843 - auc: 0.6982 - val_loss: 0.2893 - val_auc: 0.7187
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502FB0558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.6815438, 0), (0.67513186, 1), (0.66190106, 0), (0.65766305, 0), (0.652898, 0), (0.64701015, 1), (0.6462487, 1), (0.644849, 0), (0.64034307, 0), (0.6359748, 0), (0.6342878, 0), (0.6340341, 0), (0.6316771, 0), (0.6312335, 0), (0.62700605, 1), (0.62544864, 1), (0.62541425, 0), (0.6231697, 1), (0.620932, 0), (0.62012273, 0), (0.61504024, 0), (0.61033916, 0), (0.6077848, 0), (0.6044977, 0), (0.60234284, 0), (0.59011775, 0), (0.5887902, 0), (0.5371869, 0), (0.5176999, 1), (0.51280946, 0), (0.5050772, 0), (0.48819065, 1), (0.45408088, 0), (0.4422648, 0), (0.40197706, 0), (0.3851411, 0), (0.37252122, 0), (0.33767077, 0), (0.2980041, 0), (0.28378463, 1), (0.23197918, 0), (0.18308994, 0), (0.17775404, 0), (0.032519467, 0), (0.0, 0)]
0.3
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350286C168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
94/98 [===========================&gt;..] - ETA: 0s - loss: 0.6873 - auc: 0.5077WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FF1CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 7ms/step - loss: 0.6840 - auc: 0.5075 - val_loss: 0.5040 - val_auc: 0.8463
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5686 - auc: 0.5857 - val_loss: 0.4977 - val_auc: 0.7826
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5497 - auc: 0.6183 - val_loss: 0.4681 - val_auc: 0.6184
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5388 - auc: 0.6406 - val_loss: 0.4070 - val_auc: 0.6116
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5415 - auc: 0.6221 - val_loss: 0.3721 - val_auc: 0.7263
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5313 - auc: 0.6367 - val_loss: 0.4069 - val_auc: 0.6853
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6774 - val_loss: 0.4096 - val_auc: 0.6611
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5095 - auc: 0.6745 - val_loss: 0.4263 - val_auc: 0.6774
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6900 - val_loss: 0.4022 - val_auc: 0.6263
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5108 - auc: 0.6790 - val_loss: 0.3569 - val_auc: 0.7084
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6796 - val_loss: 0.3506 - val_auc: 0.6742
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6820 - val_loss: 0.3513 - val_auc: 0.7142
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5018 - auc: 0.6852 - val_loss: 0.3594 - val_auc: 0.6437
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5069 - auc: 0.6797 - val_loss: 0.3541 - val_auc: 0.7053
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.7121 - val_loss: 0.3244 - val_auc: 0.7174
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4991 - auc: 0.6864 - val_loss: 0.3282 - val_auc: 0.7058
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.7031 - val_loss: 0.3188 - val_auc: 0.6905
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6983 - val_loss: 0.3367 - val_auc: 0.7053
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.7370 - val_loss: 0.3218 - val_auc: 0.7032
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4943 - auc: 0.7111 - val_loss: 0.3477 - val_auc: 0.6721
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.97598326, 0), (0.8874249, 0), (0.8830679, 0), (0.8671376, 0), (0.8319636, 0), (0.8230113, 0), (0.8112915, 0), (0.8106625, 0), (0.809995, 0), (0.8047611, 0), (0.80097216, 0), (0.7956654, 0), (0.7831186, 0), (0.7823959, 0), (0.7678375, 0), (0.7630547, 0), (0.75847775, 1), (0.7456055, 0), (0.7400137, 0), (0.73573583, 0), (0.7349525, 0), (0.7280303, 1), (0.71617144, 0), (0.71315295, 0), (0.7114122, 0), (0.704982, 0), (0.6966493, 0), (0.6944412, 0), (0.6937185, 0), (0.6747688, 0), (0.65445787, 0), (0.6488197, 0), (0.6445882, 0), (0.62421745, 0), (0.6109612, 1), (0.5909399, 0), (0.5721905, 0), (0.5335043, 0), (0.51452106, 0), (0.48582223, 1), (0.47208193, 0), (0.43925947, 0), (0.42860618, 0), (0.2866397, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F99558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
96/98 [============================&gt;.] - ETA: 0s - loss: 0.5647 - auc: 0.4940WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350497E558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 9ms/step - loss: 0.5683 - auc: 0.4944 - val_loss: 0.3206 - val_auc: 0.6071
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5414 - auc: 0.5712 - val_loss: 0.3029 - val_auc: 0.6966
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5156 - auc: 0.6321 - val_loss: 0.3405 - val_auc: 0.5930
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5276 - auc: 0.6012 - val_loss: 0.2773 - val_auc: 0.5569
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5067 - auc: 0.6619 - val_loss: 0.2800 - val_auc: 0.6380
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6600 - val_loss: 0.3062 - val_auc: 0.5459
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5255 - auc: 0.6288 - val_loss: 0.3055 - val_auc: 0.5348
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.6726 - val_loss: 0.2997 - val_auc: 0.5842
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5064 - auc: 0.6794 - val_loss: 0.3115 - val_auc: 0.6001
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.6537 - val_loss: 0.2982 - val_auc: 0.6777
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6733 - val_loss: 0.3193 - val_auc: 0.6085
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5140 - auc: 0.6436 - val_loss: 0.3035 - val_auc: 0.7403
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6532 - val_loss: 0.3045 - val_auc: 0.6887
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6723 - val_loss: 0.3295 - val_auc: 0.5820
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6637 - val_loss: 0.2918 - val_auc: 0.6874
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6703 - val_loss: 0.3031 - val_auc: 0.5675
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6521 - val_loss: 0.2918 - val_auc: 0.6349
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6750 - val_loss: 0.2738 - val_auc: 0.7751
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6841 - val_loss: 0.2966 - val_auc: 0.5697
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6939 - val_loss: 0.3173 - val_auc: 0.5379
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023557C31708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.972015, 0), (0.95773345, 0), (0.94555616, 0), (0.8961227, 1), (0.8961227, 0), (0.8961227, 1), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 1), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8961227, 0), (0.8786887, 0), (0.85054415, 0), (0.81634825, 0), (0.7873, 0), (0.78302115, 0), (0.7128611, 1), (0.6334734, 0), (0.58915156, 0), (0.42853704, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504C01948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/98 [=========================&gt;....] - ETA: 0s - loss: 0.5377 - auc: 0.5344WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500A72168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5426 - auc: 0.5525 - val_loss: 0.3137 - val_auc: 0.5899
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5134 - auc: 0.6554 - val_loss: 0.2844 - val_auc: 0.7571
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5204 - auc: 0.6242 - val_loss: 0.2798 - val_auc: 0.7275
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5172 - auc: 0.6150 - val_loss: 0.2568 - val_auc: 0.6931
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6494 - val_loss: 0.2601 - val_auc: 0.7685
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5080 - auc: 0.6765 - val_loss: 0.2820 - val_auc: 0.6495
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5098 - auc: 0.6700 - val_loss: 0.2998 - val_auc: 0.5763
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5091 - auc: 0.6559 - val_loss: 0.2829 - val_auc: 0.5362
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6455 - val_loss: 0.2779 - val_auc: 0.7200
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6798 - val_loss: 0.2684 - val_auc: 0.7434
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6811 - val_loss: 0.2600 - val_auc: 0.7231
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6768 - val_loss: 0.2647 - val_auc: 0.7011
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6953 - val_loss: 0.2680 - val_auc: 0.6799
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5097 - auc: 0.6744 - val_loss: 0.2641 - val_auc: 0.5983
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6908 - val_loss: 0.2789 - val_auc: 0.5573
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.7183 - val_loss: 0.2640 - val_auc: 0.5833
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6897 - val_loss: 0.2793 - val_auc: 0.6296
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5141 - auc: 0.6605 - val_loss: 0.2783 - val_auc: 0.5754
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4852 - auc: 0.7054 - val_loss: 0.2852 - val_auc: 0.5988
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6804 - val_loss: 0.2805 - val_auc: 0.7050
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503BD94C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99092805, 0), (0.9255229, 0), (0.8762054, 0), (0.68045473, 0), (0.60879534, 0), (0.5972458, 0), (0.5924372, 0), (0.5871388, 0), (0.5842176, 0), (0.5821367, 0), (0.5667769, 0), (0.56676966, 0), (0.5616536, 0), (0.56158036, 0), (0.5584597, 1), (0.551229, 1), (0.54839617, 0), (0.5481521, 1), (0.5425064, 0), (0.542154, 0), (0.54001254, 1), (0.5378153, 0), (0.53707963, 0), (0.51475835, 0), (0.508747, 0), (0.5084823, 1), (0.50020736, 0), (0.49746025, 0), (0.48699188, 0), (0.4622225, 0), (0.4422649, 0), (0.43909153, 0), (0.43692407, 0), (0.43484554, 0), (0.41112614, 0), (0.35440668, 0), (0.35068932, 0), (0.24000703, 0), (0.23895404, 0), (0.2202371, 0), (0.1753133, 0), (0.13969497, 0), (0.121234916, 0), (0.109948285, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502FB08B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
93/98 [===========================&gt;..] - ETA: 0s - loss: 0.5418 - auc: 0.5588WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350301F678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 7ms/step - loss: 0.5358 - auc: 0.5644 - val_loss: 0.2598 - val_auc: 0.5517
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6267 - val_loss: 0.2273 - val_auc: 0.6030
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5145 - auc: 0.6657 - val_loss: 0.2237 - val_auc: 0.4586
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6490 - val_loss: 0.2455 - val_auc: 0.6284
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6713 - val_loss: 0.2617 - val_auc: 0.6280
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6626 - val_loss: 0.2434 - val_auc: 0.5764
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6689 - val_loss: 0.2568 - val_auc: 0.6288
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6658 - val_loss: 0.2817 - val_auc: 0.4422
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6464 - val_loss: 0.2645 - val_auc: 0.5695
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4811 - auc: 0.6950 - val_loss: 0.2547 - val_auc: 0.6698
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6608 - val_loss: 0.2391 - val_auc: 0.6888
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6803 - val_loss: 0.2457 - val_auc: 0.6641
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.7057 - val_loss: 0.2483 - val_auc: 0.6387
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5026 - auc: 0.6578 - val_loss: 0.2591 - val_auc: 0.6182
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6676 - val_loss: 0.2593 - val_auc: 0.6884
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6807 - val_loss: 0.2394 - val_auc: 0.6394
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6932 - val_loss: 0.2566 - val_auc: 0.5866
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.6892 - val_loss: 0.2562 - val_auc: 0.6094
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.7139 - val_loss: 0.2680 - val_auc: 0.5676
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5066 - auc: 0.6852 - val_loss: 0.2469 - val_auc: 0.6049
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.96963435, 0), (0.78338176, 0), (0.76376855, 0), (0.7331204, 0), (0.70528316, 0), (0.6858579, 1), (0.6711616, 0), (0.6593538, 0), (0.65876126, 0), (0.6497562, 0), (0.64828885, 0), (0.6350835, 0), (0.62465936, 0), (0.6145887, 0), (0.60804725, 0), (0.59970886, 0), (0.5974718, 1), (0.59685874, 1), (0.5914294, 1), (0.5805193, 1), (0.57610875, 0), (0.5743399, 0), (0.5738276, 0), (0.5686053, 0), (0.5678013, 1), (0.56772506, 0), (0.5657653, 0), (0.5637538, 1), (0.54827696, 0), (0.53644985, 1), (0.5235221, 0), (0.5227817, 0), (0.51025534, 0), (0.49087852, 0), (0.49059483, 0), (0.48559573, 0), (0.45716384, 0), (0.43772346, 0), (0.38717473, 1), (0.37347662, 0), (0.36189395, 0), (0.34156075, 0), (0.1837237, 0), (0.09595938, 0), (0.0, 0)]
0.1
0.1111111111111111
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502B6D828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5527 - auc: 0.5217WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023557F37F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.5762 - auc: 0.5100 - val_loss: 0.4022 - val_auc: 0.6362
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5257 - auc: 0.5923 - val_loss: 0.3673 - val_auc: 0.5996
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5215 - auc: 0.6233 - val_loss: 0.3079 - val_auc: 0.7108
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5037 - auc: 0.6333 - val_loss: 0.3185 - val_auc: 0.5472
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4986 - auc: 0.6412 - val_loss: 0.3265 - val_auc: 0.6089
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6609 - val_loss: 0.3112 - val_auc: 0.6618
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6883 - val_loss: 0.3097 - val_auc: 0.6226
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6800 - val_loss: 0.3116 - val_auc: 0.4982
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4873 - auc: 0.6725 - val_loss: 0.3191 - val_auc: 0.6265
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6715 - val_loss: 0.2899 - val_auc: 0.6966
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4822 - auc: 0.6941 - val_loss: 0.3115 - val_auc: 0.6354
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4638 - auc: 0.7140 - val_loss: 0.3313 - val_auc: 0.6781
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.7113 - val_loss: 0.2806 - val_auc: 0.6539
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6811 - val_loss: 0.3019 - val_auc: 0.6583
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.7506 - val_loss: 0.2850 - val_auc: 0.6834
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.7038 - val_loss: 0.2932 - val_auc: 0.7324
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4725 - auc: 0.7108 - val_loss: 0.2880 - val_auc: 0.7033
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4727 - auc: 0.7151 - val_loss: 0.2779 - val_auc: 0.7443
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4670 - auc: 0.7241 - val_loss: 0.3042 - val_auc: 0.7099
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4667 - auc: 0.7262 - val_loss: 0.3234 - val_auc: 0.6468
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FF19D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.8123001, 0), (0.760135, 0), (0.6982683, 0), (0.6778443, 0), (0.6299527, 0), (0.61445296, 0), (0.6099766, 0), (0.604419, 0), (0.6016607, 0), (0.5843127, 0), (0.5795519, 0), (0.5691456, 1), (0.56488276, 0), (0.5577851, 1), (0.55651873, 1), (0.5564724, 0), (0.5548983, 1), (0.5540255, 0), (0.5525906, 1), (0.5524416, 0), (0.5516886, 0), (0.5515, 1), (0.5513935, 0), (0.54273355, 0), (0.5427226, 1), (0.5357203, 0), (0.5317584, 1), (0.5183138, 0), (0.51660454, 1), (0.5127572, 0), (0.50951135, 0), (0.49958572, 0), (0.47887918, 0), (0.45659578, 0), (0.4393509, 0), (0.42264423, 0), (0.40243474, 0), (0.40183058, 0), (0.38999915, 1), (0.27291614, 0), (0.2526218, 0), (0.22047356, 1), (0.1921357, 1), (0.15326108, 0), (0.0, 0)]
0.1
0.07692307692307693
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235594A7318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/98 [==========================&gt;...] - ETA: 0s - loss: 0.5858 - auc: 0.4974WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502FB0DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5763 - auc: 0.5012 - val_loss: 0.4172 - val_auc: 0.5059
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5334 - auc: 0.6052 - val_loss: 0.3612 - val_auc: 0.5235
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5164 - auc: 0.6347 - val_loss: 0.3593 - val_auc: 0.3508
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5249 - auc: 0.6210 - val_loss: 0.3768 - val_auc: 0.4924
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5136 - auc: 0.6217 - val_loss: 0.3416 - val_auc: 0.3162
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4862 - auc: 0.7136 - val_loss: 0.3339 - val_auc: 0.3589
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6838 - val_loss: 0.3297 - val_auc: 0.3838
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5189 - auc: 0.6240 - val_loss: 0.3137 - val_auc: 0.3711
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6825 - val_loss: 0.3304 - val_auc: 0.4386
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6939 - val_loss: 0.3066 - val_auc: 0.4427
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6810 - val_loss: 0.3117 - val_auc: 0.3851
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.7095 - val_loss: 0.3062 - val_auc: 0.4559
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5091 - auc: 0.6809 - val_loss: 0.3165 - val_auc: 0.4851
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5091 - auc: 0.6748 - val_loss: 0.2962 - val_auc: 0.4649
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.6974 - val_loss: 0.3106 - val_auc: 0.4895
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6642 - val_loss: 0.3079 - val_auc: 0.4814
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6857 - val_loss: 0.2960 - val_auc: 0.4122
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6866 - val_loss: 0.3174 - val_auc: 0.4954
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4940 - auc: 0.6847 - val_loss: 0.3191 - val_auc: 0.4857
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5062 - auc: 0.6805 - val_loss: 0.3088 - val_auc: 0.4684
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502DEA708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9355377, 0), (0.9158078, 0), (0.8762588, 0), (0.8698361, 0), (0.84108794, 0), (0.82432, 0), (0.8088273, 0), (0.7986111, 0), (0.7978317, 0), (0.79592013, 0), (0.79536235, 0), (0.79536235, 1), (0.79536235, 0), (0.79536235, 0), (0.79489225, 0), (0.7944259, 0), (0.79140365, 0), (0.79126996, 0), (0.78920525, 0), (0.78478575, 0), (0.78418887, 0), (0.78243804, 0), (0.78027445, 1), (0.7779529, 0), (0.7746127, 0), (0.7745442, 0), (0.7718568, 0), (0.77060145, 0), (0.76438123, 0), (0.76021606, 0), (0.7463041, 0), (0.7263619, 0), (0.7009165, 0), (0.6880898, 0), (0.67336583, 0), (0.65548354, 0), (0.6196584, 0), (0.57692254, 0), (0.5615705, 0), (0.5256295, 0), (0.48432353, 0), (0.4768612, 0), (0.31835502, 0), (0.16002041, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502F0C0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5609 - auc: 0.5208 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350301F048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5553 - auc: 0.5210 - val_loss: 0.2817 - val_auc: 0.6237
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5297 - auc: 0.5694 - val_loss: 0.3121 - val_auc: 0.6789
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5119 - auc: 0.6170 - val_loss: 0.2652 - val_auc: 0.5879
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5228 - auc: 0.5818 - val_loss: 0.2841 - val_auc: 0.6595
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5206 - auc: 0.5707 - val_loss: 0.2457 - val_auc: 0.6868
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6154 - val_loss: 0.2393 - val_auc: 0.7153
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5184 - auc: 0.6092 - val_loss: 0.2334 - val_auc: 0.7542
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6648 - val_loss: 0.2509 - val_auc: 0.7563
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5021 - auc: 0.6509 - val_loss: 0.2698 - val_auc: 0.7358
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4996 - auc: 0.6803 - val_loss: 0.2718 - val_auc: 0.6695
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6873 - val_loss: 0.2572 - val_auc: 0.6542
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6770 - val_loss: 0.2521 - val_auc: 0.6874
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4994 - auc: 0.6746 - val_loss: 0.2583 - val_auc: 0.7011
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5015 - auc: 0.6703 - val_loss: 0.2522 - val_auc: 0.6474
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6487 - val_loss: 0.2634 - val_auc: 0.6432
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6969 - val_loss: 0.2561 - val_auc: 0.6521
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5053 - auc: 0.6756 - val_loss: 0.2738 - val_auc: 0.5889
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4854 - auc: 0.6957 - val_loss: 0.2715 - val_auc: 0.6184
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6902 - val_loss: 0.2636 - val_auc: 0.6089
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6957 - val_loss: 0.2669 - val_auc: 0.5647
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504C01A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 1), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.91062474, 0), (0.7872977, 0), (0.78210413, 0), (0.73653567, 0), (0.6875311, 0), (0.6435186, 0), (0.44344974, 0), (0.412651, 0), (0.4088834, 0), (0.2506651, 1), (0.0, 0)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502490708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.6474 - auc: 0.5226 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235594A7948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.6407 - auc: 0.5359 - val_loss: 0.6754 - val_auc: 0.5689
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5650 - auc: 0.6059 - val_loss: 0.5826 - val_auc: 0.5207
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5188 - auc: 0.6573 - val_loss: 0.5940 - val_auc: 0.6444
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6874 - val_loss: 0.4984 - val_auc: 0.6197
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6578 - val_loss: 0.4793 - val_auc: 0.5498
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5172 - auc: 0.6538 - val_loss: 0.4363 - val_auc: 0.5625
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6818 - val_loss: 0.4496 - val_auc: 0.6176
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6735 - val_loss: 0.4442 - val_auc: 0.5378
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6919 - val_loss: 0.3992 - val_auc: 0.5919
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6724 - val_loss: 0.3749 - val_auc: 0.5842
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4645 - auc: 0.7188 - val_loss: 0.3716 - val_auc: 0.6233
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4744 - auc: 0.7232 - val_loss: 0.3729 - val_auc: 0.6120
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.7087 - val_loss: 0.3798 - val_auc: 0.5749
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4681 - auc: 0.7302 - val_loss: 0.3511 - val_auc: 0.5334
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4892 - auc: 0.6890 - val_loss: 0.3508 - val_auc: 0.5531
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.6961 - val_loss: 0.3553 - val_auc: 0.5525
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4795 - auc: 0.7096 - val_loss: 0.3506 - val_auc: 0.5739
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4777 - auc: 0.7150 - val_loss: 0.3547 - val_auc: 0.5558
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.7118 - val_loss: 0.3524 - val_auc: 0.5528
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.6993 - val_loss: 0.3583 - val_auc: 0.5411
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235061F8CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.98086375, 0), (0.6208909, 0), (0.62009966, 0), (0.6159043, 0), (0.60838336, 0), (0.6075508, 0), (0.6052938, 0), (0.6040756, 0), (0.6038333, 0), (0.6028622, 0), (0.60198706, 0), (0.6019276, 0), (0.6001577, 0), (0.5998321, 1), (0.598245, 0), (0.5896895, 1), (0.58933014, 1), (0.58895767, 1), (0.58802766, 1), (0.5858213, 1), (0.5842111, 0), (0.582743, 0), (0.5683777, 0), (0.5503904, 0), (0.5472397, 0), (0.5347971, 1), (0.5213233, 0), (0.5125177, 0), (0.50481904, 0), (0.484752, 1), (0.45413783, 0), (0.4465454, 0), (0.3911309, 0), (0.37880117, 1), (0.36990222, 0), (0.36738548, 1), (0.32319406, 0), (0.29558098, 0), (0.24471964, 0), (0.1977158, 0), (0.19764696, 0), (0.07682482, 0), (0.06308142, 0), (0.031575076, 1), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350301F558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - ETA: 0s - loss: 0.5912 - auc: 0.5977WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0CD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5912 - auc: 0.5977 - val_loss: 0.4642 - val_auc: 0.6316
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5689 - auc: 0.5978 - val_loss: 0.4406 - val_auc: 0.4200
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5411 - auc: 0.6199 - val_loss: 0.4832 - val_auc: 0.6295
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5453 - auc: 0.5942 - val_loss: 0.4205 - val_auc: 0.5716
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5316 - auc: 0.6328 - val_loss: 0.3782 - val_auc: 0.5432
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5296 - auc: 0.6186 - val_loss: 0.3899 - val_auc: 0.5900
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5189 - auc: 0.6612 - val_loss: 0.3333 - val_auc: 0.5568
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6296 - val_loss: 0.3383 - val_auc: 0.6005
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6780 - val_loss: 0.3362 - val_auc: 0.6779
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5031 - auc: 0.6872 - val_loss: 0.3656 - val_auc: 0.6389
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6969 - val_loss: 0.3415 - val_auc: 0.6111
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5015 - auc: 0.6972 - val_loss: 0.3157 - val_auc: 0.6274
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4906 - auc: 0.7041 - val_loss: 0.3067 - val_auc: 0.6537
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.7028 - val_loss: 0.3127 - val_auc: 0.6432
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.7044 - val_loss: 0.3402 - val_auc: 0.5968
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6986 - val_loss: 0.3310 - val_auc: 0.6300
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.7133 - val_loss: 0.3083 - val_auc: 0.5732
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5068 - auc: 0.6806 - val_loss: 0.3080 - val_auc: 0.5853
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.7007 - val_loss: 0.3167 - val_auc: 0.5137
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.7003 - val_loss: 0.2908 - val_auc: 0.5758
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503BD9708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.89906114, 1), (0.8778736, 0), (0.80616045, 0), (0.74803615, 1), (0.7477748, 0), (0.7388486, 0), (0.72984684, 0), (0.7238526, 0), (0.716847, 0), (0.7156557, 0), (0.71216416, 0), (0.71183944, 0), (0.71026045, 0), (0.70472205, 0), (0.6967847, 0), (0.6942036, 0), (0.687263, 0), (0.6860806, 0), (0.6852797, 0), (0.6839959, 0), (0.6821403, 0), (0.6775167, 1), (0.6734758, 0), (0.67333674, 0), (0.6702747, 0), (0.66993934, 0), (0.6687124, 0), (0.6666848, 0), (0.66616726, 0), (0.66598207, 0), (0.66341704, 0), (0.6627639, 0), (0.6597249, 0), (0.65821266, 0), (0.6383324, 0), (0.5910197, 0), (0.55041325, 0), (0.5220232, 0), (0.46113318, 0), (0.43960053, 0), (0.39354473, 0), (0.3842741, 0), (0.08979048, 0), (0.059209213, 0), (0.0, 1)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350812F048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/98 [=========================&gt;....] - ETA: 0s - loss: 0.6074 - auc: 0.5699WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502729708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 8ms/step - loss: 0.6151 - auc: 0.5521 - val_loss: 0.5092 - val_auc: 0.4165
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5737 - auc: 0.5641 - val_loss: 0.4488 - val_auc: 0.6014
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5503 - auc: 0.6044 - val_loss: 0.4249 - val_auc: 0.5905
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5301 - auc: 0.6313 - val_loss: 0.4300 - val_auc: 0.3762
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5183 - auc: 0.6446 - val_loss: 0.3494 - val_auc: 0.5797
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5254 - auc: 0.6170 - val_loss: 0.3530 - val_auc: 0.4965
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5120 - auc: 0.6541 - val_loss: 0.3362 - val_auc: 0.5962
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5206 - auc: 0.6337 - val_loss: 0.3491 - val_auc: 0.3759
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6683 - val_loss: 0.3252 - val_auc: 0.5043
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6879 - val_loss: 0.3451 - val_auc: 0.3984
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4832 - auc: 0.7183 - val_loss: 0.3137 - val_auc: 0.4154
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6961 - val_loss: 0.3213 - val_auc: 0.5438
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6786 - val_loss: 0.3030 - val_auc: 0.5216
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5001 - auc: 0.6800 - val_loss: 0.3145 - val_auc: 0.4495
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6853 - val_loss: 0.3052 - val_auc: 0.4424
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5022 - auc: 0.6783 - val_loss: 0.3201 - val_auc: 0.4992
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.7103 - val_loss: 0.2967 - val_auc: 0.4816
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4930 - auc: 0.6957 - val_loss: 0.3095 - val_auc: 0.4557
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.7196 - val_loss: 0.3005 - val_auc: 0.4462
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6968 - val_loss: 0.3100 - val_auc: 0.4514
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504A6F828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.92298836, 0), (0.8622154, 0), (0.85043424, 0), (0.8388585, 0), (0.8387225, 0), (0.833272, 0), (0.81654376, 0), (0.8052918, 0), (0.8050455, 0), (0.80490774, 1), (0.8041249, 1), (0.80161774, 0), (0.801186, 0), (0.8003013, 0), (0.8002709, 0), (0.7999481, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7992382, 0), (0.7968737, 0), (0.7964753, 0), (0.7913737, 0), (0.7877098, 0), (0.7798822, 0), (0.772029, 0), (0.7700022, 0), (0.76177895, 0), (0.7430267, 0), (0.7418489, 0), (0.7161579, 0), (0.7072968, 0), (0.69594604, 0), (0.6663811, 0), (0.65987873, 0), (0.58235264, 0), (0.45254365, 0), (0.44828188, 0), (0.42678982, 0), (0.41821948, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503FAE0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/98 [=========================&gt;....] - ETA: 0s - loss: 0.5399 - auc: 0.5276WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235036DBDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5290 - auc: 0.5311 - val_loss: 0.3015 - val_auc: 0.4263
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5214 - auc: 0.5670 - val_loss: 0.3102 - val_auc: 0.6801
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6055 - val_loss: 0.3425 - val_auc: 0.4715
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5140 - auc: 0.5683 - val_loss: 0.3652 - val_auc: 0.5748
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5088 - auc: 0.5954 - val_loss: 0.3220 - val_auc: 0.7318
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6306 - val_loss: 0.3370 - val_auc: 0.4039
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6216 - val_loss: 0.3356 - val_auc: 0.5464
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4971 - auc: 0.6505 - val_loss: 0.3035 - val_auc: 0.5289
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6318 - val_loss: 0.3016 - val_auc: 0.5251
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5126 - auc: 0.6196 - val_loss: 0.3040 - val_auc: 0.5764
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.6670 - val_loss: 0.2919 - val_auc: 0.6075
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6652 - val_loss: 0.2942 - val_auc: 0.5684
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6464 - val_loss: 0.2946 - val_auc: 0.5456
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4879 - auc: 0.6560 - val_loss: 0.2899 - val_auc: 0.5464
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6454 - val_loss: 0.2889 - val_auc: 0.5426
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.6673 - val_loss: 0.2982 - val_auc: 0.5562
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4894 - auc: 0.6649 - val_loss: 0.3039 - val_auc: 0.4844
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4889 - auc: 0.6500 - val_loss: 0.2981 - val_auc: 0.5483
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.6856 - val_loss: 0.2872 - val_auc: 0.6147
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.6576 - val_loss: 0.3156 - val_auc: 0.5483
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (1.0, 0), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 0), (1.0, 1), (1.0, 0), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 1), (1.0, 0), (1.0, 0), (0.9871424, 1), (0.9843376, 0), (0.9840776, 1), (0.95833915, 0), (0.939518, 0), (0.9344559, 0), (0.9136333, 0), (0.91182065, 0), (0.7254417, 1), (0.69093734, 0), (0.6850584, 0), (0.64585245, 0), (0.6281342, 0), (0.5826955, 0), (0.0, 0)]
0.6
0.375
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350286CCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5457 - auc: 0.5386WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023CFD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5382 - auc: 0.5422 - val_loss: 0.2803 - val_auc: 0.6068
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5342 - auc: 0.6127 - val_loss: 0.2984 - val_auc: 0.5089
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6416 - val_loss: 0.3068 - val_auc: 0.4729
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5215 - auc: 0.6351 - val_loss: 0.3003 - val_auc: 0.5018
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5136 - auc: 0.6322 - val_loss: 0.3001 - val_auc: 0.4508
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5209 - auc: 0.6417 - val_loss: 0.2982 - val_auc: 0.4176
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5049 - auc: 0.6646 - val_loss: 0.2869 - val_auc: 0.4563
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5161 - auc: 0.6115 - val_loss: 0.3228 - val_auc: 0.4770
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5076 - auc: 0.6531 - val_loss: 0.3048 - val_auc: 0.5034
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6690 - val_loss: 0.3057 - val_auc: 0.5180
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5225 - auc: 0.6454 - val_loss: 0.3237 - val_auc: 0.5339
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5159 - auc: 0.6770 - val_loss: 0.2916 - val_auc: 0.5266
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6767 - val_loss: 0.2976 - val_auc: 0.5371
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5077 - auc: 0.6513 - val_loss: 0.3094 - val_auc: 0.5455
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4951 - auc: 0.6651 - val_loss: 0.2991 - val_auc: 0.5483
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6953 - val_loss: 0.2890 - val_auc: 0.5255
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6767 - val_loss: 0.2875 - val_auc: 0.4991
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6748 - val_loss: 0.3033 - val_auc: 0.5039
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6851 - val_loss: 0.2907 - val_auc: 0.5093
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6868 - val_loss: 0.2975 - val_auc: 0.5032
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502170C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8897273, 0), (0.883993, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829822, 0), (0.8829647, 0), (0.87974703, 0), (0.8796828, 0), (0.8777564, 0), (0.8774779, 0), (0.86800337, 0), (0.8451339, 0), (0.80332077, 0), (0.74858737, 0), (0.63263905, 0), (0.47245395, 0), (0.3526228, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023507651288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/98 [=========================&gt;....] - ETA: 0s - loss: 0.5428 - auc: 0.5321WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235594A75E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.5370 - auc: 0.5397 - val_loss: 0.2828 - val_auc: 0.6759
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.5854 - val_loss: 0.2973 - val_auc: 0.6989
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5054 - auc: 0.6156 - val_loss: 0.3107 - val_auc: 0.5463
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6518 - val_loss: 0.2788 - val_auc: 0.6459
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4962 - auc: 0.6581 - val_loss: 0.2886 - val_auc: 0.5123
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4827 - auc: 0.6822 - val_loss: 0.2773 - val_auc: 0.4978
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4826 - auc: 0.6911 - val_loss: 0.3078 - val_auc: 0.5273
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.7133 - val_loss: 0.3062 - val_auc: 0.4894
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7175 - val_loss: 0.3198 - val_auc: 0.5366
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4808 - auc: 0.7064 - val_loss: 0.2973 - val_auc: 0.5534
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4924 - auc: 0.6938 - val_loss: 0.3157 - val_auc: 0.5269
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7247 - val_loss: 0.2948 - val_auc: 0.5419
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.7111 - val_loss: 0.3087 - val_auc: 0.5110
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.6949 - val_loss: 0.3065 - val_auc: 0.5000
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4710 - auc: 0.7205 - val_loss: 0.2835 - val_auc: 0.5026
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4711 - auc: 0.7460 - val_loss: 0.3184 - val_auc: 0.5141
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4739 - auc: 0.7104 - val_loss: 0.2992 - val_auc: 0.4956
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4596 - auc: 0.7306 - val_loss: 0.3056 - val_auc: 0.5137
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4675 - auc: 0.7182 - val_loss: 0.2747 - val_auc: 0.5939
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4720 - auc: 0.7251 - val_loss: 0.2848 - val_auc: 0.5304
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350812F1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.83485746, 1), (0.7555484, 0), (0.7411754, 0), (0.6655562, 1), (0.6632677, 1), (0.64554596, 0), (0.6447308, 0), (0.64087856, 0), (0.63793325, 0), (0.6285839, 0), (0.6269084, 0), (0.62625116, 0), (0.6252445, 0), (0.61857307, 0), (0.6160206, 1), (0.61190385, 1), (0.61107147, 0), (0.60162157, 0), (0.59897304, 0), (0.59461814, 0), (0.58665675, 0), (0.58079267, 1), (0.5425693, 1), (0.5411055, 0), (0.5311211, 1), (0.52964145, 0), (0.52409595, 0), (0.4997509, 0), (0.4991258, 0), (0.46416873, 1), (0.4531865, 0), (0.4354683, 0), (0.4326158, 0), (0.42234653, 0), (0.40298113, 0), (0.3336017, 0), (0.29032746, 1), (0.2822602, 0), (0.25377578, 0), (0.2487842, 0), (0.23649178, 1), (0.20222792, 0), (0.15830943, 0), (0.111900076, 1), (0.0, 0)]
0.3
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502170708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/98 [=========================&gt;....] - ETA: 0s - loss: 0.5094 - auc: 0.4899WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350497E828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5046 - auc: 0.4930 - val_loss: 0.2870 - val_auc: 0.6588
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.5282 - val_loss: 0.2691 - val_auc: 0.5597
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.5420 - val_loss: 0.2526 - val_auc: 0.5965
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.5806 - val_loss: 0.2583 - val_auc: 0.6793
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.5742 - val_loss: 0.2449 - val_auc: 0.7025
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4718 - auc: 0.6303 - val_loss: 0.2285 - val_auc: 0.7675
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4665 - auc: 0.6383 - val_loss: 0.2425 - val_auc: 0.7055
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4656 - auc: 0.6424 - val_loss: 0.2258 - val_auc: 0.7515
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.6209 - val_loss: 0.2605 - val_auc: 0.6463
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4696 - auc: 0.6064 - val_loss: 0.2424 - val_auc: 0.6934
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4595 - auc: 0.6705 - val_loss: 0.2429 - val_auc: 0.6596
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4686 - auc: 0.6201 - val_loss: 0.2431 - val_auc: 0.6159
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4509 - auc: 0.6872 - val_loss: 0.2466 - val_auc: 0.6174
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4622 - auc: 0.6556 - val_loss: 0.2304 - val_auc: 0.6854
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4601 - auc: 0.6548 - val_loss: 0.2535 - val_auc: 0.6930
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4436 - auc: 0.7064 - val_loss: 0.2245 - val_auc: 0.7698
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4644 - auc: 0.6731 - val_loss: 0.2280 - val_auc: 0.7447
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4592 - auc: 0.6627 - val_loss: 0.2313 - val_auc: 0.7686
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4519 - auc: 0.6883 - val_loss: 0.2415 - val_auc: 0.7587
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4544 - auc: 0.6914 - val_loss: 0.2331 - val_auc: 0.7071
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8594128, 1), (0.8504132, 1), (0.8504132, 1), (0.8500995, 0), (0.84992343, 1), (0.8419082, 0), (0.8362346, 1), (0.83574474, 1), (0.83382064, 1), (0.8262863, 1), (0.82124144, 0), (0.81986487, 0), (0.8139365, 0), (0.8122464, 1), (0.8085359, 0), (0.8044977, 1), (0.7951528, 0), (0.7931988, 1), (0.7736501, 1), (0.7481619, 1), (0.7371684, 1), (0.7286656, 0), (0.72784126, 0), (0.7095653, 1), (0.6957184, 1), (0.65054774, 1), (0.64912117, 1), (0.6386161, 1), (0.6283933, 1), (0.4938656, 0), (0.4899693, 1), (0.44256586, 0), (0.43964502, 1), (0.43102923, 0), (0.36918506, 1), (0.3180491, 1), (0.315382, 1), (0.31058612, 1), (0.28984258, 1), (0.2542415, 1), (0.22490703, 1), (0.21463776, 1), (0.01902331, 1), (0.008226004, 0), (0.0, 1)]
0.7
0.21875
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503FF1AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/98 [=========================&gt;....] - ETA: 0s - loss: 0.5892 - auc: 0.5263 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235580A00D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5870 - auc: 0.5276 - val_loss: 0.3471 - val_auc: 0.5075
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5433 - auc: 0.5954 - val_loss: 0.3083 - val_auc: 0.4899
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5270 - auc: 0.6156 - val_loss: 0.3345 - val_auc: 0.4466
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.6485 - val_loss: 0.3671 - val_auc: 0.6715
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5197 - auc: 0.6061 - val_loss: 0.3482 - val_auc: 0.6235
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6598 - val_loss: 0.3286 - val_auc: 0.6129
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6870 - val_loss: 0.3317 - val_auc: 0.5459
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6639 - val_loss: 0.3049 - val_auc: 0.4793
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6864 - val_loss: 0.3238 - val_auc: 0.6609
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6665 - val_loss: 0.2968 - val_auc: 0.5860
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.7074 - val_loss: 0.2947 - val_auc: 0.7196
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6609 - val_loss: 0.3442 - val_auc: 0.5639
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.6928 - val_loss: 0.2819 - val_auc: 0.6102
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4833 - auc: 0.6935 - val_loss: 0.2894 - val_auc: 0.5128
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4926 - auc: 0.6863 - val_loss: 0.3006 - val_auc: 0.6111
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.7029 - val_loss: 0.2874 - val_auc: 0.6168
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4683 - auc: 0.7222 - val_loss: 0.2686 - val_auc: 0.6204
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6649 - val_loss: 0.3013 - val_auc: 0.6221
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4815 - auc: 0.6952 - val_loss: 0.2798 - val_auc: 0.6570
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4672 - auc: 0.7328 - val_loss: 0.2795 - val_auc: 0.6777
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023558298798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.59899515, 1), (0.5986716, 0), (0.5569013, 0), (0.5558376, 0), (0.5558376, 0), (0.5558376, 0), (0.55539393, 0), (0.55476147, 0), (0.5530029, 0), (0.5497675, 0), (0.5487836, 0), (0.5456812, 0), (0.5448347, 0), (0.5423364, 1), (0.5418733, 0), (0.537037, 0), (0.5364509, 1), (0.5330705, 1), (0.5105358, 0), (0.50318295, 1), (0.50124145, 1), (0.49137563, 0), (0.48489812, 0), (0.47520366, 1), (0.47243464, 0), (0.46548918, 0), (0.46453172, 0), (0.45518738, 0), (0.44067863, 0), (0.43104464, 0), (0.4228274, 1), (0.3806038, 0), (0.36358717, 0), (0.35379696, 0), (0.31541538, 0), (0.31527522, 0), (0.29458836, 1), (0.26617932, 1), (0.24977759, 0), (0.23125085, 0), (0.12552121, 0), (0.12145416, 0), (0.11685247, 0), (0.026993362, 1), (0.0, 0)]
0.1
0.09090909090909091
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502EF0E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/98 [==========================&gt;...] - ETA: 0s - loss: 0.5751 - auc: 0.5062WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504497B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 6ms/step - loss: 0.5681 - auc: 0.5132 - val_loss: 0.2624 - val_auc: 0.5684
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5381 - auc: 0.5730 - val_loss: 0.3106 - val_auc: 0.6032
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5230 - auc: 0.5955 - val_loss: 0.3035 - val_auc: 0.6174
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5300 - auc: 0.5902 - val_loss: 0.3208 - val_auc: 0.5579
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6852 - val_loss: 0.3020 - val_auc: 0.5900
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6706 - val_loss: 0.3171 - val_auc: 0.7095
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5033 - auc: 0.6768 - val_loss: 0.2771 - val_auc: 0.7821
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5080 - auc: 0.6937 - val_loss: 0.2873 - val_auc: 0.8268
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6833 - val_loss: 0.3193 - val_auc: 0.6826
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5065 - auc: 0.6766 - val_loss: 0.2917 - val_auc: 0.7189
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6990 - val_loss: 0.3129 - val_auc: 0.7700
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.7017 - val_loss: 0.2625 - val_auc: 0.6568
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5202 - auc: 0.6530 - val_loss: 0.2832 - val_auc: 0.7126
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6722 - val_loss: 0.2915 - val_auc: 0.6563
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.7025 - val_loss: 0.2859 - val_auc: 0.7279
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.7027 - val_loss: 0.3058 - val_auc: 0.7016
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4964 - auc: 0.6926 - val_loss: 0.2709 - val_auc: 0.6826
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4836 - auc: 0.6949 - val_loss: 0.2971 - val_auc: 0.6632
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.7311 - val_loss: 0.2884 - val_auc: 0.6184
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.7147 - val_loss: 0.2835 - val_auc: 0.6063
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503094DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9322721, 0), (0.86019754, 0), (0.8123332, 0), (0.7660434, 1), (0.72607976, 0), (0.7111105, 0), (0.6543852, 0), (0.6463849, 0), (0.63644713, 0), (0.6329902, 0), (0.6294752, 0), (0.6154977, 0), (0.6154928, 0), (0.60100806, 0), (0.59421265, 0), (0.5937385, 0), (0.58933693, 0), (0.5734668, 0), (0.56787074, 0), (0.5639358, 0), (0.5486145, 0), (0.54237926, 0), (0.5237777, 0), (0.5215064, 0), (0.51902455, 0), (0.5081667, 0), (0.50511336, 1), (0.4936596, 0), (0.4845544, 0), (0.44924307, 0), (0.42849275, 0), (0.40672708, 0), (0.39408916, 0), (0.37981594, 1), (0.33732104, 0), (0.3337041, 0), (0.33215496, 0), (0.3117943, 0), (0.3068802, 0), (0.26078472, 1), (0.23931621, 1), (0.20831932, 0), (0.17932507, 0), (0.07274422, 0), (0.0, 0)]
0.1
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502F0C8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/98 [=========================&gt;....] - ETA: 0s - loss: 0.5528 - auc: 0.5464WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235061F8678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 1s 6ms/step - loss: 0.5434 - auc: 0.5496 - val_loss: 0.2338 - val_auc: 0.6387
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5411 - auc: 0.5668 - val_loss: 0.2562 - val_auc: 0.6554
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.6244 - val_loss: 0.2502 - val_auc: 0.5762
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5046 - auc: 0.6366 - val_loss: 0.2770 - val_auc: 0.4479
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5123 - auc: 0.6423 - val_loss: 0.2666 - val_auc: 0.6437
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5263 - auc: 0.6102 - val_loss: 0.2642 - val_auc: 0.6751
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5260 - auc: 0.6244 - val_loss: 0.2672 - val_auc: 0.5551
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6347 - val_loss: 0.2695 - val_auc: 0.5458
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6910 - val_loss: 0.2635 - val_auc: 0.5167
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4982 - auc: 0.6944 - val_loss: 0.2748 - val_auc: 0.4983
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6718 - val_loss: 0.2597 - val_auc: 0.5625
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6834 - val_loss: 0.2601 - val_auc: 0.4806
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4978 - auc: 0.7008 - val_loss: 0.2560 - val_auc: 0.4024
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6546 - val_loss: 0.2721 - val_auc: 0.5381
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5028 - auc: 0.6715 - val_loss: 0.2713 - val_auc: 0.5428
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4986 - auc: 0.6828 - val_loss: 0.2702 - val_auc: 0.5154
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6704 - val_loss: 0.2698 - val_auc: 0.4669
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.7237 - val_loss: 0.2899 - val_auc: 0.4215
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4858 - auc: 0.7015 - val_loss: 0.2789 - val_auc: 0.5926
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5071 - auc: 0.6626 - val_loss: 0.2832 - val_auc: 0.5328
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502258558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.88061243, 0), (0.8637819, 0), (0.7041134, 0), (0.6887107, 0), (0.650828, 1), (0.6301167, 0), (0.61961865, 0), (0.5787301, 0), (0.5776649, 0), (0.5764662, 0), (0.5763497, 0), (0.5742787, 0), (0.57278085, 0), (0.56783944, 0), (0.56756806, 0), (0.5667697, 1), (0.5643987, 0), (0.56043154, 0), (0.558079, 0), (0.55620337, 0), (0.55611485, 0), (0.55584025, 0), (0.55505264, 0), (0.5535405, 0), (0.5512708, 1), (0.5512708, 0), (0.5512708, 0), (0.5512708, 0), (0.5512708, 0), (0.5472811, 0), (0.53992546, 0), (0.5338948, 0), (0.5269477, 0), (0.5250351, 0), (0.51957965, 0), (0.51603746, 0), (0.50222856, 0), (0.4849772, 0), (0.46972618, 0), (0.4524131, 0), (0.44662398, 0), (0.39894465, 0), (0.2958016, 0), (0.1852525, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023CF0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
85/98 [=========================&gt;....] - ETA: 0s - loss: 0.6502 - auc: 0.5207WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0C318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/98 [==============================] - 2s 8ms/step - loss: 0.6419 - auc: 0.5204 - val_loss: 0.4721 - val_auc: 0.5911
Epoch 2/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5682 - auc: 0.6052 - val_loss: 0.4520 - val_auc: 0.6358
Epoch 3/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5420 - auc: 0.6191 - val_loss: 0.4165 - val_auc: 0.6037
Epoch 4/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5308 - auc: 0.6369 - val_loss: 0.3341 - val_auc: 0.6174
Epoch 5/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5168 - auc: 0.6516 - val_loss: 0.3475 - val_auc: 0.6153
Epoch 6/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5043 - auc: 0.6819 - val_loss: 0.3321 - val_auc: 0.6832
Epoch 7/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5101 - auc: 0.6684 - val_loss: 0.3261 - val_auc: 0.6468
Epoch 8/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5097 - auc: 0.6578 - val_loss: 0.3171 - val_auc: 0.6421
Epoch 9/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4971 - auc: 0.6988 - val_loss: 0.3183 - val_auc: 0.6500
Epoch 10/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4798 - auc: 0.7337 - val_loss: 0.2839 - val_auc: 0.6432
Epoch 11/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4826 - auc: 0.7166 - val_loss: 0.3041 - val_auc: 0.5979
Epoch 12/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5171 - auc: 0.6542 - val_loss: 0.3076 - val_auc: 0.6605
Epoch 13/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5171 - auc: 0.6603 - val_loss: 0.3333 - val_auc: 0.6568
Epoch 14/20
98/98 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6840 - val_loss: 0.3135 - val_auc: 0.6768
Epoch 15/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6958 - val_loss: 0.2979 - val_auc: 0.6663
Epoch 16/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6826 - val_loss: 0.3104 - val_auc: 0.6253
Epoch 17/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4989 - auc: 0.6915 - val_loss: 0.3074 - val_auc: 0.6032
Epoch 18/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.7042 - val_loss: 0.3016 - val_auc: 0.6168
Epoch 19/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4919 - auc: 0.7139 - val_loss: 0.3169 - val_auc: 0.5842
Epoch 20/20
98/98 [==============================] - 0s 4ms/step - loss: 0.4939 - auc: 0.6898 - val_loss: 0.3259 - val_auc: 0.5821
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF0EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9916084, 0), (0.96511596, 0), (0.91322803, 0), (0.8786528, 0), (0.7441675, 0), (0.7152094, 0), (0.7115708, 0), (0.66789657, 0), (0.64981997, 0), (0.64801455, 0), (0.6462413, 0), (0.64592606, 0), (0.63499856, 0), (0.6300614, 0), (0.62559503, 0), (0.62174207, 0), (0.62011445, 0), (0.6185908, 0), (0.6162487, 0), (0.5995385, 1), (0.5974609, 0), (0.59397155, 0), (0.593511, 1), (0.5901696, 0), (0.57944316, 1), (0.56033224, 0), (0.55913997, 0), (0.5541649, 0), (0.52438265, 0), (0.5202297, 0), (0.49624404, 1), (0.4915355, 0), (0.48748213, 0), (0.48726517, 0), (0.48600453, 0), (0.47732338, 0), (0.46761805, 0), (0.4669816, 0), (0.46039376, 0), (0.35605302, 0), (0.3500492, 0), (0.33733064, 0), (0.3264255, 0), (0.2478906, 0), (0.0, 0)]
0.0
0.0
Siam
[0.4, 0.3, 0.0, 0.2, 0.0, 0.1, 0.1, 0.0, 0.2, 0.0, 0.2, 0.0, 0.6, 0.0, 0.3, 0.7, 0.1, 0.1, 0.2, 0.0]
0.175
[0.26666666666666666, 0.3333333333333333, 0.0, 0.5, 0.0, 0.1111111111111111, 0.07692307692307693, 0.0, 0.25, 0.0, 0.5, 0.0, 0.375, -1.0, 0.25, 0.21875, 0.09090909090909091, 0.2, 0.5, 0.0]
0.19329964626017257
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[16]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.25</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235061F8DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.5896 - auc: 0.5127 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503FAED38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5960 - auc: 0.5005 - val_loss: 0.4276 - val_auc: 0.4329
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5336 - auc: 0.5852 - val_loss: 0.4296 - val_auc: 0.4885
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5124 - auc: 0.6214 - val_loss: 0.3724 - val_auc: 0.5981
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4901 - auc: 0.6905 - val_loss: 0.3171 - val_auc: 0.5529
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5124 - auc: 0.6334 - val_loss: 0.3578 - val_auc: 0.5103
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5037 - auc: 0.6413 - val_loss: 0.3475 - val_auc: 0.5570
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4771 - auc: 0.6796 - val_loss: 0.3103 - val_auc: 0.5585
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6691 - val_loss: 0.3053 - val_auc: 0.5089
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7117 - val_loss: 0.3042 - val_auc: 0.5677
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.6694 - val_loss: 0.3100 - val_auc: 0.5304
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4846 - auc: 0.6664 - val_loss: 0.3020 - val_auc: 0.5830
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6722 - val_loss: 0.3180 - val_auc: 0.5780
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4663 - auc: 0.7030 - val_loss: 0.2779 - val_auc: 0.5493
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.6944 - val_loss: 0.3082 - val_auc: 0.5795
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4759 - auc: 0.6895 - val_loss: 0.2968 - val_auc: 0.5913
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.6906 - val_loss: 0.3188 - val_auc: 0.5467
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4655 - auc: 0.7183 - val_loss: 0.2881 - val_auc: 0.5751
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4697 - auc: 0.7207 - val_loss: 0.2999 - val_auc: 0.5801
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4706 - auc: 0.6903 - val_loss: 0.3007 - val_auc: 0.5724
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4641 - auc: 0.7240 - val_loss: 0.2913 - val_auc: 0.5417
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504C01708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.91471076, 0), (0.90873986, 0), (0.89717484, 1), (0.84439856, 1), (0.83030516, 0), (0.8110071, 0), (0.7981174, 1), (0.78097, 1), (0.777993, 0), (0.7734841, 0), (0.7622872, 1), (0.7620647, 0), (0.75237316, 1), (0.7431129, 0), (0.72857517, 1), (0.71892667, 0), (0.71777517, 1), (0.7147771, 0), (0.71052915, 0), (0.7030287, 0), (0.7016692, 0), (0.6848668, 0), (0.6642323, 1), (0.6590855, 0), (0.6530837, 0), (0.6275177, 0), (0.6167402, 1), (0.5974704, 0), (0.5960165, 0), (0.56557983, 0), (0.4597145, 0), (0.43564188, 0), (0.38919538, 1), (0.33222476, 0), (0.26058418, 0), (0.033369903, 1), (0.0, 0)]
0.4
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B51F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.6020 - auc: 0.5077WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503BD9CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5933 - auc: 0.5164 - val_loss: 0.3696 - val_auc: 0.3690
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5221 - auc: 0.6442 - val_loss: 0.3500 - val_auc: 0.5079
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5381 - auc: 0.5891 - val_loss: 0.3864 - val_auc: 0.6032
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5191 - auc: 0.6249 - val_loss: 0.3732 - val_auc: 0.6214
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5166 - auc: 0.6171 - val_loss: 0.2985 - val_auc: 0.5311
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5010 - auc: 0.6530 - val_loss: 0.3246 - val_auc: 0.5873
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5011 - auc: 0.6543 - val_loss: 0.3626 - val_auc: 0.7133
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6884 - val_loss: 0.3408 - val_auc: 0.6634
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.6973 - val_loss: 0.3248 - val_auc: 0.5883
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6833 - val_loss: 0.3322 - val_auc: 0.6524
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4817 - auc: 0.7098 - val_loss: 0.3185 - val_auc: 0.5850
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4647 - auc: 0.7366 - val_loss: 0.3302 - val_auc: 0.5999
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4731 - auc: 0.7137 - val_loss: 0.3094 - val_auc: 0.6286
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4750 - auc: 0.7138 - val_loss: 0.3101 - val_auc: 0.6134
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6795 - val_loss: 0.3215 - val_auc: 0.6567
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.6970 - val_loss: 0.3125 - val_auc: 0.7024
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4573 - auc: 0.7482 - val_loss: 0.3063 - val_auc: 0.6111
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.7141 - val_loss: 0.3091 - val_auc: 0.5956
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.7153 - val_loss: 0.3418 - val_auc: 0.7097
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.7053 - val_loss: 0.3199 - val_auc: 0.6481
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509CD8CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.99939215, 1), (0.9967312, 1), (0.99260026, 0), (0.99255747, 1), (0.98567414, 0), (0.98469275, 0), (0.9834426, 0), (0.9827758, 1), (0.98188794, 0), (0.9816083, 0), (0.9764353, 0), (0.9750918, 0), (0.9743213, 0), (0.97347015, 0), (0.9546855, 0), (0.9543299, 0), (0.95419234, 0), (0.9524917, 1), (0.9420032, 0), (0.9315465, 0), (0.92717856, 0), (0.92679656, 0), (0.8862648, 0), (0.8666064, 0), (0.859575, 0), (0.8349159, 1), (0.8117269, 0), (0.8116009, 0), (0.77351624, 0), (0.75021356, 0), (0.7351031, 0), (0.5971725, 0), (0.47627372, 0), (0.45462593, 0), (0.37501344, 0), (0.31403574, 0), (0.0, 0)]
0.5
0.7142857142857143
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A783A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
98/99 [============================&gt;.] - ETA: 0s - loss: 0.6338 - auc: 0.5027WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235047B5798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.6330 - auc: 0.5036 - val_loss: 0.3552 - val_auc: 0.5891
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5811 - auc: 0.5577 - val_loss: 0.4432 - val_auc: 0.6276
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5626 - auc: 0.5698 - val_loss: 0.4213 - val_auc: 0.5292
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5422 - auc: 0.5806 - val_loss: 0.3893 - val_auc: 0.6677
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.6482 - val_loss: 0.3291 - val_auc: 0.7526
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5226 - auc: 0.6437 - val_loss: 0.3407 - val_auc: 0.7490
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5080 - auc: 0.6617 - val_loss: 0.3334 - val_auc: 0.6714
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5039 - auc: 0.6880 - val_loss: 0.2935 - val_auc: 0.5979
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5125 - auc: 0.6802 - val_loss: 0.2881 - val_auc: 0.8156
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.6960 - val_loss: 0.3333 - val_auc: 0.7146
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5032 - auc: 0.6882 - val_loss: 0.3250 - val_auc: 0.6245
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5127 - auc: 0.6790 - val_loss: 0.3302 - val_auc: 0.7417
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6862 - val_loss: 0.3118 - val_auc: 0.7495
Epoch 14/20
99/99 [==============================] - ETA: 0s - loss: 0.4939 - auc: 0.681 - 0s 4ms/step - loss: 0.4992 - auc: 0.6745 - val_loss: 0.2996 - val_auc: 0.6922
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5071 - auc: 0.6800 - val_loss: 0.3060 - val_auc: 0.6474
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.6767 - val_loss: 0.3107 - val_auc: 0.6104
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6744 - val_loss: 0.2964 - val_auc: 0.6328
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.7052 - val_loss: 0.2926 - val_auc: 0.6406
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.7221 - val_loss: 0.2870 - val_auc: 0.6870
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.7086 - val_loss: 0.2872 - val_auc: 0.6911
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350AB705E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.87119323, 0), (0.77069205, 0), (0.7191579, 0), (0.7037116, 0), (0.70178854, 0), (0.69460064, 0), (0.6766858, 0), (0.6697494, 0), (0.667199, 0), (0.6558249, 0), (0.6521532, 0), (0.64876556, 0), (0.63326454, 0), (0.62996334, 0), (0.62855506, 0), (0.6267426, 0), (0.6238836, 0), (0.6224571, 0), (0.62189347, 0), (0.6181647, 1), (0.6155457, 0), (0.61460066, 0), (0.61293274, 0), (0.6115638, 0), (0.61100215, 0), (0.5954609, 0), (0.5871777, 0), (0.5225522, 0), (0.47314078, 1), (0.46976516, 1), (0.46821436, 0), (0.3177553, 0), (0.31550348, 1), (0.3134386, 0), (0.27725613, 0), (0.23696148, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235594A74C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
89/99 [=========================&gt;....] - ETA: 0s - loss: 0.6137 - auc: 0.5035WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023507651048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.6074 - auc: 0.4985 - val_loss: 0.4145 - val_auc: 0.6401
Epoch 2/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5289 - auc: 0.6153 - val_loss: 0.3613 - val_auc: 0.6318
Epoch 3/20
99/99 [==============================] - 1s 6ms/step - loss: 0.5283 - auc: 0.6121 - val_loss: 0.3348 - val_auc: 0.5984
Epoch 4/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4978 - auc: 0.6560 - val_loss: 0.3500 - val_auc: 0.6938
Epoch 5/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5160 - auc: 0.6426 - val_loss: 0.3193 - val_auc: 0.6333
Epoch 6/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5274 - auc: 0.6283 - val_loss: 0.3575 - val_auc: 0.6297
Epoch 7/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5031 - auc: 0.6439 - val_loss: 0.3229 - val_auc: 0.5828
Epoch 8/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5018 - auc: 0.6751 - val_loss: 0.3144 - val_auc: 0.6219
Epoch 9/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4998 - auc: 0.6880 - val_loss: 0.2926 - val_auc: 0.6333
Epoch 10/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5007 - auc: 0.6789 - val_loss: 0.2893 - val_auc: 0.6052
Epoch 11/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4956 - auc: 0.6905 - val_loss: 0.2836 - val_auc: 0.5589
Epoch 12/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4956 - auc: 0.6875 - val_loss: 0.3114 - val_auc: 0.6880
Epoch 13/20
99/99 [==============================] - 1s 6ms/step - loss: 0.5023 - auc: 0.6627 - val_loss: 0.3102 - val_auc: 0.6406
Epoch 14/20
99/99 [==============================] - 1s 6ms/step - loss: 0.4937 - auc: 0.7099 - val_loss: 0.3028 - val_auc: 0.7078
Epoch 15/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4971 - auc: 0.7097 - val_loss: 0.3114 - val_auc: 0.6516
Epoch 16/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5029 - auc: 0.6816 - val_loss: 0.3157 - val_auc: 0.6120
Epoch 17/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4878 - auc: 0.7322 - val_loss: 0.3126 - val_auc: 0.6026
Epoch 18/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4848 - auc: 0.7094 - val_loss: 0.3092 - val_auc: 0.5979
Epoch 19/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4904 - auc: 0.6969 - val_loss: 0.3020 - val_auc: 0.6089
Epoch 20/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4911 - auc: 0.7104 - val_loss: 0.3027 - val_auc: 0.6490
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503094AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.86045337, 0), (0.80747616, 0), (0.8059709, 0), (0.79408586, 0), (0.7789963, 0), (0.77245116, 0), (0.7676432, 1), (0.7608672, 0), (0.7528684, 0), (0.7513724, 0), (0.73629415, 0), (0.717264, 0), (0.71112657, 1), (0.7077783, 0), (0.69135773, 1), (0.68914795, 0), (0.6827915, 0), (0.67342865, 0), (0.67192894, 0), (0.66285753, 0), (0.65782493, 0), (0.6530291, 0), (0.65083325, 0), (0.6260114, 0), (0.61805034, 0), (0.6163383, 0), (0.6068602, 1), (0.60565287, 0), (0.5791206, 0), (0.5710248, 1), (0.54618746, 0), (0.476818, 0), (0.46841055, 0), (0.2466603, 0), (0.22502, 0), (0.18975775, 0), (0.0, 0)]
0.1
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502DEAAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
92/99 [==========================&gt;...] - ETA: 0s - loss: 0.5695 - auc: 0.5084WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350301F8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.5681 - auc: 0.5087 - val_loss: 0.4035 - val_auc: 0.4767
Epoch 2/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5245 - auc: 0.5998 - val_loss: 0.3551 - val_auc: 0.5759
Epoch 3/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5203 - auc: 0.6243 - val_loss: 0.3286 - val_auc: 0.5774
Epoch 4/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5181 - auc: 0.6385 - val_loss: 0.3486 - val_auc: 0.6662
Epoch 5/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5053 - auc: 0.6567 - val_loss: 0.3660 - val_auc: 0.6733
Epoch 6/20
99/99 [==============================] - 1s 6ms/step - loss: 0.5113 - auc: 0.6355 - val_loss: 0.3433 - val_auc: 0.6902
Epoch 7/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5024 - auc: 0.6691 - val_loss: 0.3536 - val_auc: 0.6714
Epoch 8/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4997 - auc: 0.6770 - val_loss: 0.3150 - val_auc: 0.6549
Epoch 9/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5118 - auc: 0.6542 - val_loss: 0.3189 - val_auc: 0.7301
Epoch 10/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4922 - auc: 0.6867 - val_loss: 0.2901 - val_auc: 0.5504
Epoch 11/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4902 - auc: 0.6898 - val_loss: 0.3050 - val_auc: 0.6030
Epoch 12/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4920 - auc: 0.6865 - val_loss: 0.2899 - val_auc: 0.6793
Epoch 13/20
99/99 [==============================] - 1s 6ms/step - loss: 0.5016 - auc: 0.6869 - val_loss: 0.3079 - val_auc: 0.6966
Epoch 14/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4807 - auc: 0.7151 - val_loss: 0.2879 - val_auc: 0.7098
Epoch 15/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5024 - auc: 0.6813 - val_loss: 0.2923 - val_auc: 0.7598
Epoch 16/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5022 - auc: 0.6656 - val_loss: 0.3311 - val_auc: 0.7162
Epoch 17/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4914 - auc: 0.6939 - val_loss: 0.3105 - val_auc: 0.7004
Epoch 18/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4851 - auc: 0.6933 - val_loss: 0.3033 - val_auc: 0.7515
Epoch 19/20
99/99 [==============================] - 1s 6ms/step - loss: 0.4739 - auc: 0.7207 - val_loss: 0.3108 - val_auc: 0.7143
Epoch 20/20
99/99 [==============================] - 1s 6ms/step - loss: 0.4734 - auc: 0.7329 - val_loss: 0.3139 - val_auc: 0.7139
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503880288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9394808, 0), (0.8279556, 0), (0.8256794, 0), (0.7530405, 0), (0.7530405, 0), (0.7530405, 0), (0.7530405, 1), (0.7530405, 1), (0.7530405, 0), (0.7530405, 0), (0.7530405, 0), (0.7464893, 0), (0.73955566, 0), (0.737977, 0), (0.73616314, 0), (0.72879237, 0), (0.7089456, 0), (0.6940692, 1), (0.683097, 0), (0.6731663, 0), (0.66430897, 0), (0.6502462, 0), (0.64683175, 0), (0.64014304, 0), (0.5995831, 1), (0.5863291, 0), (0.5748145, 0), (0.56327933, 0), (0.5335213, 0), (0.5169024, 0), (0.50841856, 0), (0.45921436, 0), (0.3201457, 0), (0.3151794, 0), (0.31233275, 0), (0.2434307, 0), (0.0, 0)]
0.2
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503F991F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
94/99 [===========================&gt;..] - ETA: 0s - loss: 0.6110 - auc: 0.5326WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0C0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.6126 - auc: 0.5376 - val_loss: 0.4986 - val_auc: 0.6240
Epoch 2/20
99/99 [==============================] - 1s 5ms/step - loss: 0.6011 - auc: 0.5418 - val_loss: 0.3566 - val_auc: 0.8218
Epoch 3/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5308 - auc: 0.6162 - val_loss: 0.3340 - val_auc: 0.7209
Epoch 4/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5185 - auc: 0.6384 - val_loss: 0.3726 - val_auc: 0.7216
Epoch 5/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4994 - auc: 0.6633 - val_loss: 0.3594 - val_auc: 0.7047
Epoch 6/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5007 - auc: 0.6572 - val_loss: 0.3586 - val_auc: 0.8284
Epoch 7/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5104 - auc: 0.6533 - val_loss: 0.3634 - val_auc: 0.7354
Epoch 8/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4902 - auc: 0.7022 - val_loss: 0.3210 - val_auc: 0.7831
Epoch 9/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4839 - auc: 0.6928 - val_loss: 0.3489 - val_auc: 0.6108
Epoch 10/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4895 - auc: 0.6829 - val_loss: 0.3109 - val_auc: 0.6296
Epoch 11/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4767 - auc: 0.7115 - val_loss: 0.3342 - val_auc: 0.6366
Epoch 12/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5014 - auc: 0.6896 - val_loss: 0.3444 - val_auc: 0.4729
Epoch 13/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4828 - auc: 0.6924 - val_loss: 0.3240 - val_auc: 0.6822
Epoch 14/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4842 - auc: 0.6969 - val_loss: 0.3451 - val_auc: 0.6657
Epoch 15/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4941 - auc: 0.6725 - val_loss: 0.3464 - val_auc: 0.4937
Epoch 16/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4854 - auc: 0.6867 - val_loss: 0.3584 - val_auc: 0.5595
Epoch 17/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4692 - auc: 0.7375 - val_loss: 0.3609 - val_auc: 0.5384
Epoch 18/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4969 - auc: 0.6752 - val_loss: 0.3443 - val_auc: 0.6458
Epoch 19/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4856 - auc: 0.6804 - val_loss: 0.3422 - val_auc: 0.5069
Epoch 20/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4673 - auc: 0.7204 - val_loss: 0.3346 - val_auc: 0.5175
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502B6D828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.94728565, 1), (0.92336637, 0), (0.88636017, 0), (0.81745106, 0), (0.81016594, 0), (0.7542626, 0), (0.74102855, 0), (0.74029225, 0), (0.73680466, 0), (0.73518175, 0), (0.73431087, 0), (0.73008835, 0), (0.72931844, 1), (0.7269822, 0), (0.7240578, 1), (0.70221263, 0), (0.70111483, 1), (0.6982112, 1), (0.67669845, 1), (0.6760847, 0), (0.67303264, 0), (0.64534223, 1), (0.63959974, 0), (0.62665147, 0), (0.62387294, 0), (0.5872867, 0), (0.57973677, 1), (0.57824886, 0), (0.5201538, 0), (0.5002066, 0), (0.4735463, 0), (0.40373406, 0), (0.34127563, 0), (0.32225874, 0), (0.31542394, 0), (0.13393033, 0), (0.0, 0)]
0.1
0.125
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502B6D1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
97/99 [============================&gt;.] - ETA: 0s - loss: 0.7997 - auc: 0.5155WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502258CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.8036 - auc: 0.5113 - val_loss: 0.5059 - val_auc: 0.5753
Epoch 2/20
99/99 [==============================] - 1s 5ms/step - loss: 0.6263 - auc: 0.6021 - val_loss: 0.6899 - val_auc: 0.5687
Epoch 3/20
99/99 [==============================] - 1s 5ms/step - loss: 0.6087 - auc: 0.5941 - val_loss: 0.8143 - val_auc: 0.6386
Epoch 4/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5460 - auc: 0.6568 - val_loss: 0.7989 - val_auc: 0.6097
Epoch 5/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5590 - auc: 0.6637 - val_loss: 0.7303 - val_auc: 0.5802
Epoch 6/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5359 - auc: 0.6673 - val_loss: 0.7343 - val_auc: 0.6219
Epoch 7/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5414 - auc: 0.6580 - val_loss: 0.5788 - val_auc: 0.5975
Epoch 8/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5510 - auc: 0.6206 - val_loss: 0.5789 - val_auc: 0.6234
Epoch 9/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5165 - auc: 0.6705 - val_loss: 0.6529 - val_auc: 0.5213
Epoch 10/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5229 - auc: 0.6521 - val_loss: 0.6830 - val_auc: 0.5577
Epoch 11/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5254 - auc: 0.6479 - val_loss: 0.5852 - val_auc: 0.6569
Epoch 12/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4731 - auc: 0.7238 - val_loss: 0.5028 - val_auc: 0.6364
Epoch 13/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5091 - auc: 0.6676 - val_loss: 0.5131 - val_auc: 0.6124
Epoch 14/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5186 - auc: 0.6551 - val_loss: 0.5153 - val_auc: 0.6087
Epoch 15/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4928 - auc: 0.6912 - val_loss: 0.4955 - val_auc: 0.6026
Epoch 16/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4932 - auc: 0.6829 - val_loss: 0.4822 - val_auc: 0.6039
Epoch 17/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4977 - auc: 0.6787 - val_loss: 0.4791 - val_auc: 0.6222
Epoch 18/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4887 - auc: 0.6998 - val_loss: 0.4861 - val_auc: 0.6613
Epoch 19/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4889 - auc: 0.6855 - val_loss: 0.4647 - val_auc: 0.6520
Epoch 20/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4883 - auc: 0.6994 - val_loss: 0.4536 - val_auc: 0.6263
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502729DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.99587256, 0), (0.96409327, 1), (0.956156, 1), (0.9533441, 0), (0.9528435, 0), (0.93711925, 0), (0.93317777, 0), (0.9299865, 0), (0.929568, 0), (0.9218368, 0), (0.9124585, 0), (0.90742075, 0), (0.8985719, 1), (0.89088315, 0), (0.88368434, 0), (0.8710112, 0), (0.8571948, 0), (0.8530543, 0), (0.8505906, 1), (0.82268375, 1), (0.8052367, 0), (0.76945966, 0), (0.76641655, 0), (0.7600525, 0), (0.7285256, 0), (0.7167007, 0), (0.6375862, 0), (0.62153894, 0), (0.5821085, 0), (0.58003515, 0), (0.52429056, 0), (0.4635865, 0), (0.31669563, 0), (0.31221515, 0), (0.28574282, 1), (0.28123373, 1), (0.0, 0)]
0.3
0.375
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235027DC558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
96/99 [============================&gt;.] - ETA: 0s - loss: 0.5358 - auc: 0.5395WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235594A74C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.5341 - auc: 0.5402 - val_loss: 0.2734 - val_auc: 0.4421
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5249 - auc: 0.6028 - val_loss: 0.2679 - val_auc: 0.4712
Epoch 3/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5081 - auc: 0.6651 - val_loss: 0.2695 - val_auc: 0.4196
Epoch 4/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5198 - auc: 0.6357 - val_loss: 0.2816 - val_auc: 0.4460
Epoch 5/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5034 - auc: 0.6612 - val_loss: 0.2756 - val_auc: 0.4765
Epoch 6/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4971 - auc: 0.6785 - val_loss: 0.2918 - val_auc: 0.4741
Epoch 7/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4996 - auc: 0.6611 - val_loss: 0.2857 - val_auc: 0.5467
Epoch 8/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4944 - auc: 0.6913 - val_loss: 0.2773 - val_auc: 0.4680
Epoch 9/20
99/99 [==============================] - 1s 6ms/step - loss: 0.5060 - auc: 0.6620 - val_loss: 0.2872 - val_auc: 0.4814
Epoch 10/20
99/99 [==============================] - 1s 5ms/step - loss: 0.5028 - auc: 0.6736 - val_loss: 0.2861 - val_auc: 0.5545
Epoch 11/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4819 - auc: 0.7187 - val_loss: 0.2774 - val_auc: 0.4340
Epoch 12/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4971 - auc: 0.6887 - val_loss: 0.2862 - val_auc: 0.4641
Epoch 13/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4969 - auc: 0.6601 - val_loss: 0.2895 - val_auc: 0.4724
Epoch 14/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4807 - auc: 0.7134 - val_loss: 0.2946 - val_auc: 0.5332
Epoch 15/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4989 - auc: 0.6761 - val_loss: 0.2857 - val_auc: 0.5621
Epoch 16/20
99/99 [==============================] - 1s 5ms/step - loss: 0.4988 - auc: 0.6695 - val_loss: 0.2799 - val_auc: 0.5533
Epoch 17/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4845 - auc: 0.6956 - val_loss: 0.2762 - val_auc: 0.5648
Epoch 18/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4911 - auc: 0.6905 - val_loss: 0.2819 - val_auc: 0.5247
Epoch 19/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5004 - auc: 0.6779 - val_loss: 0.2810 - val_auc: 0.4910
Epoch 20/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4683 - auc: 0.7423 - val_loss: 0.2879 - val_auc: 0.5166
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235038804C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.96709996, 0), (0.8115375, 0), (0.7562385, 0), (0.7014165, 1), (0.6750683, 0), (0.63661045, 0), (0.59569657, 0), (0.58228844, 0), (0.56345946, 0), (0.5576636, 0), (0.5537418, 0), (0.53015393, 0), (0.51255226, 0), (0.511387, 0), (0.5108808, 0), (0.50148576, 0), (0.47850773, 0), (0.4757135, 0), (0.47553417, 0), (0.47027454, 0), (0.46970674, 0), (0.46329606, 0), (0.46178243, 0), (0.4587387, 0), (0.4538369, 0), (0.45318696, 0), (0.45006025, 0), (0.44781107, 0), (0.43915844, 0), (0.3774349, 0), (0.36091527, 0), (0.3590887, 0), (0.3177595, 0), (0.31554022, 0), (0.31427282, 0), (0.12561862, 0), (0.0, 0)]
0.1
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
91/99 [==========================&gt;...] - ETA: 0s - loss: 0.8436 - auc: 0.5163WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235044978B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.8260 - auc: 0.5192 - val_loss: 0.6851 - val_auc: 0.6435
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.6483 - auc: 0.5814 - val_loss: 0.6131 - val_auc: 0.6758
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.6039 - auc: 0.6105 - val_loss: 0.5765 - val_auc: 0.8054
Epoch 4/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5604 - auc: 0.6494 - val_loss: 0.6109 - val_auc: 0.6898
Epoch 5/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5678 - auc: 0.6217 - val_loss: 0.4963 - val_auc: 0.6475
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5316 - auc: 0.6708 - val_loss: 0.5946 - val_auc: 0.6928
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5365 - auc: 0.6557 - val_loss: 0.5822 - val_auc: 0.6924
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5185 - auc: 0.6629 - val_loss: 0.4995 - val_auc: 0.6453
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6773 - val_loss: 0.4566 - val_auc: 0.6924
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6676 - val_loss: 0.4329 - val_auc: 0.6946
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4997 - auc: 0.6828 - val_loss: 0.3698 - val_auc: 0.7478
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5147 - auc: 0.6517 - val_loss: 0.3977 - val_auc: 0.7029
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6690 - val_loss: 0.3616 - val_auc: 0.7286
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4838 - auc: 0.6985 - val_loss: 0.3408 - val_auc: 0.7225
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5050 - auc: 0.6627 - val_loss: 0.3776 - val_auc: 0.6907
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6921 - val_loss: 0.3432 - val_auc: 0.7277
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4877 - auc: 0.6816 - val_loss: 0.3380 - val_auc: 0.7291
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4763 - auc: 0.7162 - val_loss: 0.3290 - val_auc: 0.7208
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7133 - val_loss: 0.3196 - val_auc: 0.7277
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4947 - auc: 0.6915 - val_loss: 0.3580 - val_auc: 0.7029
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF0828&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.99896157, 0), (0.9956942, 0), (0.991846, 0), (0.9880078, 0), (0.9845945, 1), (0.9842463, 0), (0.98361665, 1), (0.9835413, 0), (0.96762997, 0), (0.9668729, 0), (0.9507183, 0), (0.94554055, 1), (0.9289156, 0), (0.92796564, 0), (0.92269605, 0), (0.9176555, 0), (0.9107203, 0), (0.8779858, 1), (0.8763751, 0), (0.8700752, 1), (0.8352123, 0), (0.8136097, 0), (0.8097128, 0), (0.7932844, 0), (0.7827172, 0), (0.72526526, 0), (0.717409, 0), (0.7132117, 0), (0.7017303, 0), (0.6044288, 0), (0.55928695, 0), (0.5233249, 1), (0.39995617, 0), (0.36269766, 0), (0.35971028, 0), (0.24465853, 0), (0.0, 0)]
0.3
0.42857142857142855
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350AB70AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
96/99 [============================&gt;.] - ETA: 0s - loss: 0.5580 - auc: 0.5231WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350210DD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 7ms/step - loss: 0.5603 - auc: 0.5216 - val_loss: 0.3596 - val_auc: 0.4418
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5264 - auc: 0.5737 - val_loss: 0.3306 - val_auc: 0.6640
Epoch 3/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5002 - auc: 0.6284 - val_loss: 0.2897 - val_auc: 0.6259
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6489 - val_loss: 0.3321 - val_auc: 0.6144
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4897 - auc: 0.6712 - val_loss: 0.3030 - val_auc: 0.6212
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6855 - val_loss: 0.3022 - val_auc: 0.5937
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6762 - val_loss: 0.3192 - val_auc: 0.6534
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6589 - val_loss: 0.3156 - val_auc: 0.6486
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6600 - val_loss: 0.3015 - val_auc: 0.6073
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6617 - val_loss: 0.2859 - val_auc: 0.6350
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4852 - auc: 0.6814 - val_loss: 0.2691 - val_auc: 0.7364
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4689 - auc: 0.6912 - val_loss: 0.3071 - val_auc: 0.6912
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.7212 - val_loss: 0.2661 - val_auc: 0.7314
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4812 - auc: 0.7040 - val_loss: 0.3085 - val_auc: 0.6974
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4863 - auc: 0.6767 - val_loss: 0.3116 - val_auc: 0.7063
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6640 - val_loss: 0.2972 - val_auc: 0.7450
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4673 - auc: 0.7113 - val_loss: 0.3026 - val_auc: 0.6424
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4688 - auc: 0.7253 - val_loss: 0.2905 - val_auc: 0.6389
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.6916 - val_loss: 0.3109 - val_auc: 0.6034
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4849 - auc: 0.6922 - val_loss: 0.3124 - val_auc: 0.6102
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350233BB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9388857, 1), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 1), (0.9387854, 1), (0.9387854, 1), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 0), (0.9387854, 1), (0.9387854, 0), (0.9387854, 0), (0.9293964, 0), (0.9286622, 1), (0.90329653, 1), (0.8871041, 1), (0.7489637, 0), (0.7142956, 0), (0.71163756, 0), (0.6752837, 0), (0.6078066, 0), (0.59909844, 0), (0.5673806, 1), (0.46996188, 0), (0.46419594, 0), (0.358027, 0), (0.26892617, 1), (0.22013478, 0), (0.18500884, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502467948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
90/99 [==========================&gt;...] - ETA: 0s - loss: 0.5376 - auc: 0.5286 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504497288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.5500 - auc: 0.5130 - val_loss: 0.3063 - val_auc: 0.5781
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5380 - auc: 0.5422 - val_loss: 0.3055 - val_auc: 0.4865
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5226 - auc: 0.6233 - val_loss: 0.2673 - val_auc: 0.5305
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5097 - auc: 0.6316 - val_loss: 0.2953 - val_auc: 0.5384
Epoch 5/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4957 - auc: 0.6500 - val_loss: 0.2624 - val_auc: 0.5960
Epoch 6/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5352 - auc: 0.6153 - val_loss: 0.2733 - val_auc: 0.6209
Epoch 7/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5211 - auc: 0.6118 - val_loss: 0.2740 - val_auc: 0.5423
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.6590 - val_loss: 0.2681 - val_auc: 0.5388
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5059 - auc: 0.6608 - val_loss: 0.2921 - val_auc: 0.4983
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5143 - auc: 0.6161 - val_loss: 0.2807 - val_auc: 0.5092
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6794 - val_loss: 0.2529 - val_auc: 0.5633
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6793 - val_loss: 0.2702 - val_auc: 0.5000
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5117 - auc: 0.6486 - val_loss: 0.2619 - val_auc: 0.5074
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5000 - auc: 0.6693 - val_loss: 0.2712 - val_auc: 0.5742
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5030 - auc: 0.6592 - val_loss: 0.2763 - val_auc: 0.5515
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6761 - val_loss: 0.2687 - val_auc: 0.5262
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5123 - auc: 0.6575 - val_loss: 0.2539 - val_auc: 0.6091
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6462 - val_loss: 0.2644 - val_auc: 0.6134
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6850 - val_loss: 0.2845 - val_auc: 0.5031
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6655 - val_loss: 0.2834 - val_auc: 0.5026
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350812F438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.56673044, 0), (0.5336625, 1), (0.5121141, 0), (0.47248316, 0), (0.46575087, 0), (0.45747864, 1), (0.45647302, 0), (0.45557573, 0), (0.45553958, 0), (0.45506528, 0), (0.45425662, 0), (0.45279673, 0), (0.45037642, 0), (0.44859558, 0), (0.4475935, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 1), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.44657758, 0), (0.4459346, 0), (0.43885008, 0), (0.43003508, 0), (0.42494375, 0), (0.36478385, 0), (0.33702627, 0), (0.3201132, 0), (0.26108322, 0), (0.20267239, 0), (0.15228333, 0), (0.0, 0)]
0.25
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - ETA: 0s - loss: 0.6910 - auc: 0.5008WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF01F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.6910 - auc: 0.5008 - val_loss: 0.4594 - val_auc: 0.5334
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5735 - auc: 0.5895 - val_loss: 0.4628 - val_auc: 0.4660
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5317 - auc: 0.6466 - val_loss: 0.4209 - val_auc: 0.4634
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5356 - auc: 0.6268 - val_loss: 0.4295 - val_auc: 0.4206
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5208 - auc: 0.6424 - val_loss: 0.4237 - val_auc: 0.4545
Epoch 6/20
99/99 [==============================] - 0s 5ms/step - loss: 0.5211 - auc: 0.6438 - val_loss: 0.4071 - val_auc: 0.3652
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6880 - val_loss: 0.4037 - val_auc: 0.4243
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5160 - auc: 0.6515 - val_loss: 0.4099 - val_auc: 0.4374
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5167 - auc: 0.6560 - val_loss: 0.3637 - val_auc: 0.4634
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4978 - auc: 0.6774 - val_loss: 0.3406 - val_auc: 0.4444
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.7053 - val_loss: 0.3564 - val_auc: 0.4382
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4820 - auc: 0.7174 - val_loss: 0.3294 - val_auc: 0.4340
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5205 - auc: 0.6441 - val_loss: 0.3619 - val_auc: 0.4644
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6865 - val_loss: 0.3249 - val_auc: 0.4604
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.6868 - val_loss: 0.3468 - val_auc: 0.4233
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.7002 - val_loss: 0.3225 - val_auc: 0.4521
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4799 - auc: 0.7216 - val_loss: 0.3184 - val_auc: 0.4479
Epoch 18/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4959 - auc: 0.6801 - val_loss: 0.3340 - val_auc: 0.4829
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6734 - val_loss: 0.3357 - val_auc: 0.4575
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.7198 - val_loss: 0.3121 - val_auc: 0.4824
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502170708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9961684, 0), (0.98555833, 0), (0.9774599, 0), (0.97451544, 0), (0.9412706, 0), (0.94042736, 0), (0.93622386, 0), (0.92708707, 0), (0.9192586, 0), (0.90690434, 1), (0.8649889, 0), (0.8565972, 0), (0.83047086, 0), (0.825097, 0), (0.8039482, 0), (0.7552567, 0), (0.75516343, 0), (0.7299214, 0), (0.70140636, 0), (0.66491735, 0), (0.66170454, 0), (0.66084456, 0), (0.56308776, 0), (0.5473937, 0), (0.53998536, 0), (0.5220221, 0), (0.4980302, 0), (0.49457675, 0), (0.4882299, 0), (0.47696027, 0), (0.4626209, 0), (0.44035417, 0), (0.43718654, 0), (0.26743296, 0), (0.26047707, 0), (0.18516418, 0), (0.0, 0)]
0.1
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235582983A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.5337 - auc: 0.5734WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235038804C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 8ms/step - loss: 0.5191 - auc: 0.5731 - val_loss: 0.2816 - val_auc: 0.5876
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5038 - auc: 0.6131 - val_loss: 0.2848 - val_auc: 0.5794
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.5999 - val_loss: 0.3303 - val_auc: 0.4590
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4934 - auc: 0.6199 - val_loss: 0.2965 - val_auc: 0.4005
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4875 - auc: 0.6591 - val_loss: 0.2998 - val_auc: 0.5291
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4901 - auc: 0.6325 - val_loss: 0.2997 - val_auc: 0.4812
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4836 - auc: 0.6715 - val_loss: 0.3011 - val_auc: 0.4603
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.6520 - val_loss: 0.2916 - val_auc: 0.3935
Epoch 9/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4994 - auc: 0.6475 - val_loss: 0.2911 - val_auc: 0.5185
Epoch 10/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4977 - auc: 0.6391 - val_loss: 0.2900 - val_auc: 0.4084
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4891 - auc: 0.6541 - val_loss: 0.2786 - val_auc: 0.4001
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.7014 - val_loss: 0.2917 - val_auc: 0.3968
Epoch 13/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4692 - auc: 0.6946 - val_loss: 0.2834 - val_auc: 0.4160
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4706 - auc: 0.6941 - val_loss: 0.2787 - val_auc: 0.4785
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4709 - auc: 0.7266 - val_loss: 0.2937 - val_auc: 0.4699
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4850 - auc: 0.6977 - val_loss: 0.3033 - val_auc: 0.6591
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4597 - auc: 0.7216 - val_loss: 0.2732 - val_auc: 0.7298
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4567 - auc: 0.7271 - val_loss: 0.2928 - val_auc: 0.5797
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4716 - auc: 0.7144 - val_loss: 0.2792 - val_auc: 0.4954
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4722 - auc: 0.6970 - val_loss: 0.2947 - val_auc: 0.4821
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023500A72EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9945675, 1), (0.9842051, 1), (0.943581, 1), (0.8817673, 0), (0.857045, 0), (0.8060686, 1), (0.79940766, 0), (0.7989186, 1), (0.7685519, 0), (0.7428394, 0), (0.7303671, 1), (0.72343177, 0), (0.70243305, 1), (0.6977084, 0), (0.6920801, 1), (0.6865591, 0), (0.68394476, 0), (0.68100095, 0), (0.6805728, 0), (0.67990255, 1), (0.6760055, 0), (0.6760055, 1), (0.6760055, 0), (0.6760055, 0), (0.6760055, 1), (0.6760055, 1), (0.6760055, 1), (0.6760055, 0), (0.6760055, 0), (0.67277783, 0), (0.6557018, 0), (0.652374, 0), (0.6348012, 1), (0.6307753, 0), (0.5915084, 0), (0.5204531, 1), (0.0, 0)]
0.5
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502729438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - ETA: 0s - loss: 0.5516 - auc: 0.5099WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502B6D048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5516 - auc: 0.5099 - val_loss: 0.3226 - val_auc: 0.5390
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5321 - auc: 0.5618 - val_loss: 0.3365 - val_auc: 0.3750
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5172 - auc: 0.6017 - val_loss: 0.3059 - val_auc: 0.4876
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5161 - auc: 0.5863 - val_loss: 0.3079 - val_auc: 0.4000
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5158 - auc: 0.6280 - val_loss: 0.2981 - val_auc: 0.4574
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5149 - auc: 0.6068 - val_loss: 0.2928 - val_auc: 0.4818
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5039 - auc: 0.6523 - val_loss: 0.2955 - val_auc: 0.4914
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6723 - val_loss: 0.2884 - val_auc: 0.4583
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5051 - auc: 0.6563 - val_loss: 0.2984 - val_auc: 0.5288
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6672 - val_loss: 0.2920 - val_auc: 0.5502
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6631 - val_loss: 0.2946 - val_auc: 0.6106
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6694 - val_loss: 0.3093 - val_auc: 0.5743
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5027 - auc: 0.6714 - val_loss: 0.2864 - val_auc: 0.5561
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6638 - val_loss: 0.2897 - val_auc: 0.5448
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4811 - auc: 0.6974 - val_loss: 0.2763 - val_auc: 0.5586
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6619 - val_loss: 0.2763 - val_auc: 0.5680
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4885 - auc: 0.6888 - val_loss: 0.2816 - val_auc: 0.5322
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6581 - val_loss: 0.2831 - val_auc: 0.5595
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.7057 - val_loss: 0.2918 - val_auc: 0.5432
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5046 - auc: 0.6664 - val_loss: 0.2989 - val_auc: 0.5169
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235023CFDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9845572, 0), (0.8666681, 0), (0.7266476, 0), (0.6644522, 0), (0.6453217, 0), (0.62393785, 0), (0.6204018, 0), (0.6155505, 0), (0.6048209, 0), (0.6032475, 0), (0.58931434, 0), (0.5786377, 0), (0.57363695, 0), (0.5571437, 0), (0.55440366, 0), (0.53767556, 0), (0.5371261, 0), (0.5365942, 0), (0.53287494, 0), (0.5320795, 0), (0.531753, 0), (0.53084326, 0), (0.5300645, 0), (0.5288177, 0), (0.5273498, 0), (0.52724797, 0), (0.5269972, 0), (0.5234111, 0), (0.5229553, 0), (0.52247775, 0), (0.51477367, 0), (0.5115989, 0), (0.38836065, 0), (0.33823454, 0), (0.2078584, 0), (0.19952303, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235095939D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/99 [=========================&gt;....] - ETA: 0s - loss: 0.6273 - auc: 0.5603WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350301F288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.6243 - auc: 0.5576 - val_loss: 0.3971 - val_auc: 0.5317
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5577 - auc: 0.5812 - val_loss: 0.4164 - val_auc: 0.5152
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5382 - auc: 0.6103 - val_loss: 0.3788 - val_auc: 0.5463
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5339 - auc: 0.6067 - val_loss: 0.3643 - val_auc: 0.5681
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5169 - auc: 0.6295 - val_loss: 0.3212 - val_auc: 0.5909
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6516 - val_loss: 0.3553 - val_auc: 0.5479
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6547 - val_loss: 0.3208 - val_auc: 0.5939
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6747 - val_loss: 0.3248 - val_auc: 0.5880
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6652 - val_loss: 0.3285 - val_auc: 0.5370
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6606 - val_loss: 0.3231 - val_auc: 0.5638
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4977 - auc: 0.6808 - val_loss: 0.3287 - val_auc: 0.5205
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4648 - auc: 0.7139 - val_loss: 0.3058 - val_auc: 0.5291
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.7163 - val_loss: 0.2964 - val_auc: 0.5142
Epoch 14/20
99/99 [==============================] - ETA: 0s - loss: 0.4891 - auc: 0.692 - 0s 4ms/step - loss: 0.4865 - auc: 0.6922 - val_loss: 0.2761 - val_auc: 0.5979
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4845 - auc: 0.6878 - val_loss: 0.3156 - val_auc: 0.5582
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7114 - val_loss: 0.2973 - val_auc: 0.5033
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.7030 - val_loss: 0.3059 - val_auc: 0.4977
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4697 - auc: 0.7143 - val_loss: 0.3119 - val_auc: 0.4560
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4795 - auc: 0.6998 - val_loss: 0.2898 - val_auc: 0.5053
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4751 - auc: 0.7007 - val_loss: 0.2995 - val_auc: 0.5384
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350233BD38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9991327, 1), (0.9752282, 0), (0.97146976, 0), (0.97104436, 1), (0.96221924, 0), (0.95074826, 0), (0.944398, 0), (0.9360061, 0), (0.9340865, 0), (0.9316552, 1), (0.92596227, 0), (0.9219115, 0), (0.91292185, 0), (0.9113849, 0), (0.9106285, 0), (0.9010959, 0), (0.89964765, 0), (0.8956186, 1), (0.8604509, 0), (0.8597988, 1), (0.84665275, 1), (0.8223433, 1), (0.8080534, 1), (0.7942859, 0), (0.78483725, 1), (0.7488434, 0), (0.736787, 1), (0.72461164, 0), (0.692332, 0), (0.6692849, 0), (0.663131, 0), (0.64247733, 0), (0.56262755, 0), (0.26201728, 0), (0.22740763, 0), (0.13427724, 0), (0.0, 0)]
0.2
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503C9F318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/99 [=========================&gt;....] - ETA: 0s - loss: 0.5101 - auc: 0.5146WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286CDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.4975 - auc: 0.5009 - val_loss: 0.3270 - val_auc: 0.4147
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.5359 - val_loss: 0.3224 - val_auc: 0.4601
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4815 - auc: 0.5338 - val_loss: 0.3092 - val_auc: 0.4869
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4832 - auc: 0.5964 - val_loss: 0.3020 - val_auc: 0.5174
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4795 - auc: 0.5900 - val_loss: 0.3107 - val_auc: 0.5741
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4740 - auc: 0.6121 - val_loss: 0.3027 - val_auc: 0.5544
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4732 - auc: 0.6142 - val_loss: 0.3121 - val_auc: 0.4273
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4745 - auc: 0.6070 - val_loss: 0.3064 - val_auc: 0.4598
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.6200 - val_loss: 0.3107 - val_auc: 0.4503
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4728 - auc: 0.6107 - val_loss: 0.3199 - val_auc: 0.4812
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4670 - auc: 0.6246 - val_loss: 0.3143 - val_auc: 0.5171
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4655 - auc: 0.6492 - val_loss: 0.3103 - val_auc: 0.5047
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4695 - auc: 0.6398 - val_loss: 0.3159 - val_auc: 0.5445
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4743 - auc: 0.6198 - val_loss: 0.3162 - val_auc: 0.5414
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4734 - auc: 0.6402 - val_loss: 0.3166 - val_auc: 0.4660
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4580 - auc: 0.6687 - val_loss: 0.3172 - val_auc: 0.5283
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4602 - auc: 0.6751 - val_loss: 0.3224 - val_auc: 0.5437
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4594 - auc: 0.6881 - val_loss: 0.3253 - val_auc: 0.4586
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4671 - auc: 0.6523 - val_loss: 0.3215 - val_auc: 0.4634
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4558 - auc: 0.6739 - val_loss: 0.3196 - val_auc: 0.4845
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235580A0948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.66643393, 1), (0.60678595, 1), (0.5905434, 0), (0.56067353, 0), (0.53105193, 1), (0.52333355, 0), (0.51452893, 1), (0.5127058, 1), (0.5119394, 1), (0.50903535, 1), (0.50648254, 1), (0.50610787, 1), (0.5036434, 1), (0.49989063, 0), (0.48396325, 0), (0.48183805, 0), (0.47421917, 1), (0.46938133, 0), (0.46681345, 1), (0.45159414, 1), (0.44253787, 1), (0.44176057, 1), (0.4379429, 0), (0.40124664, 1), (0.40089515, 1), (0.34921315, 0), (0.33994484, 1), (0.3154071, 1), (0.31511962, 0), (0.30224696, 0), (0.28778678, 1), (0.23778954, 1), (0.21090369, 1), (0.20113093, 0), (0.17172964, 0), (0.021022532, 1), (0.0, 0)]
0.6
0.2608695652173913
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504BFFAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
88/99 [=========================&gt;....] - ETA: 0s - loss: 0.7406 - auc: 0.5105WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350812F288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.7440 - auc: 0.5092 - val_loss: 0.8895 - val_auc: 0.4752
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.6351 - auc: 0.5558 - val_loss: 0.5135 - val_auc: 0.6809
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5982 - auc: 0.5751 - val_loss: 0.7593 - val_auc: 0.5836
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5807 - auc: 0.5718 - val_loss: 0.6211 - val_auc: 0.6681
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5330 - auc: 0.6505 - val_loss: 0.5043 - val_auc: 0.5656
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5081 - auc: 0.6750 - val_loss: 0.4635 - val_auc: 0.5751
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5420 - auc: 0.6212 - val_loss: 0.4611 - val_auc: 0.5851
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6804 - val_loss: 0.4914 - val_auc: 0.5963
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5121 - auc: 0.6481 - val_loss: 0.4720 - val_auc: 0.5647
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5058 - auc: 0.6707 - val_loss: 0.4205 - val_auc: 0.5154
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.6946 - val_loss: 0.3989 - val_auc: 0.5641
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6845 - val_loss: 0.3852 - val_auc: 0.5615
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4848 - auc: 0.6958 - val_loss: 0.3886 - val_auc: 0.6247
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.6990 - val_loss: 0.3835 - val_auc: 0.6117
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4702 - auc: 0.7356 - val_loss: 0.3814 - val_auc: 0.6034
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4847 - auc: 0.7034 - val_loss: 0.3665 - val_auc: 0.5683
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.7111 - val_loss: 0.3782 - val_auc: 0.5739
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4948 - auc: 0.6915 - val_loss: 0.3888 - val_auc: 0.4941
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4831 - auc: 0.6936 - val_loss: 0.3767 - val_auc: 0.5328
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4660 - auc: 0.7311 - val_loss: 0.3753 - val_auc: 0.5301
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504497DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.95751745, 0), (0.95244354, 0), (0.9521119, 0), (0.93088126, 0), (0.92183524, 1), (0.9136616, 0), (0.91093946, 0), (0.90384567, 0), (0.8935611, 1), (0.88452667, 0), (0.8815474, 0), (0.87682104, 1), (0.8727868, 0), (0.868968, 0), (0.8605133, 1), (0.85849255, 0), (0.8497279, 0), (0.8490445, 0), (0.8429806, 0), (0.8405801, 0), (0.83373195, 0), (0.8315681, 0), (0.82925117, 0), (0.82807916, 0), (0.79699403, 1), (0.79150236, 0), (0.7888235, 0), (0.7671217, 0), (0.7148524, 0), (0.70437664, 0), (0.670273, 0), (0.58432245, 0), (0.5286218, 1), (0.5211922, 1), (0.43570125, 0), (0.41050908, 0), (0.0, 0)]
0.3
0.375
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023CF0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
86/99 [=========================&gt;....] - ETA: 0s - loss: 0.5668 - auc: 0.4973WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB74C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5711 - auc: 0.4991 - val_loss: 0.3375 - val_auc: 0.4927
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5391 - auc: 0.5562 - val_loss: 0.2874 - val_auc: 0.6406
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5328 - auc: 0.5821 - val_loss: 0.2802 - val_auc: 0.6516
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5288 - auc: 0.5860 - val_loss: 0.3015 - val_auc: 0.6839
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5260 - auc: 0.6102 - val_loss: 0.3014 - val_auc: 0.7354
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.5937 - val_loss: 0.2877 - val_auc: 0.7214
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4992 - auc: 0.6758 - val_loss: 0.2753 - val_auc: 0.7146
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5230 - auc: 0.6197 - val_loss: 0.2851 - val_auc: 0.6807
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6858 - val_loss: 0.2315 - val_auc: 0.7474
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5027 - auc: 0.6510 - val_loss: 0.2723 - val_auc: 0.6740
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5086 - auc: 0.6826 - val_loss: 0.2949 - val_auc: 0.6797
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4927 - auc: 0.6731 - val_loss: 0.2952 - val_auc: 0.6464
Epoch 13/20
99/99 [==============================] - 0s 5ms/step - loss: 0.4898 - auc: 0.6934 - val_loss: 0.2660 - val_auc: 0.7146
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6883 - val_loss: 0.2638 - val_auc: 0.6781
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.7089 - val_loss: 0.2715 - val_auc: 0.6219
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.7126 - val_loss: 0.2633 - val_auc: 0.6104
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.7102 - val_loss: 0.2903 - val_auc: 0.6297
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4940 - auc: 0.6872 - val_loss: 0.2901 - val_auc: 0.5844
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.7205 - val_loss: 0.3028 - val_auc: 0.6516
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6934 - val_loss: 0.2713 - val_auc: 0.6865
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023557F37CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.5918777, 0), (0.5339138, 0), (0.52297485, 0), (0.51921105, 1), (0.51589733, 0), (0.5126989, 0), (0.5047928, 0), (0.5026244, 0), (0.49556226, 0), (0.49143136, 0), (0.48437056, 0), (0.48346266, 0), (0.47934312, 0), (0.47831485, 0), (0.4768498, 0), (0.47506952, 0), (0.47230083, 0), (0.46175325, 0), (0.46175316, 0), (0.4562409, 0), (0.4499869, 0), (0.4480291, 0), (0.4146648, 0), (0.40486816, 1), (0.40006626, 0), (0.39765698, 0), (0.337422, 0), (0.28261125, 0), (0.2755813, 0), (0.2201541, 0), (0.20573834, 1), (0.14950898, 0), (0.13528025, 0), (0.11997225, 0), (0.06705457, 0), (0.044556163, 1), (0.0, 1)]
0.1111111111111111
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504497678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.6440 - auc: 0.4848WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0C558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 2s 6ms/step - loss: 0.6392 - auc: 0.4918 - val_loss: 0.3748 - val_auc: 0.6294
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5505 - auc: 0.6197 - val_loss: 0.4202 - val_auc: 0.4226
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5272 - auc: 0.6433 - val_loss: 0.3861 - val_auc: 0.4589
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5266 - auc: 0.6458 - val_loss: 0.3539 - val_auc: 0.3901
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5082 - auc: 0.6691 - val_loss: 0.3449 - val_auc: 0.5461
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5070 - auc: 0.6654 - val_loss: 0.3205 - val_auc: 0.4536
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4867 - auc: 0.7027 - val_loss: 0.3433 - val_auc: 0.4572
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4899 - auc: 0.7026 - val_loss: 0.2919 - val_auc: 0.4560
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4938 - auc: 0.6837 - val_loss: 0.3027 - val_auc: 0.4864
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6911 - val_loss: 0.2989 - val_auc: 0.5012
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4863 - auc: 0.6888 - val_loss: 0.2880 - val_auc: 0.5508
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4764 - auc: 0.7215 - val_loss: 0.2887 - val_auc: 0.5526
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4864 - auc: 0.7232 - val_loss: 0.3071 - val_auc: 0.5130
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5029 - auc: 0.6780 - val_loss: 0.3053 - val_auc: 0.5830
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.6901 - val_loss: 0.2973 - val_auc: 0.4905
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6887 - val_loss: 0.2856 - val_auc: 0.5207
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6887 - val_loss: 0.2945 - val_auc: 0.4879
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4814 - auc: 0.7061 - val_loss: 0.2876 - val_auc: 0.5068
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4765 - auc: 0.7264 - val_loss: 0.2765 - val_auc: 0.5553
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6993 - val_loss: 0.2968 - val_auc: 0.5366
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503F99798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.95534873, 0), (0.9473812, 1), (0.9223677, 0), (0.8593732, 0), (0.8388432, 0), (0.8300907, 0), (0.80896217, 0), (0.8050983, 0), (0.77454513, 0), (0.7733889, 0), (0.76907474, 0), (0.7676867, 0), (0.7439911, 0), (0.7328916, 0), (0.72827315, 0), (0.71844655, 0), (0.70241153, 0), (0.6808915, 0), (0.6798337, 0), (0.6778453, 0), (0.6768622, 0), (0.6722627, 0), (0.66533935, 0), (0.6555627, 0), (0.65368897, 0), (0.64868927, 1), (0.6400541, 0), (0.62332195, 0), (0.6129551, 0), (0.60171026, 1), (0.5348632, 0), (0.5322315, 0), (0.5232788, 0), (0.5122459, 0), (0.4981794, 0), (0.47098428, 0), (0.0, 0)]
0.1
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504AB7D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
87/99 [=========================&gt;....] - ETA: 0s - loss: 0.5337 - auc: 0.5586WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023CFCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
99/99 [==============================] - 1s 6ms/step - loss: 0.5310 - auc: 0.5687 - val_loss: 0.2271 - val_auc: 0.4795
Epoch 2/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5289 - auc: 0.5802 - val_loss: 0.2501 - val_auc: 0.5467
Epoch 3/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5212 - auc: 0.5980 - val_loss: 0.2634 - val_auc: 0.6867
Epoch 4/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5108 - auc: 0.6091 - val_loss: 0.2622 - val_auc: 0.5807
Epoch 5/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5097 - auc: 0.6501 - val_loss: 0.2547 - val_auc: 0.6466
Epoch 6/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5119 - auc: 0.6432 - val_loss: 0.2499 - val_auc: 0.6475
Epoch 7/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5111 - auc: 0.6320 - val_loss: 0.2543 - val_auc: 0.6339
Epoch 8/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5221 - auc: 0.6157 - val_loss: 0.2458 - val_auc: 0.5585
Epoch 9/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6610 - val_loss: 0.2511 - val_auc: 0.6003
Epoch 10/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5069 - auc: 0.6709 - val_loss: 0.2448 - val_auc: 0.5065
Epoch 11/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5074 - auc: 0.6547 - val_loss: 0.2443 - val_auc: 0.4764
Epoch 12/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5119 - auc: 0.6174 - val_loss: 0.2530 - val_auc: 0.6047
Epoch 13/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6941 - val_loss: 0.2437 - val_auc: 0.5794
Epoch 14/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5075 - auc: 0.6722 - val_loss: 0.2490 - val_auc: 0.5646
Epoch 15/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5021 - auc: 0.6564 - val_loss: 0.2479 - val_auc: 0.5218
Epoch 16/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5090 - auc: 0.6800 - val_loss: 0.2539 - val_auc: 0.6863
Epoch 17/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4938 - auc: 0.6908 - val_loss: 0.2503 - val_auc: 0.7243
Epoch 18/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5060 - auc: 0.6838 - val_loss: 0.2533 - val_auc: 0.7038
Epoch 19/20
99/99 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6838 - val_loss: 0.2447 - val_auc: 0.6248
Epoch 20/20
99/99 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6833 - val_loss: 0.2456 - val_auc: 0.7417
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503BD9EE8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9281693, 0), (0.70148695, 0), (0.6088734, 0), (0.57970035, 0), (0.5582622, 0), (0.5556142, 0), (0.55377775, 0), (0.54718816, 0), (0.54569083, 0), (0.53619146, 0), (0.5256923, 0), (0.5081253, 0), (0.50337875, 0), (0.5007797, 0), (0.49209616, 0), (0.49127728, 1), (0.48700824, 0), (0.48700824, 0), (0.48700824, 1), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.48700824, 0), (0.47348943, 1), (0.4510094, 0), (0.43367806, 0), (0.4254496, 0), (0.28408536, 0), (0.26719722, 0), (0.21107933, 0), (0.086906895, 0), (0.0, 0)]
0.0
0.0
Siam
[0.4, 0.5, 0.0, 0.1, 0.2, 0.1, 0.3, 0.1, 0.3, 0.2, 0.25, 0.1, 0.5, 0.0, 0.2, 0.6, 0.3, 0.1111111111111111, 0.1, 0.0]
0.21805555555555556
[0.3333333333333333, 0.7142857142857143, 0.0, 0.2, 0.5, 0.125, 0.375, 1.0, 0.42857142857142855, 0.2, 0.3333333333333333, 0.5, 0.3333333333333333, -1.0, 0.2, 0.2608695652173913, 0.375, 0.2, 0.3333333333333333, 0.0]
0.3374768442846246
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[17]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350233B318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/100 [============================&gt;.] - ETA: 0s - loss: 0.6467 - auc: 0.5378WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235030945E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.6444 - auc: 0.5389 - val_loss: 0.4865 - val_auc: 0.5931
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5394 - auc: 0.6304 - val_loss: 0.5490 - val_auc: 0.3367
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5128 - auc: 0.6548 - val_loss: 0.4676 - val_auc: 0.5560
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5393 - auc: 0.6112 - val_loss: 0.5066 - val_auc: 0.5205
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5163 - auc: 0.6325 - val_loss: 0.4549 - val_auc: 0.4969
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5035 - auc: 0.6475 - val_loss: 0.4326 - val_auc: 0.5127
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6642 - val_loss: 0.3920 - val_auc: 0.5413
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5088 - auc: 0.6342 - val_loss: 0.3688 - val_auc: 0.5203
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.6708 - val_loss: 0.3726 - val_auc: 0.5247
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4928 - auc: 0.6493 - val_loss: 0.3652 - val_auc: 0.5073
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4695 - auc: 0.7055 - val_loss: 0.3524 - val_auc: 0.5407
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4784 - auc: 0.6907 - val_loss: 0.3534 - val_auc: 0.5535
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4809 - auc: 0.6755 - val_loss: 0.3583 - val_auc: 0.4614
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4639 - auc: 0.7061 - val_loss: 0.3602 - val_auc: 0.4006
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4635 - auc: 0.7203 - val_loss: 0.3539 - val_auc: 0.4539
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4698 - auc: 0.7033 - val_loss: 0.3560 - val_auc: 0.4349
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4573 - auc: 0.7163 - val_loss: 0.3558 - val_auc: 0.4861
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4787 - auc: 0.6801 - val_loss: 0.3360 - val_auc: 0.5539
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4756 - auc: 0.6931 - val_loss: 0.3486 - val_auc: 0.5012
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4606 - auc: 0.7201 - val_loss: 0.3540 - val_auc: 0.4517
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B5E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.93896526, 0), (0.8881276, 0), (0.8775478, 0), (0.8744757, 1), (0.8525043, 1), (0.84054387, 1), (0.83853394, 0), (0.8367767, 1), (0.8326735, 1), (0.8271359, 0), (0.8179831, 0), (0.81360465, 0), (0.8065964, 0), (0.8044442, 0), (0.80305654, 1), (0.8006977, 0), (0.7945012, 0), (0.7945012, 0), (0.7871669, 0), (0.78049225, 0), (0.7160716, 0), (0.71163577, 0), (0.41076756, 0), (0.0, 1)]
0.5
0.7142857142857143
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350812F0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/100 [===========================&gt;..] - ETA: 0s - loss: 0.5372 - auc: 0.5303WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023CF3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 7ms/step - loss: 0.5323 - auc: 0.5294 - val_loss: 0.3061 - val_auc: 0.6442
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5135 - auc: 0.6015 - val_loss: 0.3234 - val_auc: 0.4437
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6755 - val_loss: 0.3087 - val_auc: 0.4455
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5084 - auc: 0.6386 - val_loss: 0.2806 - val_auc: 0.6243
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5007 - auc: 0.6544 - val_loss: 0.3091 - val_auc: 0.5582
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4960 - auc: 0.6750 - val_loss: 0.2920 - val_auc: 0.5828
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4912 - auc: 0.6718 - val_loss: 0.3145 - val_auc: 0.6767
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.6876 - val_loss: 0.3037 - val_auc: 0.6349
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4971 - auc: 0.6746 - val_loss: 0.2903 - val_auc: 0.5421
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4990 - auc: 0.6730 - val_loss: 0.2971 - val_auc: 0.6915
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5106 - auc: 0.6576 - val_loss: 0.3012 - val_auc: 0.6646
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4778 - auc: 0.7183 - val_loss: 0.3187 - val_auc: 0.6696
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4651 - auc: 0.7289 - val_loss: 0.2907 - val_auc: 0.6302
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5044 - auc: 0.6581 - val_loss: 0.3090 - val_auc: 0.6217
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4933 - auc: 0.6735 - val_loss: 0.3192 - val_auc: 0.5788
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6844 - val_loss: 0.2997 - val_auc: 0.6484
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4745 - auc: 0.6954 - val_loss: 0.2912 - val_auc: 0.6450
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.6861 - val_loss: 0.2943 - val_auc: 0.6638
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4682 - auc: 0.7203 - val_loss: 0.2882 - val_auc: 0.5354
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6737 - val_loss: 0.3039 - val_auc: 0.5817
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509CD8558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.43525827, 0), (0.40011925, 1), (0.3483831, 0), (0.33830148, 0), (0.32051736, 1), (0.3179024, 0), (0.315292, 0), (0.314683, 1), (0.314683, 0), (0.314683, 0), (0.314683, 0), (0.314683, 0), (0.314683, 1), (0.3061037, 0), (0.2967237, 0), (0.26632857, 0), (0.21688665, 1), (0.17999405, 0), (0.13842493, 0), (0.114689216, 0), (0.08653326, 0), (0.07565657, 0), (0.013379906, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235038800D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 94/100 [===========================&gt;..] - ETA: 0s - loss: 0.6072 - auc: 0.4803WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350286C558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.6133 - auc: 0.4771 - val_loss: 0.4714 - val_auc: 0.4751
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5262 - auc: 0.6105 - val_loss: 0.4004 - val_auc: 0.5105
Epoch 3/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5320 - auc: 0.6190 - val_loss: 0.3828 - val_auc: 0.5380
Epoch 4/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5276 - auc: 0.5997 - val_loss: 0.3283 - val_auc: 0.5710
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5255 - auc: 0.5966 - val_loss: 0.3364 - val_auc: 0.6492
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5145 - auc: 0.6364 - val_loss: 0.3220 - val_auc: 0.4696
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.6741 - val_loss: 0.3181 - val_auc: 0.4643
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6361 - val_loss: 0.3317 - val_auc: 0.5344
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4982 - auc: 0.6783 - val_loss: 0.3059 - val_auc: 0.5510
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5092 - auc: 0.6390 - val_loss: 0.3003 - val_auc: 0.5926
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4991 - auc: 0.6832 - val_loss: 0.3024 - val_auc: 0.5694
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4984 - auc: 0.6808 - val_loss: 0.3237 - val_auc: 0.5635
Epoch 13/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4950 - auc: 0.6661 - val_loss: 0.3149 - val_auc: 0.5252
Epoch 14/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4876 - auc: 0.7026 - val_loss: 0.3011 - val_auc: 0.6201
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.6935 - val_loss: 0.3117 - val_auc: 0.5707
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6837 - val_loss: 0.3111 - val_auc: 0.5376
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4965 - auc: 0.6810 - val_loss: 0.3033 - val_auc: 0.6037
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6641 - val_loss: 0.3130 - val_auc: 0.5065
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6997 - val_loss: 0.3050 - val_auc: 0.5753
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4991 - auc: 0.6911 - val_loss: 0.3201 - val_auc: 0.5213
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502170D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.93739945, 0), (0.92990535, 0), (0.9184975, 0), (0.903952, 0), (0.90360004, 0), (0.9031444, 0), (0.8915305, 0), (0.88883483, 1), (0.8882319, 0), (0.8869534, 0), (0.8857944, 0), (0.8857085, 0), (0.8851178, 0), (0.8774193, 0), (0.8758109, 0), (0.87121075, 0), (0.86969376, 0), (0.86817634, 0), (0.8655644, 0), (0.77444047, 0), (0.6687184, 0), (0.6519125, 0), (0.29907966, 0), (0.0, 0)]
0.1
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235021579D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 96/100 [===========================&gt;..] - ETA: 0s - loss: 0.5469 - auc: 0.4929WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350239A0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 7ms/step - loss: 0.5447 - auc: 0.5001 - val_loss: 0.2711 - val_auc: 0.6233
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5311 - auc: 0.5615 - val_loss: 0.2894 - val_auc: 0.7963
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5179 - auc: 0.5939 - val_loss: 0.2776 - val_auc: 0.6693
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.5798 - val_loss: 0.2647 - val_auc: 0.6730
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.6027 - val_loss: 0.2902 - val_auc: 0.6275
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5138 - auc: 0.6219 - val_loss: 0.2932 - val_auc: 0.6061
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5118 - auc: 0.6273 - val_loss: 0.2964 - val_auc: 0.5397
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4912 - auc: 0.6830 - val_loss: 0.2901 - val_auc: 0.6153
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5017 - auc: 0.6095 - val_loss: 0.2763 - val_auc: 0.5413
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5086 - auc: 0.6527 - val_loss: 0.2873 - val_auc: 0.6558
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4947 - auc: 0.6636 - val_loss: 0.2885 - val_auc: 0.6124
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4914 - auc: 0.6896 - val_loss: 0.2889 - val_auc: 0.5241
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5128 - auc: 0.6629 - val_loss: 0.2931 - val_auc: 0.4878
Epoch 14/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5090 - auc: 0.6557 - val_loss: 0.2740 - val_auc: 0.4958
Epoch 15/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5041 - auc: 0.6488 - val_loss: 0.3001 - val_auc: 0.5378
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5091 - auc: 0.6427 - val_loss: 0.2925 - val_auc: 0.5323
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4886 - auc: 0.6506 - val_loss: 0.2883 - val_auc: 0.4831
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4939 - auc: 0.6793 - val_loss: 0.3124 - val_auc: 0.5362
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4968 - auc: 0.6884 - val_loss: 0.3027 - val_auc: 0.4910
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4856 - auc: 0.7151 - val_loss: 0.2937 - val_auc: 0.5183
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502B6D948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.97163, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.93419254, 0), (0.76799196, 0), (0.7277501, 0), (0.36073864, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350497E798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.6631 - auc: 0.5347WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023509CD8E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 9ms/step - loss: 0.6440 - auc: 0.5470 - val_loss: 0.3767 - val_auc: 0.6398
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5689 - auc: 0.5996 - val_loss: 0.4068 - val_auc: 0.5360
Epoch 3/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5540 - auc: 0.6134 - val_loss: 0.4598 - val_auc: 0.5909
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5217 - auc: 0.6471 - val_loss: 0.3881 - val_auc: 0.6751
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5141 - auc: 0.6574 - val_loss: 0.3990 - val_auc: 0.6944
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5046 - auc: 0.6630 - val_loss: 0.3936 - val_auc: 0.6845
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5067 - auc: 0.6712 - val_loss: 0.4175 - val_auc: 0.6822
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4867 - auc: 0.7090 - val_loss: 0.3816 - val_auc: 0.7117
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4952 - auc: 0.6796 - val_loss: 0.3440 - val_auc: 0.7137
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5070 - auc: 0.6588 - val_loss: 0.3777 - val_auc: 0.6985
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4851 - auc: 0.6813 - val_loss: 0.3508 - val_auc: 0.6556
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5015 - auc: 0.6702 - val_loss: 0.3251 - val_auc: 0.6754
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4771 - auc: 0.7182 - val_loss: 0.3209 - val_auc: 0.6629
Epoch 14/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4840 - auc: 0.7107 - val_loss: 0.3282 - val_auc: 0.6912
Epoch 15/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4763 - auc: 0.7174 - val_loss: 0.3331 - val_auc: 0.6883
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4791 - auc: 0.7209 - val_loss: 0.3434 - val_auc: 0.6839
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4783 - auc: 0.7275 - val_loss: 0.3350 - val_auc: 0.7325
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4809 - auc: 0.7115 - val_loss: 0.3110 - val_auc: 0.7219
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4631 - auc: 0.7452 - val_loss: 0.3156 - val_auc: 0.7135
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4874 - auc: 0.7056 - val_loss: 0.2959 - val_auc: 0.7439
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235023CFB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8184251, 0), (0.5110651, 0), (0.50507236, 0), (0.496539, 0), (0.4882198, 0), (0.45577836, 0), (0.4416671, 0), (0.43260252, 0), (0.43030223, 0), (0.40749356, 1), (0.40700313, 0), (0.38392976, 1), (0.38375625, 0), (0.37640736, 0), (0.372409, 0), (0.36385384, 0), (0.27231365, 0), (0.2572722, 0), (0.22165003, 0), (0.2063457, 0), (0.2026107, 0), (0.16004457, 0), (0.1222132, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235021A7678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/100 [===========================&gt;..] - ETA: 0s - loss: 0.9343 - auc: 0.5067WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503094048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.9277 - auc: 0.5072 - val_loss: 1.8206 - val_auc: 0.6260
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.7100 - auc: 0.5803 - val_loss: 0.8004 - val_auc: 0.7117
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.6626 - auc: 0.6015 - val_loss: 0.9307 - val_auc: 0.6044
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.6282 - auc: 0.6336 - val_loss: 0.6782 - val_auc: 0.6469
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5766 - auc: 0.6489 - val_loss: 0.7463 - val_auc: 0.6954
Epoch 6/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5912 - auc: 0.6395 - val_loss: 0.9477 - val_auc: 0.6679
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5942 - auc: 0.6005 - val_loss: 0.9719 - val_auc: 0.6607
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5761 - auc: 0.6191 - val_loss: 0.8630 - val_auc: 0.7176
Epoch 9/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5612 - auc: 0.6231 - val_loss: 0.7903 - val_auc: 0.6551
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5285 - auc: 0.6606 - val_loss: 0.7893 - val_auc: 0.6384
Epoch 11/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5367 - auc: 0.6396 - val_loss: 0.7055 - val_auc: 0.6217
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5177 - auc: 0.6660 - val_loss: 0.6854 - val_auc: 0.6427
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5259 - auc: 0.6477 - val_loss: 0.6664 - val_auc: 0.6152
Epoch 14/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5152 - auc: 0.6643 - val_loss: 0.5419 - val_auc: 0.6741
Epoch 15/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5026 - auc: 0.6720 - val_loss: 0.4824 - val_auc: 0.6486
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4858 - auc: 0.6900 - val_loss: 0.4781 - val_auc: 0.6459
Epoch 17/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4887 - auc: 0.6871 - val_loss: 0.4633 - val_auc: 0.6230
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4805 - auc: 0.7018 - val_loss: 0.4072 - val_auc: 0.6410
Epoch 19/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4738 - auc: 0.7076 - val_loss: 0.4391 - val_auc: 0.6666
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4862 - auc: 0.6960 - val_loss: 0.3916 - val_auc: 0.6744
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350301FCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.98699486, 0), (0.97468305, 1), (0.9429155, 0), (0.93504524, 0), (0.89331144, 1), (0.8666762, 0), (0.86321366, 0), (0.8287801, 0), (0.8154298, 1), (0.7997357, 1), (0.7832331, 1), (0.76399314, 0), (0.74506074, 0), (0.73655915, 0), (0.63043386, 1), (0.5400416, 0), (0.51201296, 0), (0.5117951, 0), (0.49422473, 0), (0.4645291, 1), (0.42538065, 0), (0.3031433, 0), (0.27462518, 0), (0.0, 0)]
0.4
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B5438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.6780 - auc: 0.5253WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503F99F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.6746 - auc: 0.5269 - val_loss: 0.5337 - val_auc: 0.6796
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5666 - auc: 0.6038 - val_loss: 0.4403 - val_auc: 0.6878
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5482 - auc: 0.6334 - val_loss: 0.5041 - val_auc: 0.5978
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5381 - auc: 0.6116 - val_loss: 0.3630 - val_auc: 0.7059
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5125 - auc: 0.6471 - val_loss: 0.3570 - val_auc: 0.6653
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6740 - val_loss: 0.3433 - val_auc: 0.7052
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4872 - auc: 0.6809 - val_loss: 0.3218 - val_auc: 0.6642
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.6937 - val_loss: 0.3571 - val_auc: 0.6633
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4917 - auc: 0.6781 - val_loss: 0.3588 - val_auc: 0.6544
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4759 - auc: 0.6977 - val_loss: 0.3344 - val_auc: 0.6446
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.6899 - val_loss: 0.3128 - val_auc: 0.7061
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6983 - val_loss: 0.3048 - val_auc: 0.6936
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4721 - auc: 0.7318 - val_loss: 0.3133 - val_auc: 0.6798
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4776 - auc: 0.7202 - val_loss: 0.3179 - val_auc: 0.6622
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4827 - auc: 0.7075 - val_loss: 0.3083 - val_auc: 0.6484
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4645 - auc: 0.7091 - val_loss: 0.3315 - val_auc: 0.6132
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4670 - auc: 0.7085 - val_loss: 0.3116 - val_auc: 0.6598
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4669 - auc: 0.7130 - val_loss: 0.3098 - val_auc: 0.6451
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4577 - auc: 0.7252 - val_loss: 0.3227 - val_auc: 0.6279
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4650 - auc: 0.7230 - val_loss: 0.3418 - val_auc: 0.6573
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350289A4C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.83224404, 0), (0.62025124, 1), (0.60995466, 0), (0.6081209, 0), (0.60556656, 0), (0.60478944, 0), (0.5862868, 0), (0.58184016, 1), (0.5495174, 1), (0.5485587, 1), (0.54012156, 0), (0.53424585, 0), (0.52423096, 0), (0.50238925, 0), (0.48302132, 1), (0.44254473, 0), (0.38574255, 0), (0.3745759, 0), (0.3643158, 0), (0.21127312, 1), (0.17263618, 1), (0.12661998, 0), (0.110958695, 0), (0.0, 0)]
0.3
0.42857142857142855
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235030945E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/100 [============================&gt;.] - ETA: 0s - loss: 0.5428 - auc: 0.5337WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235023CF0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5415 - auc: 0.5333 - val_loss: 0.3015 - val_auc: 0.7151
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5195 - auc: 0.5900 - val_loss: 0.2836 - val_auc: 0.6333
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5180 - auc: 0.6001 - val_loss: 0.2870 - val_auc: 0.5508
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5114 - auc: 0.6228 - val_loss: 0.2770 - val_auc: 0.5437
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6735 - val_loss: 0.2840 - val_auc: 0.4976
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5072 - auc: 0.6227 - val_loss: 0.3038 - val_auc: 0.5495
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5110 - auc: 0.6551 - val_loss: 0.2814 - val_auc: 0.5595
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4994 - auc: 0.6797 - val_loss: 0.3082 - val_auc: 0.5968
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4932 - auc: 0.6647 - val_loss: 0.3004 - val_auc: 0.5783
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6644 - val_loss: 0.2937 - val_auc: 0.5704
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6612 - val_loss: 0.3006 - val_auc: 0.5571
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4817 - auc: 0.7259 - val_loss: 0.3005 - val_auc: 0.6196
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4893 - auc: 0.6970 - val_loss: 0.2873 - val_auc: 0.6392
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4892 - auc: 0.6988 - val_loss: 0.2908 - val_auc: 0.6201
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6750 - val_loss: 0.2902 - val_auc: 0.6029
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6990 - val_loss: 0.2979 - val_auc: 0.6220
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.7001 - val_loss: 0.2917 - val_auc: 0.5831
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4846 - auc: 0.7120 - val_loss: 0.2928 - val_auc: 0.5968
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4857 - auc: 0.7152 - val_loss: 0.2885 - val_auc: 0.5981
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.7012 - val_loss: 0.2818 - val_auc: 0.5566
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502EF0D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.71790105, 0), (0.69223213, 0), (0.6905617, 0), (0.6800014, 0), (0.675521, 0), (0.6735108, 0), (0.67180514, 0), (0.6712834, 0), (0.67104495, 0), (0.66569644, 0), (0.6621802, 0), (0.6599742, 0), (0.65748405, 0), (0.65693176, 0), (0.6464172, 0), (0.641615, 0), (0.63619745, 0), (0.469575, 0), (0.41578227, 0), (0.37028185, 0), (0.21847282, 0), (0.081196785, 0), (0.053024966, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023507651168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 88/100 [=========================&gt;....] - ETA: 0s - loss: 0.5584 - auc: 0.5577WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235061F85E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.5460 - auc: 0.5617 - val_loss: 0.2055 - val_auc: 0.5209
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5332 - auc: 0.5628 - val_loss: 0.2296 - val_auc: 0.7261
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5323 - auc: 0.6053 - val_loss: 0.2454 - val_auc: 0.6760
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5116 - auc: 0.6433 - val_loss: 0.2290 - val_auc: 0.6423
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6548 - val_loss: 0.2435 - val_auc: 0.6260
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5229 - auc: 0.6322 - val_loss: 0.2387 - val_auc: 0.5785
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5067 - auc: 0.6611 - val_loss: 0.2444 - val_auc: 0.6387
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6289 - val_loss: 0.2391 - val_auc: 0.6489
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6522 - val_loss: 0.2694 - val_auc: 0.7166
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.6775 - val_loss: 0.2735 - val_auc: 0.6819
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6800 - val_loss: 0.2594 - val_auc: 0.6443
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4998 - auc: 0.6602 - val_loss: 0.2643 - val_auc: 0.6823
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4953 - auc: 0.6830 - val_loss: 0.2594 - val_auc: 0.7493
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.7040 - val_loss: 0.2439 - val_auc: 0.7304
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4972 - auc: 0.6727 - val_loss: 0.2738 - val_auc: 0.6888
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4916 - auc: 0.6718 - val_loss: 0.2700 - val_auc: 0.5700
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.6813 - val_loss: 0.2916 - val_auc: 0.5609
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4714 - auc: 0.7341 - val_loss: 0.2662 - val_auc: 0.5942
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4861 - auc: 0.6880 - val_loss: 0.2824 - val_auc: 0.6420
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.7336 - val_loss: 0.2736 - val_auc: 0.6410
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.7865629, 1), (0.71643806, 0), (0.7157864, 0), (0.69905376, 0), (0.6405903, 0), (0.6279629, 1), (0.56663233, 0), (0.53694695, 1), (0.5291654, 0), (0.52310866, 0), (0.5203066, 0), (0.5188184, 0), (0.5115249, 0), (0.50782853, 0), (0.50197554, 0), (0.49796894, 1), (0.4909034, 0), (0.45958272, 0), (0.4382401, 0), (0.40660864, 0), (0.39135167, 0), (0.29321596, 0), (0.20436135, 0), (0.0, 0)]
0.4
0.8
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500A72CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.6194 - auc: 0.5336WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350301F8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.6243 - auc: 0.5266 - val_loss: 0.3864 - val_auc: 0.6165
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5255 - auc: 0.6275 - val_loss: 0.3553 - val_auc: 0.6127
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5278 - auc: 0.6215 - val_loss: 0.3646 - val_auc: 0.5520
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5088 - auc: 0.6531 - val_loss: 0.3391 - val_auc: 0.6008
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4822 - auc: 0.6838 - val_loss: 0.3681 - val_auc: 0.5691
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6755 - val_loss: 0.3496 - val_auc: 0.5426
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.6740 - val_loss: 0.3529 - val_auc: 0.5704
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6764 - val_loss: 0.3376 - val_auc: 0.6008
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.6837 - val_loss: 0.3586 - val_auc: 0.6683
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4819 - auc: 0.6828 - val_loss: 0.3477 - val_auc: 0.6734
Epoch 11/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4790 - auc: 0.6884 - val_loss: 0.3342 - val_auc: 0.6755
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4862 - auc: 0.6880 - val_loss: 0.3289 - val_auc: 0.6811
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4852 - auc: 0.6778 - val_loss: 0.3445 - val_auc: 0.5648
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4648 - auc: 0.7179 - val_loss: 0.3560 - val_auc: 0.5375
Epoch 15/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4692 - auc: 0.7159 - val_loss: 0.3115 - val_auc: 0.6083
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4759 - auc: 0.6995 - val_loss: 0.3308 - val_auc: 0.6112
Epoch 17/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4696 - auc: 0.7105 - val_loss: 0.3250 - val_auc: 0.5882
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4608 - auc: 0.7261 - val_loss: 0.3319 - val_auc: 0.5496
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4561 - auc: 0.7325 - val_loss: 0.3106 - val_auc: 0.5890
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4637 - auc: 0.7225 - val_loss: 0.3123 - val_auc: 0.5897
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502B6D948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.89478797, 0), (0.8369352, 0), (0.8330821, 0), (0.817622, 1), (0.8150531, 1), (0.81227237, 0), (0.7707065, 0), (0.76743644, 1), (0.76262164, 1), (0.7609161, 0), (0.7594225, 0), (0.7530403, 0), (0.7155842, 0), (0.6969926, 1), (0.6708667, 0), (0.6649605, 1), (0.6584576, 0), (0.64624536, 1), (0.6394381, 0), (0.557378, 0), (0.48953915, 0), (0.29078898, 1), (0.27814117, 0), (0.0, 0)]
0.4
0.5
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235594A7B88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 92/100 [==========================&gt;...] - ETA: 0s - loss: 0.6503 - auc: 0.5274WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350AB70D38&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 9ms/step - loss: 0.6476 - auc: 0.5308 - val_loss: 0.5779 - val_auc: 0.5520
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5970 - auc: 0.5987 - val_loss: 0.5028 - val_auc: 0.6214
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5692 - auc: 0.5807 - val_loss: 0.4214 - val_auc: 0.6201
Epoch 4/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5494 - auc: 0.6110 - val_loss: 0.4062 - val_auc: 0.6904
Epoch 5/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5274 - auc: 0.6642 - val_loss: 0.3844 - val_auc: 0.6934
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5448 - auc: 0.5952 - val_loss: 0.4033 - val_auc: 0.5991
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5264 - auc: 0.6397 - val_loss: 0.3742 - val_auc: 0.7405
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5129 - auc: 0.6443 - val_loss: 0.3710 - val_auc: 0.7984
Epoch 9/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5026 - auc: 0.6682 - val_loss: 0.3295 - val_auc: 0.6986
Epoch 10/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5221 - auc: 0.6217 - val_loss: 0.3380 - val_auc: 0.6855
Epoch 11/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5014 - auc: 0.6629 - val_loss: 0.3337 - val_auc: 0.7300
Epoch 12/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4874 - auc: 0.6890 - val_loss: 0.3482 - val_auc: 0.7042
Epoch 13/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4882 - auc: 0.6949 - val_loss: 0.3059 - val_auc: 0.7474
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4982 - auc: 0.6758 - val_loss: 0.3198 - val_auc: 0.7091
Epoch 15/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5016 - auc: 0.6799 - val_loss: 0.3113 - val_auc: 0.6976
Epoch 16/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4951 - auc: 0.7003 - val_loss: 0.3240 - val_auc: 0.7297
Epoch 17/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4817 - auc: 0.7165 - val_loss: 0.3000 - val_auc: 0.7071
Epoch 18/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4790 - auc: 0.6886 - val_loss: 0.3120 - val_auc: 0.6757
Epoch 19/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4870 - auc: 0.6930 - val_loss: 0.2907 - val_auc: 0.7026
Epoch 20/20
100/100 [==============================] - 1s 6ms/step - loss: 0.4979 - auc: 0.6921 - val_loss: 0.2925 - val_auc: 0.7356
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503525E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.94324106, 0), (0.91365916, 0), (0.9029327, 0), (0.90187645, 0), (0.8677104, 0), (0.85490626, 0), (0.852036, 0), (0.8299905, 0), (0.82987386, 0), (0.8281331, 0), (0.78636897, 0), (0.73979366, 0), (0.6941869, 0), (0.6446602, 0), (0.6350952, 0), (0.62953573, 0), (0.59488314, 0), (0.56016505, 0), (0.46177384, 0), (0.45386606, 0), (0.31945246, 0), (0.24794422, 0), (0.13718878, 0), (0.0, 1)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235076AFC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.5881 - auc: 0.5276WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235047B5438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 3s 8ms/step - loss: 0.5787 - auc: 0.5360 - val_loss: 0.3183 - val_auc: 0.4392
Epoch 2/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5243 - auc: 0.6096 - val_loss: 0.3545 - val_auc: 0.5196
Epoch 3/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5253 - auc: 0.6107 - val_loss: 0.3249 - val_auc: 0.4778
Epoch 4/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5282 - auc: 0.5907 - val_loss: 0.3329 - val_auc: 0.5713
Epoch 5/20
100/100 [==============================] - 1s 6ms/step - loss: 0.5102 - auc: 0.6254 - val_loss: 0.3001 - val_auc: 0.5488
Epoch 6/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5089 - auc: 0.6405 - val_loss: 0.3143 - val_auc: 0.5354
Epoch 7/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5126 - auc: 0.6378 - val_loss: 0.3116 - val_auc: 0.5249
Epoch 8/20
100/100 [==============================] - 1s 5ms/step - loss: 0.5073 - auc: 0.6573 - val_loss: 0.3039 - val_auc: 0.4713
Epoch 9/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4922 - auc: 0.6950 - val_loss: 0.3124 - val_auc: 0.5289
Epoch 10/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4864 - auc: 0.6986 - val_loss: 0.2936 - val_auc: 0.5678
Epoch 11/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4983 - auc: 0.6861 - val_loss: 0.3015 - val_auc: 0.5795
Epoch 12/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5181 - auc: 0.6327 - val_loss: 0.3211 - val_auc: 0.5813
Epoch 13/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4851 - auc: 0.6922 - val_loss: 0.3130 - val_auc: 0.5392
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4968 - auc: 0.6831 - val_loss: 0.2960 - val_auc: 0.5114
Epoch 15/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4984 - auc: 0.6880 - val_loss: 0.2963 - val_auc: 0.5529
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4890 - auc: 0.7104 - val_loss: 0.3032 - val_auc: 0.5503
Epoch 17/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4892 - auc: 0.6947 - val_loss: 0.3032 - val_auc: 0.6082
Epoch 18/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4916 - auc: 0.7067 - val_loss: 0.3185 - val_auc: 0.6275
Epoch 19/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4782 - auc: 0.7147 - val_loss: 0.3103 - val_auc: 0.5363
Epoch 20/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4809 - auc: 0.7216 - val_loss: 0.3133 - val_auc: 0.5687
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023500B7FC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.91509086, 0), (0.90174013, 0), (0.90174013, 0), (0.90174013, 0), (0.8996541, 0), (0.89743924, 0), (0.8968153, 0), (0.8966032, 0), (0.894243, 0), (0.89339197, 1), (0.890471, 0), (0.88804466, 0), (0.88450027, 0), (0.7923031, 0), (0.78740895, 0), (0.67138535, 0), (0.65438205, 0), (0.62189204, 0), (0.61741596, 0), (0.58650076, 0), (0.53239924, 0), (0.25785977, 0), (0.08967088, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503525E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 92/100 [==========================&gt;...] - ETA: 0s - loss: 0.5663 - auc: 0.5648WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502DEA3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 8ms/step - loss: 0.5662 - auc: 0.5579 - val_loss: 0.2578 - val_auc: 0.4965
Epoch 2/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5062 - auc: 0.6392 - val_loss: 0.2513 - val_auc: 0.6151
Epoch 3/20
100/100 [==============================] - 0s 5ms/step - loss: 0.5308 - auc: 0.6058 - val_loss: 0.2533 - val_auc: 0.6732
Epoch 4/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4923 - auc: 0.6597 - val_loss: 0.2589 - val_auc: 0.6100
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4999 - auc: 0.6333 - val_loss: 0.2569 - val_auc: 0.6120
Epoch 6/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4893 - auc: 0.6533 - val_loss: 0.2609 - val_auc: 0.5618
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6466 - val_loss: 0.2683 - val_auc: 0.5736
Epoch 8/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4981 - auc: 0.6318 - val_loss: 0.2894 - val_auc: 0.5693
Epoch 9/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4897 - auc: 0.6390 - val_loss: 0.2776 - val_auc: 0.4869
Epoch 10/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4823 - auc: 0.6147 - val_loss: 0.2753 - val_auc: 0.6234
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4611 - auc: 0.7073 - val_loss: 0.2772 - val_auc: 0.5886
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4858 - auc: 0.6743 - val_loss: 0.2698 - val_auc: 0.6131
Epoch 13/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4839 - auc: 0.6671 - val_loss: 0.2872 - val_auc: 0.5357
Epoch 14/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4796 - auc: 0.6516 - val_loss: 0.2883 - val_auc: 0.5124
Epoch 15/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4691 - auc: 0.6928 - val_loss: 0.2856 - val_auc: 0.6017
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4574 - auc: 0.7078 - val_loss: 0.2810 - val_auc: 0.6237
Epoch 17/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4641 - auc: 0.6779 - val_loss: 0.2942 - val_auc: 0.5844
Epoch 18/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4646 - auc: 0.7067 - val_loss: 0.2900 - val_auc: 0.5732
Epoch 19/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4716 - auc: 0.6905 - val_loss: 0.2820 - val_auc: 0.4865
Epoch 20/20
100/100 [==============================] - 1s 5ms/step - loss: 0.4738 - auc: 0.6958 - val_loss: 0.2907 - val_auc: 0.5328
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503BD9C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.97561103, 0), (0.9595862, 0), (0.69729626, 0), (0.6020841, 1), (0.58099884, 0), (0.5711366, 0), (0.5091802, 0), (0.5031397, 0), (0.48042998, 1), (0.44886437, 1), (0.4188916, 0), (0.41540417, 0), (0.39306194, 1), (0.38683033, 1), (0.3706593, 1), (0.36407948, 0), (0.33539584, 0), (0.33251774, 0), (0.3132531, 0), (0.3044291, 0), (0.23651065, 1), (0.19279435, 1), (0.095146246, 0), (0.0, 0)]
0.2222222222222222
0.2222222222222222
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/100 [==========================&gt;...] - ETA: 0s - loss: 0.5750 - auc: 0.4975WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023509CD81F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 10ms/step - loss: 0.5684 - auc: 0.5120 - val_loss: 0.3527 - val_auc: 0.5640
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5149 - auc: 0.6195 - val_loss: 0.3612 - val_auc: 0.6016
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5200 - auc: 0.6439 - val_loss: 0.3584 - val_auc: 0.5939
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4966 - auc: 0.6805 - val_loss: 0.3121 - val_auc: 0.6421
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4918 - auc: 0.6885 - val_loss: 0.3054 - val_auc: 0.6140
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.6994 - val_loss: 0.3006 - val_auc: 0.4995
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5052 - auc: 0.6703 - val_loss: 0.2994 - val_auc: 0.5206
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4958 - auc: 0.6774 - val_loss: 0.3084 - val_auc: 0.6124
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4921 - auc: 0.7011 - val_loss: 0.3028 - val_auc: 0.6196
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6851 - val_loss: 0.3167 - val_auc: 0.5429
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4960 - auc: 0.6880 - val_loss: 0.3010 - val_auc: 0.5217
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4852 - auc: 0.7108 - val_loss: 0.3032 - val_auc: 0.5915
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6880 - val_loss: 0.3016 - val_auc: 0.6016
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4924 - auc: 0.6814 - val_loss: 0.3005 - val_auc: 0.5968
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4751 - auc: 0.7315 - val_loss: 0.2989 - val_auc: 0.6058
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.7228 - val_loss: 0.2914 - val_auc: 0.6283
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7157 - val_loss: 0.3142 - val_auc: 0.5698
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4971 - auc: 0.6986 - val_loss: 0.3055 - val_auc: 0.5939
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4860 - auc: 0.7159 - val_loss: 0.2995 - val_auc: 0.5701
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4756 - auc: 0.7165 - val_loss: 0.3028 - val_auc: 0.5455
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350239A288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9854684, 0), (0.95198804, 0), (0.87867653, 0), (0.85208595, 0), (0.7836517, 0), (0.7624911, 0), (0.74890584, 0), (0.73550415, 0), (0.7316311, 0), (0.7247305, 0), (0.6972171, 0), (0.69564563, 0), (0.67071587, 0), (0.6593942, 0), (0.61185426, 0), (0.5493871, 0), (0.54325825, 0), (0.5000902, 0), (0.43837553, 0), (0.4293773, 0), (0.30603427, 0), (0.30321175, 0), (0.22268292, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/100 [==========================&gt;...] - ETA: 0s - loss: 0.6514 - auc: 0.5532WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235098E0C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.6595 - auc: 0.5491 - val_loss: 0.5491 - val_auc: 0.4114
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5714 - auc: 0.6063 - val_loss: 0.5077 - val_auc: 0.5659
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5328 - auc: 0.6394 - val_loss: 0.4268 - val_auc: 0.4587
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5435 - auc: 0.6298 - val_loss: 0.4431 - val_auc: 0.5500
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5177 - auc: 0.6504 - val_loss: 0.4792 - val_auc: 0.4664
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5227 - auc: 0.6540 - val_loss: 0.4920 - val_auc: 0.5812
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5101 - auc: 0.6698 - val_loss: 0.4413 - val_auc: 0.5558
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5178 - auc: 0.6571 - val_loss: 0.4336 - val_auc: 0.5063
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6808 - val_loss: 0.4455 - val_auc: 0.5664
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.6984 - val_loss: 0.3982 - val_auc: 0.5563
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4751 - auc: 0.6941 - val_loss: 0.3824 - val_auc: 0.5595
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4722 - auc: 0.7102 - val_loss: 0.3544 - val_auc: 0.6082
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4868 - auc: 0.6922 - val_loss: 0.3729 - val_auc: 0.5587
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4670 - auc: 0.7227 - val_loss: 0.3487 - val_auc: 0.5894
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4739 - auc: 0.7070 - val_loss: 0.3801 - val_auc: 0.5164
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4707 - auc: 0.7125 - val_loss: 0.3424 - val_auc: 0.5701
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6719 - val_loss: 0.3792 - val_auc: 0.6024
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4729 - auc: 0.7043 - val_loss: 0.3386 - val_auc: 0.5656
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4809 - auc: 0.7025 - val_loss: 0.3343 - val_auc: 0.5624
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4700 - auc: 0.7154 - val_loss: 0.3298 - val_auc: 0.6095
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023500B7FC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9840782, 0), (0.9828613, 1), (0.9757781, 0), (0.9479068, 0), (0.9424208, 0), (0.93937224, 0), (0.9374306, 0), (0.9365086, 0), (0.93462443, 0), (0.93196034, 0), (0.91203725, 0), (0.9110368, 0), (0.84020776, 1), (0.82314885, 1), (0.7470741, 1), (0.7160459, 0), (0.6923361, 0), (0.60977954, 0), (0.47832724, 1), (0.43285674, 0), (0.34017685, 1), (0.28419042, 0), (0.25737944, 0), (0.0, 1)]
0.2
0.25
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023CFC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 89/100 [=========================&gt;....] - ETA: 0s - loss: 0.4935 - auc: 0.5199WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504C01E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.4840 - auc: 0.5314 - val_loss: 0.3609 - val_auc: 0.3681
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.5773 - val_loss: 0.3488 - val_auc: 0.5722
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.5832 - val_loss: 0.3682 - val_auc: 0.5392
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.6145 - val_loss: 0.3521 - val_auc: 0.5851
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4752 - auc: 0.5998 - val_loss: 0.3639 - val_auc: 0.5490
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4662 - auc: 0.6134 - val_loss: 0.3754 - val_auc: 0.5243
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4542 - auc: 0.6652 - val_loss: 0.3781 - val_auc: 0.5384
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4593 - auc: 0.6677 - val_loss: 0.3841 - val_auc: 0.5448
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4550 - auc: 0.6789 - val_loss: 0.3890 - val_auc: 0.5456
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4614 - auc: 0.6585 - val_loss: 0.3705 - val_auc: 0.6007
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4527 - auc: 0.6844 - val_loss: 0.3743 - val_auc: 0.6102
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4538 - auc: 0.6697 - val_loss: 0.3800 - val_auc: 0.6058
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4499 - auc: 0.6783 - val_loss: 0.3866 - val_auc: 0.5970
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4447 - auc: 0.7058 - val_loss: 0.3820 - val_auc: 0.5902
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4549 - auc: 0.6774 - val_loss: 0.3813 - val_auc: 0.5860
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4480 - auc: 0.6945 - val_loss: 0.3852 - val_auc: 0.5835
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4505 - auc: 0.6795 - val_loss: 0.3808 - val_auc: 0.5788
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4399 - auc: 0.7093 - val_loss: 0.3841 - val_auc: 0.5785
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4569 - auc: 0.6792 - val_loss: 0.3845 - val_auc: 0.5958
Epoch 20/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4465 - auc: 0.7061 - val_loss: 0.3942 - val_auc: 0.5912
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350282B948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9519513, 1), (0.8274808, 0), (0.8120191, 1), (0.8092806, 0), (0.73617595, 1), (0.61974007, 0), (0.61173946, 1), (0.61173946, 1), (0.60175323, 1), (0.5716518, 1), (0.56065613, 1), (0.54720277, 0), (0.5398949, 1), (0.51558626, 1), (0.47060695, 1), (0.3205038, 1), (0.29979968, 0), (0.2251038, 0), (0.16484423, 1), (0.093620636, 1), (0.03713167, 1), (0.004460565, 1), (0.002478326, 1), (0.0, 1)]
0.6
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504911798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 89/100 [=========================&gt;....] - ETA: 0s - loss: 0.5385 - auc: 0.5464WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504AB7948&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.5437 - auc: 0.5353 - val_loss: 0.2712 - val_auc: 0.5008
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5227 - auc: 0.5518 - val_loss: 0.2759 - val_auc: 0.5997
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.6231 - val_loss: 0.3059 - val_auc: 0.5526
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4952 - auc: 0.6387 - val_loss: 0.2875 - val_auc: 0.5323
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6456 - val_loss: 0.2872 - val_auc: 0.4714
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6399 - val_loss: 0.3016 - val_auc: 0.4923
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6498 - val_loss: 0.2858 - val_auc: 0.5307
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6675 - val_loss: 0.2858 - val_auc: 0.5201
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4839 - auc: 0.6814 - val_loss: 0.2867 - val_auc: 0.5296
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.6854 - val_loss: 0.3053 - val_auc: 0.4183
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5129 - auc: 0.6324 - val_loss: 0.2914 - val_auc: 0.4659
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4770 - auc: 0.6907 - val_loss: 0.2928 - val_auc: 0.3918
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.7025 - val_loss: 0.2951 - val_auc: 0.4209
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6743 - val_loss: 0.2929 - val_auc: 0.4590
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4607 - auc: 0.7038 - val_loss: 0.3121 - val_auc: 0.5048
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4808 - auc: 0.6945 - val_loss: 0.3018 - val_auc: 0.5952
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4709 - auc: 0.7233 - val_loss: 0.2978 - val_auc: 0.5095
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4706 - auc: 0.7249 - val_loss: 0.2918 - val_auc: 0.5450
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4581 - auc: 0.7393 - val_loss: 0.2905 - val_auc: 0.4926
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4798 - auc: 0.7086 - val_loss: 0.2673 - val_auc: 0.5407
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235021703A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99937224, 0), (0.878419, 0), (0.87331825, 1), (0.852318, 0), (0.84430426, 1), (0.84174514, 0), (0.84174514, 0), (0.84174514, 0), (0.84174514, 0), (0.84174514, 1), (0.84174514, 1), (0.8283881, 0), (0.79247904, 0), (0.78591, 0), (0.7702651, 0), (0.7563303, 0), (0.7527828, 0), (0.71835023, 1), (0.6655137, 0), (0.3838243, 0), (0.122082435, 0), (0.08719824, 1), (4.2580567e-05, 0), (0.0, 1)]
0.2
0.2857142857142857
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235076519D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/100 [============================&gt;.] - ETA: 0s - loss: 0.5340 - auc: 0.5337WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500B7F0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5341 - auc: 0.5334 - val_loss: 0.2930 - val_auc: 0.5882
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5135 - auc: 0.6093 - val_loss: 0.2570 - val_auc: 0.6391
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5133 - auc: 0.6324 - val_loss: 0.2688 - val_auc: 0.6235
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5056 - auc: 0.6474 - val_loss: 0.2751 - val_auc: 0.7031
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5218 - auc: 0.6281 - val_loss: 0.2666 - val_auc: 0.6373
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4998 - auc: 0.6644 - val_loss: 0.3091 - val_auc: 0.5108
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5018 - auc: 0.6555 - val_loss: 0.2936 - val_auc: 0.5149
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6857 - val_loss: 0.2835 - val_auc: 0.6771
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4962 - auc: 0.6865 - val_loss: 0.2876 - val_auc: 0.5569
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4880 - auc: 0.7001 - val_loss: 0.2849 - val_auc: 0.5770
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.7085 - val_loss: 0.2539 - val_auc: 0.6350
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6631 - val_loss: 0.2854 - val_auc: 0.6239
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6784 - val_loss: 0.2889 - val_auc: 0.5711
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.7032 - val_loss: 0.2942 - val_auc: 0.6057
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4730 - auc: 0.7345 - val_loss: 0.2693 - val_auc: 0.6618
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4865 - auc: 0.7038 - val_loss: 0.2506 - val_auc: 0.6882
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6758 - val_loss: 0.2771 - val_auc: 0.6097
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4799 - auc: 0.7260 - val_loss: 0.2885 - val_auc: 0.5848
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4845 - auc: 0.7019 - val_loss: 0.2597 - val_auc: 0.6228
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4668 - auc: 0.7358 - val_loss: 0.2708 - val_auc: 0.6406
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235098E0288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9608469, 0), (0.9458595, 0), (0.8739918, 0), (0.8691238, 0), (0.86788785, 0), (0.85632694, 1), (0.8474568, 0), (0.76737833, 0), (0.75095636, 0), (0.7442714, 0), (0.7397814, 0), (0.7379058, 0), (0.7189996, 0), (0.71827865, 0), (0.7126965, 0), (0.6656585, 0), (0.65328646, 0), (0.62281597, 0), (0.53509915, 0), (0.49004468, 1), (0.48575264, 0), (0.43204415, 0), (0.31224826, 1), (0.0, 0)]
0.1
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B5438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/100 [=========================&gt;....] - ETA: 0s - loss: 0.5371 - auc: 0.5493WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350233B3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 1s 6ms/step - loss: 0.5369 - auc: 0.5516 - val_loss: 0.3067 - val_auc: 0.4483
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5338 - auc: 0.5463 - val_loss: 0.2942 - val_auc: 0.5126
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5268 - auc: 0.5661 - val_loss: 0.3021 - val_auc: 0.4118
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5244 - auc: 0.5620 - val_loss: 0.2829 - val_auc: 0.4710
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5139 - auc: 0.5964 - val_loss: 0.2790 - val_auc: 0.4665
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5024 - auc: 0.6383 - val_loss: 0.2679 - val_auc: 0.4550
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5122 - auc: 0.6149 - val_loss: 0.2719 - val_auc: 0.5074
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5185 - auc: 0.6171 - val_loss: 0.2710 - val_auc: 0.4661
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5041 - auc: 0.6451 - val_loss: 0.2690 - val_auc: 0.4714
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4911 - auc: 0.6412 - val_loss: 0.2619 - val_auc: 0.4754
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4980 - auc: 0.6594 - val_loss: 0.2709 - val_auc: 0.4721
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5046 - auc: 0.6519 - val_loss: 0.2937 - val_auc: 0.5357
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5093 - auc: 0.6488 - val_loss: 0.2801 - val_auc: 0.5339
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5005 - auc: 0.6567 - val_loss: 0.2617 - val_auc: 0.5469
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5045 - auc: 0.6364 - val_loss: 0.2814 - val_auc: 0.5510
Epoch 16/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6546 - val_loss: 0.2728 - val_auc: 0.5543
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4955 - auc: 0.6715 - val_loss: 0.2780 - val_auc: 0.5592
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4929 - auc: 0.6859 - val_loss: 0.2847 - val_auc: 0.5714
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6695 - val_loss: 0.2733 - val_auc: 0.5696
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6731 - val_loss: 0.2773 - val_auc: 0.5368
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350301FCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99434525, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 1), (0.9883565, 1), (0.9883565, 1), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.9883565, 0), (0.864102, 0), (0.79796076, 0), (0.65704775, 0), (0.33969477, 0), (0.22564894, 0), (0.18521059, 0), (0.0, 0)]
0.3
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023558298558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/100 [==========================&gt;...] - ETA: 0s - loss: 0.5400 - auc: 0.5710WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502FB0F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/100 [==============================] - 2s 6ms/step - loss: 0.5310 - auc: 0.5725 - val_loss: 0.2192 - val_auc: 0.6097
Epoch 2/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5167 - auc: 0.6173 - val_loss: 0.2324 - val_auc: 0.6090
Epoch 3/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5171 - auc: 0.6237 - val_loss: 0.2425 - val_auc: 0.5595
Epoch 4/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5172 - auc: 0.6312 - val_loss: 0.2453 - val_auc: 0.5476
Epoch 5/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5146 - auc: 0.6384 - val_loss: 0.2453 - val_auc: 0.5952
Epoch 6/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5105 - auc: 0.6647 - val_loss: 0.2421 - val_auc: 0.5711
Epoch 7/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5135 - auc: 0.6575 - val_loss: 0.2429 - val_auc: 0.6916
Epoch 8/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6695 - val_loss: 0.2527 - val_auc: 0.7228
Epoch 9/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6519 - val_loss: 0.2752 - val_auc: 0.6127
Epoch 10/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6718 - val_loss: 0.2720 - val_auc: 0.5647
Epoch 11/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4827 - auc: 0.7197 - val_loss: 0.2585 - val_auc: 0.5885
Epoch 12/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4970 - auc: 0.6885 - val_loss: 0.2558 - val_auc: 0.6362
Epoch 13/20
100/100 [==============================] - 0s 4ms/step - loss: 0.5051 - auc: 0.6805 - val_loss: 0.2696 - val_auc: 0.5956
Epoch 14/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6914 - val_loss: 0.2932 - val_auc: 0.5859
Epoch 15/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6940 - val_loss: 0.2704 - val_auc: 0.5882
Epoch 16/20
100/100 [==============================] - 0s 5ms/step - loss: 0.4753 - auc: 0.7379 - val_loss: 0.2729 - val_auc: 0.6507
Epoch 17/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6976 - val_loss: 0.2588 - val_auc: 0.6317
Epoch 18/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.7035 - val_loss: 0.2692 - val_auc: 0.6403
Epoch 19/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6986 - val_loss: 0.2662 - val_auc: 0.6004
Epoch 20/20
100/100 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6995 - val_loss: 0.2881 - val_auc: 0.6031
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235080D3DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7510498, 0), (0.5410068, 0), (0.5234181, 0), (0.5213833, 0), (0.48509333, 0), (0.45684257, 0), (0.44472566, 0), (0.42819965, 1), (0.42110363, 0), (0.42091057, 0), (0.4194391, 0), (0.41919586, 0), (0.41865194, 0), (0.39501035, 0), (0.38583273, 0), (0.3242873, 0), (0.31563205, 0), (0.30783346, 0), (0.24985251, 0), (0.2349917, 0), (0.17102496, 1), (0.15212382, 0), (0.014056461, 0), (0.0, 0)]
0.0
0.0
Siam
[0.5, 0.0, 0.1, 0.0, 0.0, 0.4, 0.3, 0.0, 0.4, 0.4, 0.0, 0.0, 0.2222222222222222, 0.0, 0.2, 0.6, 0.2, 0.1, 0.3, 0.0]
0.18611111111111112
[0.7142857142857143, 0.0, 1.0, -1.0, 0.0, 0.5, 0.42857142857142855, -1.0, 0.8, 0.5, 0.0, 0.0, 0.2222222222222222, -1.0, 0.25, 0.3333333333333333, 0.2857142857142857, 0.3333333333333333, 1.0, 0.0]
0.3745564892623716
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[18]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">testEverythingGroupSIAM</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span><span class="s2">&quot;id_user&quot;</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mf">0.75</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>LeaveOneGroupOut()
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350233B048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - ETA: 0s - loss: 0.5179 - auc: 0.5778WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502B6D8B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5179 - auc: 0.5778 - val_loss: 0.2911 - val_auc: 0.4106
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6284 - val_loss: 0.2982 - val_auc: 0.4471
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4944 - auc: 0.6265 - val_loss: 0.2937 - val_auc: 0.5494
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4823 - auc: 0.6506 - val_loss: 0.3128 - val_auc: 0.4772
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4860 - auc: 0.6476 - val_loss: 0.3050 - val_auc: 0.4904
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.6585 - val_loss: 0.3095 - val_auc: 0.4457
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4876 - auc: 0.6278 - val_loss: 0.3069 - val_auc: 0.4716
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.6385 - val_loss: 0.3159 - val_auc: 0.3313
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4779 - auc: 0.7053 - val_loss: 0.3101 - val_auc: 0.3649
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4694 - auc: 0.7034 - val_loss: 0.3208 - val_auc: 0.4298
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.6292 - val_loss: 0.3157 - val_auc: 0.4123
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.6859 - val_loss: 0.3133 - val_auc: 0.3459
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4675 - auc: 0.6933 - val_loss: 0.3155 - val_auc: 0.3384
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4633 - auc: 0.6941 - val_loss: 0.3144 - val_auc: 0.4609
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4787 - auc: 0.6880 - val_loss: 0.3215 - val_auc: 0.4724
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4692 - auc: 0.7000 - val_loss: 0.3138 - val_auc: 0.3962
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.6742 - val_loss: 0.3146 - val_auc: 0.3421
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4635 - auc: 0.7008 - val_loss: 0.3144 - val_auc: 0.4570
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4664 - auc: 0.7015 - val_loss: 0.3149 - val_auc: 0.3599
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4757 - auc: 0.6920 - val_loss: 0.3177 - val_auc: 0.3103
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235036DB0D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.22446252, 1), (0.046251614, 0), (0.0, 1), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 0), (0.0, 1), (0.0, 1)]
1.0
0.2
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503880438&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 90/101 [=========================&gt;....] - ETA: 0s - loss: 0.5445 - auc: 0.5370 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235035258B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5316 - auc: 0.5489 - val_loss: 0.3525 - val_auc: 0.6697
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5173 - auc: 0.6066 - val_loss: 0.3771 - val_auc: 0.3374
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4950 - auc: 0.6401 - val_loss: 0.3520 - val_auc: 0.4383
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5009 - auc: 0.6431 - val_loss: 0.3618 - val_auc: 0.7143
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6474 - val_loss: 0.3595 - val_auc: 0.3928
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4909 - auc: 0.6785 - val_loss: 0.3555 - val_auc: 0.4090
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4796 - auc: 0.6748 - val_loss: 0.3329 - val_auc: 0.6435
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6601 - val_loss: 0.3424 - val_auc: 0.7206
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6732 - val_loss: 0.3171 - val_auc: 0.5140
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.6752 - val_loss: 0.3230 - val_auc: 0.4214
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4923 - auc: 0.6857 - val_loss: 0.3270 - val_auc: 0.5511
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4908 - auc: 0.6749 - val_loss: 0.3380 - val_auc: 0.4931
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4769 - auc: 0.7124 - val_loss: 0.3206 - val_auc: 0.5999
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4829 - auc: 0.6993 - val_loss: 0.3248 - val_auc: 0.5987
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6811 - val_loss: 0.3138 - val_auc: 0.6996
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4785 - auc: 0.6885 - val_loss: 0.3332 - val_auc: 0.6585
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4747 - auc: 0.6956 - val_loss: 0.3153 - val_auc: 0.6587
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.6944 - val_loss: 0.3321 - val_auc: 0.5922
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4738 - auc: 0.7175 - val_loss: 0.3263 - val_auc: 0.5871
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4774 - auc: 0.7116 - val_loss: 0.3219 - val_auc: 0.5466
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235076519D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99426365, 0), (0.98927224, 0), (0.9834114, 1), (0.94667166, 0), (0.9329299, 0), (0.82447946, 1), (0.78447944, 0), (0.76440537, 0), (0.7455931, 0), (0.64147824, 0), (0.5845578, 0), (0.0, 0)]
0.2
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023504723AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 96/101 [===========================&gt;..] - ETA: 0s - loss: 0.5904 - auc: 0.4935WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235098E00D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5917 - auc: 0.4963 - val_loss: 0.3905 - val_auc: 0.5876
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5458 - auc: 0.5682 - val_loss: 0.3744 - val_auc: 0.5586
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5198 - auc: 0.6011 - val_loss: 0.3156 - val_auc: 0.5035
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6656 - val_loss: 0.3229 - val_auc: 0.5741
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5097 - auc: 0.6475 - val_loss: 0.3116 - val_auc: 0.6334
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5023 - auc: 0.6496 - val_loss: 0.3169 - val_auc: 0.6263
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6546 - val_loss: 0.3208 - val_auc: 0.5496
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5061 - auc: 0.6611 - val_loss: 0.3078 - val_auc: 0.5203
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.6892 - val_loss: 0.3030 - val_auc: 0.6018
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6620 - val_loss: 0.3477 - val_auc: 0.5606
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4943 - auc: 0.6632 - val_loss: 0.3161 - val_auc: 0.5976
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4871 - auc: 0.7080 - val_loss: 0.3231 - val_auc: 0.5174
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6752 - val_loss: 0.2935 - val_auc: 0.5880
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4935 - auc: 0.6550 - val_loss: 0.2936 - val_auc: 0.5602
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6870 - val_loss: 0.3208 - val_auc: 0.5689
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4851 - auc: 0.6860 - val_loss: 0.3157 - val_auc: 0.5683
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4874 - auc: 0.7002 - val_loss: 0.3045 - val_auc: 0.5670
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4821 - auc: 0.7191 - val_loss: 0.3075 - val_auc: 0.5470
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4747 - auc: 0.7204 - val_loss: 0.3206 - val_auc: 0.6079
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.7135 - val_loss: 0.3250 - val_auc: 0.6128
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350301FAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7191178, 0), (0.71906203, 0), (0.6970959, 0), (0.6496104, 0), (0.64793855, 0), (0.6374941, 0), (0.6347328, 0), (0.6338169, 0), (0.5406498, 0), (0.45196357, 1), (0.36596188, 0), (0.0, 0)]
0.0
0.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350289A318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 94/101 [==========================&gt;...] - ETA: 0s - loss: 0.5840 - auc: 0.5146WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350282BB88&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5784 - auc: 0.5125 - val_loss: 0.3690 - val_auc: 0.6633
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5319 - auc: 0.5944 - val_loss: 0.3513 - val_auc: 0.6073
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5149 - auc: 0.6268 - val_loss: 0.3609 - val_auc: 0.6443
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5188 - auc: 0.6546 - val_loss: 0.3604 - val_auc: 0.5925
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5120 - auc: 0.6492 - val_loss: 0.2940 - val_auc: 0.5995
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5079 - auc: 0.6508 - val_loss: 0.3109 - val_auc: 0.6401
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4988 - auc: 0.6987 - val_loss: 0.3341 - val_auc: 0.5812
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.6940 - val_loss: 0.3387 - val_auc: 0.6382
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4925 - auc: 0.6912 - val_loss: 0.3184 - val_auc: 0.5909
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4832 - auc: 0.6984 - val_loss: 0.3134 - val_auc: 0.6211
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4792 - auc: 0.6971 - val_loss: 0.2939 - val_auc: 0.6572
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4937 - auc: 0.6743 - val_loss: 0.3162 - val_auc: 0.6392
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6831 - val_loss: 0.2960 - val_auc: 0.6482
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4904 - auc: 0.7018 - val_loss: 0.3060 - val_auc: 0.5699
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4963 - auc: 0.6792 - val_loss: 0.2881 - val_auc: 0.6131
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.7203 - val_loss: 0.2918 - val_auc: 0.5983
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4775 - auc: 0.7173 - val_loss: 0.3008 - val_auc: 0.6086
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4849 - auc: 0.7022 - val_loss: 0.3038 - val_auc: 0.5583
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4961 - auc: 0.6896 - val_loss: 0.3087 - val_auc: 0.5164
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.7229 - val_loss: 0.3057 - val_auc: 0.6144
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235047B5558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9123384, 1), (0.7934478, 0), (0.69850576, 0), (0.6425494, 0), (0.5842467, 0), (0.57912785, 0), (0.5772542, 1), (0.57528055, 0), (0.5652502, 0), (0.5404717, 0), (0.4275859, 0), (0.0, 0)]
0.2
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235061F8DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/101 [===========================&gt;..] - ETA: 0s - loss: 0.5048 - auc: 0.6175WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350812FDC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.5092 - auc: 0.6088 - val_loss: 0.2633 - val_auc: 0.3943
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5003 - auc: 0.5970 - val_loss: 0.2725 - val_auc: 0.5964
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5113 - auc: 0.6179 - val_loss: 0.2767 - val_auc: 0.5216
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6823 - val_loss: 0.2653 - val_auc: 0.6398
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6655 - val_loss: 0.3045 - val_auc: 0.6141
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4831 - auc: 0.6819 - val_loss: 0.3112 - val_auc: 0.7253
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4978 - auc: 0.6657 - val_loss: 0.2767 - val_auc: 0.7208
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4975 - auc: 0.6779 - val_loss: 0.2956 - val_auc: 0.6732
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6716 - val_loss: 0.2960 - val_auc: 0.5461
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4721 - auc: 0.7228 - val_loss: 0.2950 - val_auc: 0.6880
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7293 - val_loss: 0.2722 - val_auc: 0.6201
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.6804 - val_loss: 0.3175 - val_auc: 0.5974
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4661 - auc: 0.7340 - val_loss: 0.2949 - val_auc: 0.6008
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4882 - auc: 0.7049 - val_loss: 0.3036 - val_auc: 0.5870
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4827 - auc: 0.7024 - val_loss: 0.3046 - val_auc: 0.6284
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.7102 - val_loss: 0.3119 - val_auc: 0.6430
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4753 - auc: 0.6973 - val_loss: 0.3032 - val_auc: 0.5872
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4813 - auc: 0.7281 - val_loss: 0.3206 - val_auc: 0.5706
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4664 - auc: 0.7365 - val_loss: 0.3074 - val_auc: 0.6107
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4727 - auc: 0.7281 - val_loss: 0.3086 - val_auc: 0.6518
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502DEAC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.85287315, 0), (0.61751825, 0), (0.60963684, 1), (0.6084808, 0), (0.5761623, 0), (0.57613766, 0), (0.5451832, 0), (0.43712363, 0), (0.3958424, 0), (0.38524523, 0), (0.11174412, 0), (0.0, 0)]
0.125
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x000002350282B3A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 97/101 [===========================&gt;..] - ETA: 0s - loss: 0.8088 - auc: 0.5267WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF08B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.8041 - auc: 0.5292 - val_loss: 0.7454 - val_auc: 0.5638
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6351 - auc: 0.6223 - val_loss: 0.7640 - val_auc: 0.6979
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6554 - auc: 0.5942 - val_loss: 0.5452 - val_auc: 0.5706
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5969 - auc: 0.6450 - val_loss: 0.7788 - val_auc: 0.7068
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5764 - auc: 0.6390 - val_loss: 0.6482 - val_auc: 0.5911
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5853 - auc: 0.6386 - val_loss: 0.6544 - val_auc: 0.6758
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5336 - auc: 0.6561 - val_loss: 0.8629 - val_auc: 0.6206
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5361 - auc: 0.6629 - val_loss: 0.7387 - val_auc: 0.6836
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5280 - auc: 0.6616 - val_loss: 0.6195 - val_auc: 0.6594
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5073 - auc: 0.6836 - val_loss: 0.6144 - val_auc: 0.5815
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5419 - auc: 0.6358 - val_loss: 0.5257 - val_auc: 0.6557
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4957 - auc: 0.7004 - val_loss: 0.5811 - val_auc: 0.6638
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4995 - auc: 0.6868 - val_loss: 0.5146 - val_auc: 0.6440
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5194 - auc: 0.6554 - val_loss: 0.5471 - val_auc: 0.6591
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4791 - auc: 0.7002 - val_loss: 0.4861 - val_auc: 0.6758
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.6928 - val_loss: 0.4698 - val_auc: 0.6732
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6832 - val_loss: 0.4691 - val_auc: 0.6602
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4804 - auc: 0.7013 - val_loss: 0.4478 - val_auc: 0.6674
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4704 - auc: 0.7175 - val_loss: 0.4823 - val_auc: 0.6779
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4668 - auc: 0.7348 - val_loss: 0.4342 - val_auc: 0.6638
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235098E03A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.95637596, 1), (0.90480125, 0), (0.8779312, 1), (0.8449173, 0), (0.81863457, 0), (0.8184833, 1), (0.7496579, 1), (0.7257134, 1), (0.60086536, 0), (0.5592924, 1), (0.36356872, 0), (0.0, 0)]
0.5
0.8333333333333334
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023508324CA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/101 [==========================&gt;...] - ETA: 0s - loss: 0.8100 - auc: 0.5138WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350A161048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.8057 - auc: 0.5175 - val_loss: 0.6083 - val_auc: 0.6207
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.6571 - auc: 0.5418 - val_loss: 0.5287 - val_auc: 0.6795
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5885 - auc: 0.6065 - val_loss: 0.5529 - val_auc: 0.6229
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5525 - auc: 0.6312 - val_loss: 0.5699 - val_auc: 0.6262
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5464 - auc: 0.6318 - val_loss: 0.5836 - val_auc: 0.6606
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5234 - auc: 0.6557 - val_loss: 0.5100 - val_auc: 0.6689
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.7008 - val_loss: 0.5324 - val_auc: 0.6925
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.6948 - val_loss: 0.4879 - val_auc: 0.7536
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6635 - val_loss: 0.5059 - val_auc: 0.6406
Epoch 10/20
101/101 [==============================] - ETA: 0s - loss: 0.4857 - auc: 0.695 - 0s 4ms/step - loss: 0.4803 - auc: 0.6974 - val_loss: 0.4432 - val_auc: 0.6748
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5014 - auc: 0.6634 - val_loss: 0.4706 - val_auc: 0.6644
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4607 - auc: 0.7228 - val_loss: 0.4036 - val_auc: 0.6416
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4987 - auc: 0.6635 - val_loss: 0.4442 - val_auc: 0.6284
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4807 - auc: 0.6769 - val_loss: 0.4115 - val_auc: 0.6795
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4675 - auc: 0.7197 - val_loss: 0.4174 - val_auc: 0.6380
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4654 - auc: 0.7106 - val_loss: 0.3932 - val_auc: 0.6573
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4721 - auc: 0.6976 - val_loss: 0.4048 - val_auc: 0.6783
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4692 - auc: 0.6967 - val_loss: 0.4194 - val_auc: 0.6644
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4683 - auc: 0.7216 - val_loss: 0.3814 - val_auc: 0.6819
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4529 - auc: 0.7402 - val_loss: 0.3725 - val_auc: 0.6608
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503525E58&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.7170382, 0), (0.71615195, 0), (0.7075016, 0), (0.67249763, 0), (0.596641, 1), (0.48648542, 0), (0.37795088, 0), (0.3156726, 1), (0.18156753, 1), (0.16925488, 0), (0.10409547, 1), (0.0, 1)]
0.3333333333333333
0.3333333333333333
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023506224AF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/101 [==========================&gt;...] - ETA: 0s - loss: 0.6129 - auc: 0.5197WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235047B5558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.6140 - auc: 0.5222 - val_loss: 0.4029 - val_auc: 0.6833
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5612 - auc: 0.5475 - val_loss: 0.3736 - val_auc: 0.4665
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5286 - auc: 0.6002 - val_loss: 0.3943 - val_auc: 0.4272
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5205 - auc: 0.6524 - val_loss: 0.3755 - val_auc: 0.5197
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6515 - val_loss: 0.3514 - val_auc: 0.4659
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4983 - auc: 0.6635 - val_loss: 0.3316 - val_auc: 0.4249
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5008 - auc: 0.6618 - val_loss: 0.3205 - val_auc: 0.4214
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4754 - auc: 0.7129 - val_loss: 0.3204 - val_auc: 0.5016
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6947 - val_loss: 0.3336 - val_auc: 0.4420
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4907 - auc: 0.6787 - val_loss: 0.3018 - val_auc: 0.4913
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4968 - auc: 0.6721 - val_loss: 0.3154 - val_auc: 0.4610
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4910 - auc: 0.6852 - val_loss: 0.3095 - val_auc: 0.5467
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4920 - auc: 0.6916 - val_loss: 0.3153 - val_auc: 0.5377
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4860 - auc: 0.6954 - val_loss: 0.2942 - val_auc: 0.5954
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4773 - auc: 0.7121 - val_loss: 0.2794 - val_auc: 0.4907
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4803 - auc: 0.7121 - val_loss: 0.2896 - val_auc: 0.5151
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4810 - auc: 0.7048 - val_loss: 0.3066 - val_auc: 0.5058
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4787 - auc: 0.7255 - val_loss: 0.2816 - val_auc: 0.6253
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4787 - auc: 0.7257 - val_loss: 0.3145 - val_auc: 0.6092
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4786 - auc: 0.7070 - val_loss: 0.2752 - val_auc: 0.5338
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350497E798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8901692, 0), (0.87495893, 0), (0.86800206, 0), (0.83078164, 1), (0.813723, 0), (0.791929, 0), (0.7593423, 0), (0.7364567, 0), (0.6391348, 0), (0.35963714, 0), (0.34815994, 0), (0.0, 0)]
0.1
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235023CFAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
100/101 [============================&gt;.] - ETA: 0s - loss: 0.6216 - auc: 0.5829WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235098E0048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.6209 - auc: 0.5829 - val_loss: 0.6239 - val_auc: 0.5583
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5815 - auc: 0.6212 - val_loss: 0.4630 - val_auc: 0.5315
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5606 - auc: 0.6185 - val_loss: 0.5178 - val_auc: 0.6391
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5257 - auc: 0.6330 - val_loss: 0.4182 - val_auc: 0.5747
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4959 - auc: 0.6713 - val_loss: 0.4509 - val_auc: 0.5922
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5182 - auc: 0.6407 - val_loss: 0.4269 - val_auc: 0.6714
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5163 - auc: 0.6591 - val_loss: 0.4075 - val_auc: 0.6674
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5019 - auc: 0.6467 - val_loss: 0.3894 - val_auc: 0.7445
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4938 - auc: 0.6706 - val_loss: 0.3379 - val_auc: 0.7424
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4881 - auc: 0.6821 - val_loss: 0.3186 - val_auc: 0.7594
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6896 - val_loss: 0.3518 - val_auc: 0.6750
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4716 - auc: 0.7146 - val_loss: 0.3162 - val_auc: 0.7094
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4676 - auc: 0.7171 - val_loss: 0.3217 - val_auc: 0.7146
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4670 - auc: 0.7155 - val_loss: 0.3626 - val_auc: 0.7177
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4805 - auc: 0.7108 - val_loss: 0.3481 - val_auc: 0.6755
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4749 - auc: 0.7079 - val_loss: 0.3369 - val_auc: 0.6896
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4954 - auc: 0.6881 - val_loss: 0.3337 - val_auc: 0.6904
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4715 - auc: 0.7066 - val_loss: 0.3262 - val_auc: 0.6898
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4738 - auc: 0.7245 - val_loss: 0.3536 - val_auc: 0.7206
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4806 - auc: 0.7049 - val_loss: 0.3178 - val_auc: 0.6227
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350289A798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.7504613, 0), (0.6927907, 1), (0.68528575, 0), (0.68174064, 0), (0.67698646, 1), (0.6580898, 0), (0.64766747, 0), (0.62408733, 0), (0.60704106, 0), (0.54784393, 0), (0.32853892, 1), (0.0, 0)]
0.2
0.6666666666666666
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503094708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/101 [==========================&gt;...] - ETA: 0s - loss: 0.5443 - auc: 0.5747WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023506224168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5364 - auc: 0.5734 - val_loss: 0.2596 - val_auc: 0.4384
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5223 - auc: 0.6027 - val_loss: 0.2652 - val_auc: 0.3910
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4943 - auc: 0.6377 - val_loss: 0.2598 - val_auc: 0.4225
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5013 - auc: 0.6593 - val_loss: 0.2695 - val_auc: 0.3556
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4956 - auc: 0.6607 - val_loss: 0.2771 - val_auc: 0.3925
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4830 - auc: 0.6734 - val_loss: 0.2699 - val_auc: 0.4821
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6676 - val_loss: 0.2901 - val_auc: 0.4345
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4825 - auc: 0.6794 - val_loss: 0.2823 - val_auc: 0.5771
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4973 - auc: 0.6554 - val_loss: 0.2825 - val_auc: 0.4143
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4793 - auc: 0.6913 - val_loss: 0.2883 - val_auc: 0.4151
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4739 - auc: 0.7057 - val_loss: 0.2874 - val_auc: 0.4531
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4789 - auc: 0.7136 - val_loss: 0.2930 - val_auc: 0.4791
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.6851 - val_loss: 0.2964 - val_auc: 0.4489
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4893 - auc: 0.6469 - val_loss: 0.2898 - val_auc: 0.5114
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4771 - auc: 0.6717 - val_loss: 0.3015 - val_auc: 0.4234
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4772 - auc: 0.6780 - val_loss: 0.2899 - val_auc: 0.4753
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.7008 - val_loss: 0.2916 - val_auc: 0.5182
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4750 - auc: 0.6871 - val_loss: 0.2907 - val_auc: 0.4717
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4794 - auc: 0.6850 - val_loss: 0.2815 - val_auc: 0.4892
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4690 - auc: 0.7095 - val_loss: 0.2889 - val_auc: 0.4652
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503094558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8008754, 0), (0.8008754, 1), (0.8008754, 1), (0.8008754, 1), (0.8008754, 1), (0.8008754, 0), (0.8008754, 1), (0.78225094, 0), (0.76248664, 0), (0.3558086, 0), (0.05018079, 0), (0.0, 0)]
0.5
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235047B50D8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/101 [==========================&gt;...] - ETA: 0s - loss: 0.5427 - auc: 0.4780WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x000002350289AF78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.5427 - auc: 0.4822 - val_loss: 0.2978 - val_auc: 0.4588
Epoch 2/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5256 - auc: 0.5621 - val_loss: 0.2955 - val_auc: 0.4691
Epoch 3/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5081 - auc: 0.6323 - val_loss: 0.2926 - val_auc: 0.4526
Epoch 4/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5073 - auc: 0.6419 - val_loss: 0.2856 - val_auc: 0.5171
Epoch 5/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4917 - auc: 0.6824 - val_loss: 0.2722 - val_auc: 0.5190
Epoch 6/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5174 - auc: 0.6395 - val_loss: 0.2724 - val_auc: 0.6424
Epoch 7/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5051 - auc: 0.6435 - val_loss: 0.3016 - val_auc: 0.5486
Epoch 8/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5019 - auc: 0.6548 - val_loss: 0.2955 - val_auc: 0.4932
Epoch 9/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5014 - auc: 0.6664 - val_loss: 0.3042 - val_auc: 0.4520
Epoch 10/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4869 - auc: 0.6795 - val_loss: 0.2939 - val_auc: 0.6082
Epoch 11/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4954 - auc: 0.6649 - val_loss: 0.2863 - val_auc: 0.4965
Epoch 12/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4902 - auc: 0.6769 - val_loss: 0.3060 - val_auc: 0.5509
Epoch 13/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4929 - auc: 0.6980 - val_loss: 0.2837 - val_auc: 0.5950
Epoch 14/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5037 - auc: 0.6499 - val_loss: 0.2953 - val_auc: 0.5612
Epoch 15/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4855 - auc: 0.6984 - val_loss: 0.2917 - val_auc: 0.5828
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4825 - auc: 0.7103 - val_loss: 0.2626 - val_auc: 0.6479
Epoch 17/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4843 - auc: 0.7054 - val_loss: 0.2829 - val_auc: 0.6147
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4838 - auc: 0.6882 - val_loss: 0.2743 - val_auc: 0.5180
Epoch 19/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4846 - auc: 0.7214 - val_loss: 0.2821 - val_auc: 0.6894
Epoch 20/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4799 - auc: 0.7115 - val_loss: 0.2922 - val_auc: 0.6456
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023509CD8168&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.84778076, 1), (0.84497154, 0), (0.8258777, 0), (0.8099892, 0), (0.77915555, 0), (0.7551211, 0), (0.7208165, 0), (0.65262187, 0), (0.6172006, 0), (0.5167473, 0), (0.32063606, 0), (0.0, 0)]
0.1
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023500B7FAF8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/101 [==========================&gt;...] - ETA: 0s - loss: 0.6452 - auc: 0.5293WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504497678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.6459 - auc: 0.5269 - val_loss: 0.6405 - val_auc: 0.4583
Epoch 2/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5791 - auc: 0.5716 - val_loss: 0.4916 - val_auc: 0.6367
Epoch 3/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5429 - auc: 0.6262 - val_loss: 0.4508 - val_auc: 0.4519
Epoch 4/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5030 - auc: 0.6821 - val_loss: 0.4560 - val_auc: 0.5210
Epoch 5/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5342 - auc: 0.6352 - val_loss: 0.3869 - val_auc: 0.5521
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5004 - auc: 0.6746 - val_loss: 0.4403 - val_auc: 0.3797
Epoch 7/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5411 - auc: 0.6085 - val_loss: 0.4004 - val_auc: 0.5694
Epoch 8/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5069 - auc: 0.6419 - val_loss: 0.3779 - val_auc: 0.5723
Epoch 9/20
101/101 [==============================] - 1s 5ms/step - loss: 0.5043 - auc: 0.6588 - val_loss: 0.3856 - val_auc: 0.4899
Epoch 10/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5037 - auc: 0.6719 - val_loss: 0.3632 - val_auc: 0.5507
Epoch 11/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4854 - auc: 0.6872 - val_loss: 0.3517 - val_auc: 0.5276
Epoch 12/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4904 - auc: 0.6990 - val_loss: 0.3583 - val_auc: 0.5360
Epoch 13/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4821 - auc: 0.7148 - val_loss: 0.3339 - val_auc: 0.6284
Epoch 14/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4940 - auc: 0.6829 - val_loss: 0.3426 - val_auc: 0.5587
Epoch 15/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4859 - auc: 0.7029 - val_loss: 0.3524 - val_auc: 0.5616
Epoch 16/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4900 - auc: 0.6837 - val_loss: 0.3358 - val_auc: 0.5645
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4920 - auc: 0.6981 - val_loss: 0.3569 - val_auc: 0.5524
Epoch 18/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4845 - auc: 0.7168 - val_loss: 0.3242 - val_auc: 0.6209
Epoch 19/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4869 - auc: 0.7149 - val_loss: 0.3302 - val_auc: 0.5746
Epoch 20/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4977 - auc: 0.6766 - val_loss: 0.3351 - val_auc: 0.5524
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502170318&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (1.0, 0), (0.9955018, 0), (0.9863327, 0), (0.9829748, 0), (0.9778792, 0), (0.8267927, 0), (0.81232846, 0), (0.6926566, 0), (0.5649442, 0), (0.55420554, 0), (0.35004234, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235037CCCA8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 99/101 [============================&gt;.] - ETA: 0s - loss: 0.4917 - auc: 0.5862WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023504497048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 8ms/step - loss: 0.4894 - auc: 0.5822 - val_loss: 0.3451 - val_auc: 0.4216
Epoch 2/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4887 - auc: 0.6163 - val_loss: 0.3329 - val_auc: 0.4411
Epoch 3/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4845 - auc: 0.6344 - val_loss: 0.3406 - val_auc: 0.6919
Epoch 4/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4742 - auc: 0.6755 - val_loss: 0.3541 - val_auc: 0.5341
Epoch 5/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4682 - auc: 0.6662 - val_loss: 0.3429 - val_auc: 0.4405
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4714 - auc: 0.6650 - val_loss: 0.3409 - val_auc: 0.5617
Epoch 7/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4840 - auc: 0.6626 - val_loss: 0.3390 - val_auc: 0.4745
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4741 - auc: 0.6844 - val_loss: 0.3594 - val_auc: 0.4633
Epoch 9/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4735 - auc: 0.6784 - val_loss: 0.3710 - val_auc: 0.4582
Epoch 10/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4859 - auc: 0.6548 - val_loss: 0.3734 - val_auc: 0.3625
Epoch 11/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4716 - auc: 0.6732 - val_loss: 0.3617 - val_auc: 0.4484
Epoch 12/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4568 - auc: 0.7165 - val_loss: 0.3620 - val_auc: 0.4751
Epoch 13/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4619 - auc: 0.6881 - val_loss: 0.3528 - val_auc: 0.4509
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4716 - auc: 0.6798 - val_loss: 0.3573 - val_auc: 0.4783
Epoch 15/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4599 - auc: 0.7155 - val_loss: 0.3530 - val_auc: 0.4944
Epoch 16/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4762 - auc: 0.6881 - val_loss: 0.3665 - val_auc: 0.4748
Epoch 17/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4780 - auc: 0.6792 - val_loss: 0.3600 - val_auc: 0.4864
Epoch 18/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4627 - auc: 0.6931 - val_loss: 0.3662 - val_auc: 0.4718
Epoch 19/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4637 - auc: 0.6976 - val_loss: 0.3576 - val_auc: 0.5051
Epoch 20/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4694 - auc: 0.7027 - val_loss: 0.3530 - val_auc: 0.5103
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350812F1F8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.6607374, 1), (0.64274937, 1), (0.62882537, 1), (0.62352264, 0), (0.61064374, 0), (0.61064374, 0), (0.61064374, 0), (0.61064374, 0), (0.61064374, 0), (0.61064374, 1), (0.49506244, 0), (0.0, 0)]
0.4
0.8
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235594A74C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/101 [==========================&gt;...] - ETA: 0s - loss: 0.6207 - auc: 0.4926WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502EF0708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 7ms/step - loss: 0.6102 - auc: 0.4992 - val_loss: 0.4423 - val_auc: 0.5147
Epoch 2/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5282 - auc: 0.6283 - val_loss: 0.3919 - val_auc: 0.6718
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5175 - auc: 0.6401 - val_loss: 0.4611 - val_auc: 0.4655
Epoch 4/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5261 - auc: 0.6212 - val_loss: 0.3858 - val_auc: 0.5302
Epoch 5/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5246 - auc: 0.6239 - val_loss: 0.3238 - val_auc: 0.5055
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4977 - auc: 0.6613 - val_loss: 0.3314 - val_auc: 0.4534
Epoch 7/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5175 - auc: 0.6565 - val_loss: 0.3422 - val_auc: 0.4902
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4935 - auc: 0.6755 - val_loss: 0.3440 - val_auc: 0.4836
Epoch 9/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4949 - auc: 0.6840 - val_loss: 0.3154 - val_auc: 0.5265
Epoch 10/20
101/101 [==============================] - 0s 5ms/step - loss: 0.5023 - auc: 0.6665 - val_loss: 0.3154 - val_auc: 0.5389
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4974 - auc: 0.6767 - val_loss: 0.3201 - val_auc: 0.5135
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4883 - auc: 0.6787 - val_loss: 0.3219 - val_auc: 0.5253
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4748 - auc: 0.7190 - val_loss: 0.3066 - val_auc: 0.5538
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4888 - auc: 0.6704 - val_loss: 0.3254 - val_auc: 0.5081
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4788 - auc: 0.7172 - val_loss: 0.2986 - val_auc: 0.5320
Epoch 16/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4864 - auc: 0.6927 - val_loss: 0.3152 - val_auc: 0.5956
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4940 - auc: 0.6968 - val_loss: 0.2931 - val_auc: 0.5613
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4866 - auc: 0.6976 - val_loss: 0.3016 - val_auc: 0.5524
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4859 - auc: 0.7053 - val_loss: 0.3093 - val_auc: 0.5858
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5016 - auc: 0.6835 - val_loss: 0.3098 - val_auc: 0.5386
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x000002350289A558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8471443, 0), (0.8471443, 0), (0.8471443, 0), (0.8471443, 0), (0.83589995, 0), (0.8315084, 0), (0.6782102, 0), (0.62238204, 0), (0.53240794, 0), (0.30665693, 0), (0.06180226, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235098E0A68&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 91/101 [==========================&gt;...] - ETA: 0s - loss: 0.5285 - auc: 0.5496WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502DC65E8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5300 - auc: 0.5529 - val_loss: 0.3424 - val_auc: 0.4888
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4984 - auc: 0.6205 - val_loss: 0.3431 - val_auc: 0.4373
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4844 - auc: 0.6812 - val_loss: 0.3436 - val_auc: 0.4440
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4946 - auc: 0.6457 - val_loss: 0.3297 - val_auc: 0.6135
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4855 - auc: 0.6696 - val_loss: 0.3328 - val_auc: 0.5430
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4897 - auc: 0.6740 - val_loss: 0.3289 - val_auc: 0.5373
Epoch 7/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4952 - auc: 0.6711 - val_loss: 0.3252 - val_auc: 0.4923
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4803 - auc: 0.6690 - val_loss: 0.3214 - val_auc: 0.4563
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4831 - auc: 0.6585 - val_loss: 0.3172 - val_auc: 0.5041
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4643 - auc: 0.7285 - val_loss: 0.3334 - val_auc: 0.5043
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4828 - auc: 0.6868 - val_loss: 0.3310 - val_auc: 0.5269
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4760 - auc: 0.7193 - val_loss: 0.3358 - val_auc: 0.5162
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4744 - auc: 0.6884 - val_loss: 0.3364 - val_auc: 0.5248
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4768 - auc: 0.7014 - val_loss: 0.3260 - val_auc: 0.5034
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4731 - auc: 0.7011 - val_loss: 0.3423 - val_auc: 0.4004
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4726 - auc: 0.6984 - val_loss: 0.3214 - val_auc: 0.5228
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4596 - auc: 0.7168 - val_loss: 0.3235 - val_auc: 0.5633
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4686 - auc: 0.7080 - val_loss: 0.3296 - val_auc: 0.4906
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4632 - auc: 0.7249 - val_loss: 0.3318 - val_auc: 0.4578
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4676 - auc: 0.7382 - val_loss: 0.3262 - val_auc: 0.4504
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235062243A8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.8893555, 1), (0.87576455, 0), (0.85822594, 0), (0.797642, 0), (0.741371, 1), (0.63128096, 0), (0.6128592, 0), (0.5985972, 1), (0.5777168, 0), (0.074138775, 0), (0.04059685, 0), (0.0, 0)]
0.3
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023503094678&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 87/101 [========================&gt;.....] - ETA: 0s - loss: 0.6927 - auc: 0.5154WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023558298F78&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 6ms/step - loss: 0.6656 - auc: 0.5294 - val_loss: 0.4781 - val_auc: 0.3903
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5567 - auc: 0.6024 - val_loss: 0.4814 - val_auc: 0.5088
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5715 - auc: 0.5689 - val_loss: 0.6178 - val_auc: 0.5198
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5396 - auc: 0.5811 - val_loss: 0.5840 - val_auc: 0.5527
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6356 - val_loss: 0.5621 - val_auc: 0.5314
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4914 - auc: 0.6473 - val_loss: 0.5465 - val_auc: 0.5820
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4945 - auc: 0.6364 - val_loss: 0.5685 - val_auc: 0.6077
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4842 - auc: 0.6326 - val_loss: 0.5344 - val_auc: 0.5903
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4755 - auc: 0.6537 - val_loss: 0.5090 - val_auc: 0.5712
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4504 - auc: 0.6850 - val_loss: 0.5168 - val_auc: 0.5811
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4585 - auc: 0.6670 - val_loss: 0.5042 - val_auc: 0.5197
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4613 - auc: 0.6671 - val_loss: 0.4950 - val_auc: 0.5953
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4528 - auc: 0.6884 - val_loss: 0.4826 - val_auc: 0.6058
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4537 - auc: 0.6870 - val_loss: 0.4944 - val_auc: 0.5884
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4463 - auc: 0.7022 - val_loss: 0.4888 - val_auc: 0.5569
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4405 - auc: 0.7106 - val_loss: 0.4851 - val_auc: 0.5725
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4420 - auc: 0.6973 - val_loss: 0.4807 - val_auc: 0.5797
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4421 - auc: 0.7159 - val_loss: 0.4803 - val_auc: 0.5619
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4460 - auc: 0.6884 - val_loss: 0.4764 - val_auc: 0.5312
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4481 - auc: 0.6797 - val_loss: 0.4826 - val_auc: 0.5347
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023503FAE708&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9944849, 0), (0.9918221, 1), (0.9741047, 0), (0.9717012, 1), (0.9431897, 1), (0.93973804, 0), (0.8308934, 1), (0.6750031, 0), (0.6010729, 1), (0.4527196, 0), (0.36891672, 1), (0.0, 1)]
0.5
0.7142857142857143
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023502DC6DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 92/101 [==========================&gt;...] - ETA: 0s - loss: 0.6413 - auc: 0.4728WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023502F0C798&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.6334 - auc: 0.4845 - val_loss: 0.4261 - val_auc: 0.4200
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5291 - auc: 0.6176 - val_loss: 0.3876 - val_auc: 0.3938
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5209 - auc: 0.6216 - val_loss: 0.4522 - val_auc: 0.3856
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5034 - auc: 0.6403 - val_loss: 0.4120 - val_auc: 0.4141
Epoch 5/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4929 - auc: 0.6669 - val_loss: 0.3674 - val_auc: 0.4746
Epoch 6/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4739 - auc: 0.6921 - val_loss: 0.3834 - val_auc: 0.4768
Epoch 7/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4848 - auc: 0.6755 - val_loss: 0.3518 - val_auc: 0.4717
Epoch 8/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4601 - auc: 0.7205 - val_loss: 0.3435 - val_auc: 0.4782
Epoch 9/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4807 - auc: 0.6967 - val_loss: 0.3596 - val_auc: 0.4096
Epoch 10/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4645 - auc: 0.7128 - val_loss: 0.3415 - val_auc: 0.4424
Epoch 11/20
101/101 [==============================] - 1s 5ms/step - loss: 0.4712 - auc: 0.7106 - val_loss: 0.3325 - val_auc: 0.4453
Epoch 12/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4703 - auc: 0.7140 - val_loss: 0.3501 - val_auc: 0.4483
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4692 - auc: 0.7219 - val_loss: 0.3557 - val_auc: 0.4455
Epoch 14/20
101/101 [==============================] - 0s 5ms/step - loss: 0.4660 - auc: 0.7138 - val_loss: 0.3391 - val_auc: 0.4552
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4543 - auc: 0.7421 - val_loss: 0.3360 - val_auc: 0.4400
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4654 - auc: 0.7170 - val_loss: 0.3403 - val_auc: 0.4394
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4646 - auc: 0.7326 - val_loss: 0.3299 - val_auc: 0.4733
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4691 - auc: 0.7057 - val_loss: 0.3453 - val_auc: 0.4727
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4613 - auc: 0.7086 - val_loss: 0.3300 - val_auc: 0.4799
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4504 - auc: 0.7398 - val_loss: 0.3351 - val_auc: 0.4469
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235098E0048&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.99060774, 1), (0.7340767, 0), (0.66278315, 0), (0.58188915, 0), (0.5784509, 1), (0.576002, 0), (0.574952, 0), (0.5329703, 0), (0.5184626, 1), (0.33223137, 0), (0.22582226, 0), (0.0, 1)]
0.3
0.75
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x0000023509CD8558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 96/101 [===========================&gt;..] - ETA: 0s - loss: 0.5323 - auc: 0.5612WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023500B7FC18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 2s 9ms/step - loss: 0.5343 - auc: 0.5577 - val_loss: 0.2860 - val_auc: 0.6208
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5150 - auc: 0.6123 - val_loss: 0.3250 - val_auc: 0.4964
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5216 - auc: 0.6182 - val_loss: 0.2828 - val_auc: 0.5687
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5109 - auc: 0.6247 - val_loss: 0.2726 - val_auc: 0.5919
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5040 - auc: 0.6385 - val_loss: 0.2859 - val_auc: 0.5547
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4979 - auc: 0.6458 - val_loss: 0.2624 - val_auc: 0.4940
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5058 - auc: 0.6336 - val_loss: 0.2583 - val_auc: 0.4878
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4902 - auc: 0.6858 - val_loss: 0.2604 - val_auc: 0.4807
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4931 - auc: 0.6811 - val_loss: 0.2733 - val_auc: 0.5068
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5002 - auc: 0.6460 - val_loss: 0.2822 - val_auc: 0.5122
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4993 - auc: 0.6705 - val_loss: 0.2797 - val_auc: 0.5029
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5038 - auc: 0.6529 - val_loss: 0.2918 - val_auc: 0.5081
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4742 - auc: 0.7051 - val_loss: 0.2767 - val_auc: 0.5143
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4968 - auc: 0.6884 - val_loss: 0.2703 - val_auc: 0.4797
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5015 - auc: 0.6476 - val_loss: 0.2718 - val_auc: 0.5294
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4905 - auc: 0.6760 - val_loss: 0.2808 - val_auc: 0.5354
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4838 - auc: 0.7083 - val_loss: 0.2783 - val_auc: 0.5143
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.7199 - val_loss: 0.2721 - val_auc: 0.5492
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4845 - auc: 0.7062 - val_loss: 0.2767 - val_auc: 0.5875
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4886 - auc: 0.6890 - val_loss: 0.2878 - val_auc: 0.5138
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x00000235594A7558&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9783383, 0), (0.93608177, 0), (0.66082335, 0), (0.52796715, 0), (0.525996, 0), (0.5156267, 0), (0.41889358, 0), (0.35581973, 0), (0.26758552, 0), (0.19141605, 0), (0.07062741, 0), (0.0, 0)]
0.0
-1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235098E0C18&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 93/101 [==========================&gt;...] - ETA: 0s - loss: 0.5636 - auc: 0.4790WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x0000023503525DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.5597 - auc: 0.4960 - val_loss: 0.3787 - val_auc: 0.6849
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5203 - auc: 0.6177 - val_loss: 0.3056 - val_auc: 0.5399
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5220 - auc: 0.6079 - val_loss: 0.3408 - val_auc: 0.6269
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5176 - auc: 0.6332 - val_loss: 0.3360 - val_auc: 0.6285
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4986 - auc: 0.6769 - val_loss: 0.3073 - val_auc: 0.5921
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6962 - val_loss: 0.3377 - val_auc: 0.5548
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4878 - auc: 0.6942 - val_loss: 0.2940 - val_auc: 0.6875
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5020 - auc: 0.6547 - val_loss: 0.2920 - val_auc: 0.6295
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4841 - auc: 0.6837 - val_loss: 0.3060 - val_auc: 0.5332
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4981 - auc: 0.6810 - val_loss: 0.3094 - val_auc: 0.5216
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4900 - auc: 0.6950 - val_loss: 0.3220 - val_auc: 0.4952
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4898 - auc: 0.6872 - val_loss: 0.3076 - val_auc: 0.5093
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.6999 - val_loss: 0.3052 - val_auc: 0.5509
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4854 - auc: 0.7063 - val_loss: 0.3144 - val_auc: 0.5074
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4835 - auc: 0.7191 - val_loss: 0.3018 - val_auc: 0.6089
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4890 - auc: 0.7017 - val_loss: 0.2985 - val_auc: 0.6836
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4727 - auc: 0.7203 - val_loss: 0.3069 - val_auc: 0.7004
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4967 - auc: 0.6894 - val_loss: 0.3246 - val_auc: 0.6073
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4736 - auc: 0.7249 - val_loss: 0.3058 - val_auc: 0.6166
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4801 - auc: 0.7258 - val_loss: 0.2870 - val_auc: 0.6002
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023502DC64C8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 1), (0.9168444, 0), (0.875427, 0), (0.8685955, 0), (0.8590792, 0), (0.83082134, 0), (0.76079434, 0), (0.7231657, 0), (0.6306767, 0), (0.4499785, 0), (0.41341653, 0), (0.30907932, 0), (0.0, 0)]
0.1111111111111111
1.0
Epoch 1/20
WARNING: AutoGraph could not transform &lt;function Model.make_train_function.&lt;locals&gt;.train_function at 0x00000235061F8288&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
 95/101 [===========================&gt;..] - ETA: 0s - loss: 0.5976 - auc: 0.5227 WARNING: AutoGraph could not transform &lt;function Model.make_test_function.&lt;locals&gt;.test_function at 0x00000235010458B8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
101/101 [==============================] - 1s 6ms/step - loss: 0.6032 - auc: 0.5094 - val_loss: 0.3477 - val_auc: 0.3950
Epoch 2/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5531 - auc: 0.5614 - val_loss: 0.3806 - val_auc: 0.5789
Epoch 3/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5282 - auc: 0.5977 - val_loss: 0.3784 - val_auc: 0.5535
Epoch 4/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5209 - auc: 0.6331 - val_loss: 0.3387 - val_auc: 0.7001
Epoch 5/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5087 - auc: 0.6447 - val_loss: 0.3450 - val_auc: 0.6511
Epoch 6/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5096 - auc: 0.6616 - val_loss: 0.3236 - val_auc: 0.5947
Epoch 7/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5240 - auc: 0.6284 - val_loss: 0.3536 - val_auc: 0.6363
Epoch 8/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5131 - auc: 0.6218 - val_loss: 0.3350 - val_auc: 0.6788
Epoch 9/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5057 - auc: 0.6654 - val_loss: 0.3270 - val_auc: 0.6769
Epoch 10/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4853 - auc: 0.6940 - val_loss: 0.3082 - val_auc: 0.6598
Epoch 11/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4985 - auc: 0.6873 - val_loss: 0.2909 - val_auc: 0.7123
Epoch 12/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4942 - auc: 0.6894 - val_loss: 0.3166 - val_auc: 0.6666
Epoch 13/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5052 - auc: 0.6677 - val_loss: 0.3144 - val_auc: 0.7023
Epoch 14/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4711 - auc: 0.7271 - val_loss: 0.3038 - val_auc: 0.7017
Epoch 15/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4837 - auc: 0.7112 - val_loss: 0.2856 - val_auc: 0.6540
Epoch 16/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4969 - auc: 0.6789 - val_loss: 0.3136 - val_auc: 0.6637
Epoch 17/20
101/101 [==============================] - 0s 4ms/step - loss: 0.5017 - auc: 0.6910 - val_loss: 0.3067 - val_auc: 0.6430
Epoch 18/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4831 - auc: 0.6925 - val_loss: 0.3075 - val_auc: 0.5966
Epoch 19/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4895 - auc: 0.6996 - val_loss: 0.2991 - val_auc: 0.6421
Epoch 20/20
101/101 [==============================] - 0s 4ms/step - loss: 0.4903 - auc: 0.6978 - val_loss: 0.3200 - val_auc: 0.6401
WARNING: AutoGraph could not transform &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x0000023504734DC8&gt; and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: &#39;arguments&#39; object has no attribute &#39;posonlyargs&#39;
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
[(1.0, 0), (0.9984418, 0), (0.9937469, 0), (0.988269, 0), (0.98678064, 0), (0.9761399, 0), (0.9662915, 0), (0.7983802, 0), (0.6788578, 0), (0.6382118, 0), (0.514651, 0), (0.27464247, 0), (0.0, 1)]
0.0
0.0
Siam
[1.0, 0.2, 0.0, 0.2, 0.125, 0.5, 0.3333333333333333, 0.1, 0.2, 0.5, 0.1, 0.0, 0.4, 0.0, 0.3, 0.5, 0.3, 0.0, 0.1111111111111111, 0.0]
0.24347222222222223
[0.2, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 1.0, -1.0, 0.8, -1.0, 1.0, 0.7142857142857143, 0.75, -1.0, 1.0, 0.0]
0.7233893557422969
</pre>
</div>
</div>

</div>

</div>

</div>
</body>







</html>
