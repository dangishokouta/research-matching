{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e665d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "matchData=pd.read_csv(\"matchedVector_Oct.csv\")\n",
    "matchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matchData['id_user'].nunique()) #number of users\n",
    "print(matchData['id_matched'].nunique())#number of candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize language model\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "japanese_sentences = [\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"]\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "ja_result = embed(japanese_sentences)\n",
    "ja_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#select features (include everything but text)\n",
    "user_X=matchData.loc[:,\"gender_公開したくない_user\":\"coping_strategy_飲酒_user\"]\n",
    "target_X=matchData.loc[:,\"gender_公開したくない_matched\":\"coping_strategy_飲酒_matched\"]\n",
    "user_X_Id=matchData.loc[:,[\"id_user\"]]\n",
    "isMatched=matchData.loc[:,[\"isMatched\"]]\n",
    "\n",
    "#vectorize the languages\n",
    "loss_description_user=matchData.loc[:,\"loss_description_user\"]\n",
    "loss_vector_col_name = [\"loss_user_\"+str(num) for num in range(0, 512)]\n",
    "loss_vector = pd.DataFrame(embed(loss_description_user).numpy(),columns=loss_vector_col_name)\n",
    "\n",
    "loss_description_matched=matchData.loc[:,\"loss_description_matched\"]\n",
    "loss_vector_match_col_name = [\"loss_user_matched_\"+str(num) for num in range(0, 512)]\n",
    "loss_vector_matched = pd.DataFrame(embed(loss_description_matched).numpy(),columns=loss_vector_match_col_name)\n",
    "\n",
    "hobbies_description=matchData.loc[:,\"hobbies_description_user\"]\n",
    "hobbies_col_name = [\"hobbies_description_\"+str(num) for num in range(0, 512)]\n",
    "hobbies_vector = pd.DataFrame(embed(hobbies_description).numpy(),columns=hobbies_col_name)\n",
    "\n",
    "hobbies_description_matched=matchData.loc[:,\"hobbies_description_matched\"]\n",
    "hobbies_col_name_matched = [\"hobbies_description_matched_\"+str(num) for num in range(0, 512)]\n",
    "hobbies_vector_matched = pd.DataFrame(embed(hobbies_description_matched).numpy(),columns=hobbies_col_name_matched)\n",
    "\n",
    "\n",
    "matchEncodedData=pd.DataFrame(pd.concat([\n",
    "    pd.DataFrame(user_X,columns=user_X.columns),loss_vector,hobbies_vector,\n",
    "    pd.DataFrame(target_X,columns=target_X.columns),loss_vector_matched,hobbies_vector_matched,\n",
    "    pd.DataFrame(user_X_Id,columns=user_X_Id.columns),\n",
    "    pd.DataFrame(isMatched,columns=isMatched.columns)\n",
    "]\n",
    "    ,axis=1))\n",
    "\n",
    "matchEncodedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1327ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def getExistingTrainingToTest(train_index,test_index,ratio,numMatches):\n",
    "    pickNum=round(numMatches*ratio)\n",
    "    numUsers=round(len(test_index)/numMatches)\n",
    "    index=0\n",
    "    new_train_index=[]\n",
    "    new_test_index=[]\n",
    "    moveList=[]\n",
    "    for index in range(numUsers):\n",
    "        randomIndexList=random.sample(range(numMatches), pickNum)\n",
    "        randomIndexList=[x+(index*numMatches) for x in randomIndexList]\n",
    "        moveList = moveList+[test_index[x] for x in randomIndexList]\n",
    "        index=index+1\n",
    "    #move the numbers in the move list to the test and train index\n",
    "    new_test_index=list(filter(lambda x: not(x in moveList),test_index))\n",
    "    new_train_index=list(train_index)\n",
    "    move_index=moveList\n",
    "    return new_train_index,move_index,new_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceac946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Flatten,Input,Lambda\n",
    "from keras.metrics import AUC\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def testDLSiamese(X_train, X_test, Y_train, groupString):\n",
    "    X_train=X_train.drop(groupString,axis=1)\n",
    "    X_train=X_train.drop(\"isMatched\",axis=1)\n",
    "    X_test=X_test.drop(groupString,axis=1)\n",
    "    X_test=X_test.drop(\"isMatched\",axis=1)\n",
    "    \n",
    "    #Start training\n",
    "    X_train=np.array(X_train)\n",
    "    X_test=np.array(X_test)\n",
    "    Y_train=np.array(Y_train)\n",
    "\n",
    "    half_size=round(len(X_train[0])/2)\n",
    "    input_1 = Input(shape=(half_size,))\n",
    "    layer_1 = Dense(512, activation='relu')(input_1)\n",
    "    layer_1 = Dropout(0.4)(layer_1)\n",
    "    layer_1 = Dense(32, activation='relu')(layer_1)\n",
    "    layer_1 = Dropout(0.4)(layer_1)\n",
    "    layer_1 = Dense(8, activation='relu')(layer_1)\n",
    "    layer_1 = Dropout(0.4)(layer_1)\n",
    "    \n",
    "    input_2 = Input(shape=(half_size,))\n",
    "    layer_2 = Dense(512, activation='relu')(input_2)\n",
    "    layer_2 = Dropout(0.4)(layer_2)\n",
    "    layer_2 = Dense(32, activation='relu')(layer_2)\n",
    "    layer_2 = Dropout(0.4)(layer_2)\n",
    "    layer_2 = Dense(8, activation='relu')(layer_2)\n",
    "    layer_2 = Dropout(0.4)(layer_2)\n",
    "    \n",
    "    l1_norm = lambda x: 1 - K.abs(x[0] - x[1])\n",
    "    merged = Lambda(function=l1_norm, output_shape=lambda x: x[0], name='L1_distance')([layer_1, layer_2])\n",
    "    predictions = Dense(1, activation='sigmoid', name='classification_layer')(merged)\n",
    "\n",
    "    model = Model([input_1, input_2], predictions)\n",
    "    model.compile(loss='binary_crossentropy',optimizer=\"adam\", metrics=[AUC(name='auc')])    \n",
    "    result=model.fit([X_train[:,:half_size],X_train[:,half_size:]],np.array(Y_train),epochs=20,batch_size=8,validation_split=0.2)\n",
    "    \n",
    "    predict_y=model.predict([X_test[:,:half_size],X_test[:,half_size:]])\n",
    "\n",
    "    return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174884fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "        \n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in predictions.items():\n",
    "        \n",
    "        # normalize from zero to one\n",
    "        getNormalizeNumber=[]\n",
    "        for eachRating in user_ratings:\n",
    "            getNormalizeNumber.append(eachRating[0])\n",
    "            \n",
    "        normalized=NormalizeData(getNormalizeNumber)\n",
    "        \n",
    "        newRating=[]\n",
    "        for index,eachRating in enumerate(user_ratings):\n",
    "            newRating.append((normalized[index],eachRating[1]))\n",
    "        user_ratings=newRating\n",
    "        \n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        print(user_ratings)\n",
    "        \n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "        if n_rel == 0:\n",
    "            recalls[uid] = -1\n",
    "        \n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b61f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for parameter optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#for evaluation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "def testEverythingGroupSIAM(X,Y,groupString,k_value,ratio):\n",
    "    group=X[groupString].values\n",
    "    skf = LeaveOneGroupOut()\n",
    "    skf.get_n_splits(X,Y,group)\n",
    "    print(skf)\n",
    "    \n",
    "    siam_p_k=[]\n",
    "    siam_r_k=[]\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,Y,group):\n",
    "        train_index,move_index,test_index=getExistingTrainingToTest(train_index,test_index,ratio,51)\n",
    "        \n",
    "        X_train = X[X.index.isin(train_index)]\n",
    "        X_train_moved=X[X.index.isin(move_index)]\n",
    "        X_test = X[X.index.isin(test_index)]\n",
    "\n",
    "        Y_train = Y[Y.index.isin(train_index)]\n",
    "        Y_train_moved=Y[Y.index.isin(move_index)]\n",
    "        Y_test = Y[Y.index.isin(test_index)]\n",
    "            \n",
    "        X_train=pd.DataFrame(pd.concat([\n",
    "           pd.DataFrame(X_train),\n",
    "           pd.DataFrame(X_train_moved)\n",
    "        ]))\n",
    "        \n",
    "        Y_train=pd.DataFrame(pd.concat([\n",
    "           pd.DataFrame(Y_train),\n",
    "           pd.DataFrame(Y_train_moved)\n",
    "        ]))\n",
    "    \n",
    "        y_pred= testDLSiamese(X_train,X_test,Y_train,groupString)\n",
    "        \n",
    "        #for this to work, we need to format it correctly [uid]=(predicted,true)\n",
    "        prec_cal=defaultdict(list)\n",
    "        \n",
    "        counter=0 #don't use index as it doesn't start at zero\n",
    "        for index,eachTest in X_test.iterrows():\n",
    "            prec_cal[eachTest['id_user']].append((y_pred[counter][0],Y_test['isMatched'].values[counter]))\n",
    "            counter=counter+1\n",
    "\n",
    "        precisions, recalls = precision_recall_at_k(prec_cal, k=k_value, threshold=0.5)\n",
    "        print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        print(sum(rec for rec in recalls.values()) / len(recalls))        \n",
    "        siam_p_k.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        siam_r_k.append(sum(rec for rec in recalls.values()) / len(recalls))  \n",
    "        \n",
    "        \n",
    "    print(\"Siam\")\n",
    "    print(siam_p_k)\n",
    "    print(mean([x for x in siam_p_k  if x != -1]))\n",
    "    print(siam_r_k)\n",
    "    print(mean([x for x in siam_r_k  if x != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=matchEncodedData\n",
    "Y=isMatched\n",
    "\n",
    "testEverythingGroupSIAM(X,Y,\"id_user\",5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75020ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",5,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693c0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59eb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",5,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2335f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eac60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",10,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fe2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",10,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd32c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupSIAM(X,Y,\"id_user\",10,0.75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
