{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c7f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "matchData=pd.read_csv(\"matchedVector_Oct.csv\")\n",
    "\n",
    "matchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c342e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize language model\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "\n",
    "japanese_sentences = [\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"]\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "ja_result = embed(japanese_sentences)\n",
    "ja_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#select features (include everything but text)\n",
    "user_X=matchData.loc[:,\"gender_公開したくない_user\":\"coping_strategy_飲酒_user\"]\n",
    "target_X=matchData.loc[:,\"gender_公開したくない_matched\":\"coping_strategy_飲酒_matched\"]\n",
    "user_X_Id=matchData.loc[:,[\"id_user\"]]\n",
    "matched_X_Id=matchData.loc[:,[\"id_matched\"]]\n",
    "isMatched=matchData.loc[:,[\"isMatched\"]]\n",
    "\n",
    "\n",
    "#vectorize the languages\n",
    "loss_description_user=matchData.loc[:,\"loss_description_user\"]\n",
    "loss_vector_col_name = [\"loss_user_\"+str(num) for num in range(0, 512)]\n",
    "loss_vector = pd.DataFrame(embed(loss_description_user).numpy(),columns=loss_vector_col_name)\n",
    "\n",
    "loss_description_matched=matchData.loc[:,\"loss_description_matched\"]\n",
    "loss_vector_match_col_name = [\"loss_user_matched_\"+str(num) for num in range(0, 512)]\n",
    "loss_vector_matched = pd.DataFrame(embed(loss_description_matched).numpy(),columns=loss_vector_match_col_name)\n",
    "\n",
    "hobbies_description=matchData.loc[:,\"hobbies_description_user\"]\n",
    "hobbies_col_name = [\"hobbies_description_\"+str(num) for num in range(0, 512)]\n",
    "hobbies_vector = pd.DataFrame(embed(hobbies_description).numpy(),columns=hobbies_col_name)\n",
    "\n",
    "hobbies_description_matched=matchData.loc[:,\"hobbies_description_matched\"]\n",
    "hobbies_col_name_matched = [\"hobbies_description_matched_\"+str(num) for num in range(0, 512)]\n",
    "hobbies_vector_matched = pd.DataFrame(embed(hobbies_description_matched).numpy(),columns=hobbies_col_name_matched)\n",
    "\n",
    "\n",
    "matchEncodedData=pd.DataFrame(pd.concat([\n",
    "    pd.DataFrame(user_X,columns=user_X.columns),\n",
    "    pd.DataFrame(target_X,columns=target_X.columns),\n",
    "    pd.DataFrame(user_X_Id,columns=user_X_Id.columns),\n",
    "    pd.DataFrame(matched_X_Id,columns=matched_X_Id.columns),\n",
    "    loss_vector,loss_vector_matched,hobbies_vector,hobbies_vector_matched,\n",
    "    pd.DataFrame(isMatched,columns=isMatched.columns)\n",
    "\n",
    "]\n",
    "    ,axis=1))\n",
    "\n",
    "# user_features=pd.DataFrame(pd.concat([\n",
    "#     pd.DataFrame(user_X,columns=user_X.columns),\n",
    "#     loss_vector,hobbies_vector\n",
    "# ]\n",
    "#     ,axis=1))\n",
    "\n",
    "# item_features=pd.DataFrame(pd.concat([\n",
    "#     pd.DataFrame(target_X,columns=target_X.columns),\n",
    "#     loss_vector_matched,hobbies_vector_matched,\n",
    "# ]\n",
    "#     ,axis=1))\n",
    "\n",
    "# interaction_matrix=pd.DataFrame(pd.concat([\n",
    "#     pd.DataFrame(user_X_Id,columns=user_X_Id.columns),\n",
    "#     pd.DataFrame(match_X_Id,columns=match_X_Id.columns),\n",
    "#     pd.DataFrame(isMatched,columns=isMatched.columns)\n",
    "# ]\n",
    "#     ,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def getExistingTrainingToTest(train_index,test_index,ratio,numMatches):\n",
    "    pickNum=round(numMatches*ratio)\n",
    "    numUsers=round(len(test_index)/numMatches)\n",
    "    index=0\n",
    "    new_train_index=[]\n",
    "    new_test_index=[]\n",
    "    moveList=[]\n",
    "    for index in range(numUsers):\n",
    "        randomIndexList=random.sample(range(numMatches), pickNum)\n",
    "        randomIndexList=[x+(index*numMatches) for x in randomIndexList]\n",
    "        moveList = moveList+[test_index[x] for x in randomIndexList]\n",
    "        index=index+1\n",
    "    #move the numbers in the move list to the test and train index\n",
    "    print(len(moveList))\n",
    "    new_test_index=list(filter(lambda x: not(x in moveList),test_index))\n",
    "    new_train_index=list(train_index)\n",
    "    move_index=moveList\n",
    "    return new_train_index,move_index,new_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d39939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "\n",
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "        \n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        \n",
    "        # normalize from zero to one\n",
    "        getNormalizeNumber=[]\n",
    "        for eachRating in user_ratings:\n",
    "            getNormalizeNumber.append(eachRating[0])\n",
    "            \n",
    "        normalized=NormalizeData(getNormalizeNumber)\n",
    "        \n",
    "        newRating=[]\n",
    "        for index,eachRating in enumerate(user_ratings):\n",
    "            newRating.append((normalized[index],eachRating[1]))\n",
    "        user_ratings=newRating\n",
    "        \n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        \n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        \n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "        if n_rel == 0:\n",
    "            recalls[uid] = -1\n",
    "            precisions[uid]=-1\n",
    "        \n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceb070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for evaluation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVDpp,BaselineOnly,SlopeOne\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "#threashold not used\n",
    "def testEverythingGroupCF(X,Y,groupString,k_value,ratio):\n",
    "    group=X[groupString].values\n",
    "    \n",
    "    skf = LeaveOneGroupOut()\n",
    "    skf.get_n_splits(X,Y,group)\n",
    "    print(skf)\n",
    "\n",
    "    cf_p_k=[]\n",
    "    cf_r_k=[]\n",
    "    \n",
    "    base_p_k=[]\n",
    "    base_r_k=[]\n",
    "    \n",
    "    slope_p_k=[]\n",
    "    slope_r_k=[]\n",
    "    \n",
    "    for train_index, test_index in skf.split(X,Y,group):\n",
    "        train_index,move_index,test_index=getExistingTrainingToTest(train_index,test_index,ratio,51)\n",
    "        \n",
    "        X_train = X[X.index.isin(train_index)]\n",
    "        X_train_moved=X[X.index.isin(move_index)]\n",
    "        X_test = X[X.index.isin(test_index)]\n",
    "\n",
    "        Y_train = Y[Y.index.isin(train_index)]\n",
    "        Y_train_moved=Y[Y.index.isin(move_index)]\n",
    "        Y_test = Y[Y.index.isin(test_index)]\n",
    "\n",
    "        X_train=pd.DataFrame(pd.concat([\n",
    "           pd.DataFrame(X_train),\n",
    "           pd.DataFrame(X_train_moved)\n",
    "        ]))\n",
    "        \n",
    "        Y_train=pd.DataFrame(pd.concat([\n",
    "           pd.DataFrame(Y_train),\n",
    "           pd.DataFrame(Y_train_moved)\n",
    "        ]))\n",
    "        \n",
    "        \n",
    "        #build the dataset with the user ID & match ID, to show the unique features for lightfm\n",
    "        reader = Reader(rating_scale=(0, 1))\n",
    "        data_train = Dataset.load_from_df(X_train[['id_user', 'id_matched', 'isMatched']], reader)\n",
    "        data_test = Dataset.load_from_df(X_test[['id_user', 'id_matched', 'isMatched']], reader)\n",
    "        testset = [data_test.df.iloc[i].to_list() for i in range(len(data_test.df))]\n",
    "        \n",
    "        ############DO SVD ######################\n",
    "        param_grid = {'n_epochs': [5,20,100], 'reg_all': [0.4,0.8]}\n",
    "        gs = GridSearchCV(SVDpp, param_grid, measures=['rmse'], cv=3)\n",
    "        gs.fit(data_train)\n",
    "        print(gs)\n",
    "        algo = gs.best_estimator['rmse']\n",
    "        algo.fit(data_train.build_full_trainset())\n",
    "        \n",
    "        pred= algo.test(testset)\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(pred, k=k_value, threshold=0.5)\n",
    "        print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        print(sum(rec for rec in recalls.values()) / len(recalls))        \n",
    "        cf_p_k.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        cf_r_k.append(sum(rec for rec in recalls.values()) / len(recalls))\n",
    "        \n",
    "        ############DO BASELINE ######################\n",
    "        algo = BaselineOnly()\n",
    "        algo.fit(data_train.build_full_trainset())\n",
    "        pred= algo.test(testset)\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(pred, k=k_value, threshold=0.5)\n",
    "        print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        print(sum(rec for rec in recalls.values()) / len(recalls))        \n",
    "        base_p_k.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        base_r_k.append(sum(rec for rec in recalls.values()) / len(recalls)) \n",
    "        \n",
    "        ############DO SLOPEONE ######################\n",
    "        algo = SlopeOne()\n",
    "        algo.fit(data_train.build_full_trainset())\n",
    "        pred= algo.test(testset)\n",
    "        \n",
    "#         #get the threashold \n",
    "#         est_value=[]\n",
    "#         for eachItem in pred:\n",
    "#             est_value.append(eachItem.est)\n",
    "#         est_value_np = np.array(est_value)\n",
    "#         adj_threashold = np.percentile(est_value_np, 80)\n",
    "#         print(\"threadshold:\"+str(adj_threashold))\n",
    "        \n",
    "        precisions, recalls = precision_recall_at_k(pred, k=k_value, threshold=0.5)\n",
    "        print(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        print(sum(rec for rec in recalls.values()) / len(recalls))        \n",
    "        slope_p_k.append(sum(prec for prec in precisions.values()) / len(precisions))\n",
    "        slope_r_k.append(sum(rec for rec in recalls.values()) / len(recalls))  \n",
    "        \n",
    "    print(\"SVD\")\n",
    "    print(cf_p_k)\n",
    "    print(mean([x for x in cf_p_k  if x != -1]))\n",
    "    print(cf_r_k)\n",
    "    print(mean([x for x in cf_r_k  if x != -1]))\n",
    "    print(\"BASELINE\")\n",
    "    print(base_p_k)\n",
    "    print(mean([x for x in base_p_k  if x != -1]))\n",
    "    print(base_r_k)\n",
    "    print(mean([x for x in base_r_k  if x != -1]))\n",
    "    print(\"SLOPE\")\n",
    "    print(slope_p_k)\n",
    "    print(mean([x for x in slope_p_k  if x != -1]))\n",
    "    print(slope_r_k)\n",
    "    print(mean([x for x in slope_r_k  if x != -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9994d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=matchEncodedData\n",
    "Y=isMatched\n",
    "\n",
    "testEverythingGroupCF(X,Y,\"id_user\",5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",5,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",5,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a29c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",5,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208284a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "testEverythingGroupCF(X,Y,\"id_user\",10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f8384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
